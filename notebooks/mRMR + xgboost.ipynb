{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae468260-b8b2-419c-9917-d9aeee35901f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import optuna\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "import joblib\n",
    "from mrmr import mrmr_classif\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20864616-0095-40a0-94bc-c10071e3900e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load both datasets\n",
    "original = pd.read_csv(\"PCOS_data.csv\")\n",
    "new = pd.read_csv(\"pcos_dataset.csv\")\n",
    "\n",
    "# Set max columns to show is unlimited\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da865d79-aa70-4b23-9d0a-2b45791d685b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df = df.copy()  # avoid SettingWithCopyWarning\n",
    "\n",
    "    # 1. Clean column names\n",
    "    df.columns = df.columns.str.strip() \\\n",
    "                           .str.replace(' ', '_') \\\n",
    "                           .str.replace('(', '') \\\n",
    "                           .str.replace(')', '') \\\n",
    "                           .str.replace('.', '') \\\n",
    "                           .str.replace('-', '_') \\\n",
    "                           .str.replace('/', '_')\n",
    "    df.rename(columns={'II____beta_HCGmIU_mL': 'II_beta_HCG'}, inplace=True)\n",
    "\n",
    "    # 2. Drop irrelevant columns\n",
    "    df.drop(columns=['Sl_No', 'Patient_File_No'], inplace=True, errors='ignore')\n",
    "    df = df.loc[:, ~df.columns.str.startswith('Unnamed')]\n",
    "\n",
    "    # 3. Merge Age columns\n",
    "    if 'Age' not in df.columns and 'Age_yrs' in df.columns:\n",
    "        df.rename(columns={'Age_yrs': 'Age'}, inplace=True)\n",
    "    elif 'Age' in df.columns and 'Age_yrs' in df.columns:\n",
    "        df['Age'] = df['Age'].fillna(df['Age_yrs'])\n",
    "        df.drop(columns=['Age_yrs'], inplace=True)\n",
    "\n",
    "    # 4. Merge PCOS diagnosis columns\n",
    "    if 'PCOS_Diagnosis' in df.columns:\n",
    "        df.rename(columns={'PCOS_Diagnosis': 'PCOS_Y_N'}, inplace=True)\n",
    "\n",
    "    # 5. Handle missing values\n",
    "    if 'Marraige_Status_Yrs' in df.columns:\n",
    "        df.loc[:, 'Marraige_Status_Yrs'] = df['Marraige_Status_Yrs'].fillna(df['Marraige_Status_Yrs'].median())\n",
    "\n",
    "    if 'Fast_food_Y_N' not in df.columns and 'Fast_food_YN' in df.columns:\n",
    "        df.rename(columns={'Fast_food_YN': 'Fast_food_Y_N'}, inplace=True)\n",
    "    if 'Fast_food_Y_N' in df.columns:\n",
    "        df.loc[:, 'Fast_food_Y_N'] = df['Fast_food_Y_N'].fillna(df['Fast_food_Y_N'].mode()[0])\n",
    "\n",
    "    # 6. Convert to numeric and fill missing values\n",
    "    if 'II_beta_HCG' not in df.columns and 'II_beta_HCGmIU_mL' in df.columns:\n",
    "        df.rename(columns={'II_beta_HCGmIU_mL': 'II_beta_HCG'}, inplace=True)\n",
    "    if 'II_beta_HCG' in df.columns:\n",
    "        df.loc[:, 'II_beta_HCG'] = pd.to_numeric(df['II_beta_HCG'], errors='coerce')\n",
    "        df['II_beta_HCG'] = df['II_beta_HCG'].astype(float)\n",
    "        df.loc[:, 'II_beta_HCG'] = df['II_beta_HCG'].fillna(df['II_beta_HCG'].median())\n",
    "\n",
    "    if 'AMHng_mL' in df.columns:\n",
    "        df.loc[:, 'AMHng_mL'] = pd.to_numeric(df['AMHng_mL'], errors='coerce')\n",
    "        df['AMHng_mL'] = df['AMHng_mL'].astype(float)\n",
    "        df.loc[:, 'AMHng_mL'] = df['AMHng_mL'].fillna(df['AMHng_mL'].median())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9783e46b-bfee-4ba4-96d8-1c2241513935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing\n",
    "original_clean = preprocess(original)\n",
    "new_clean = preprocess(new)\n",
    "\n",
    "# Ensure consistent columns across both\n",
    "all_columns = list(set(original_clean.columns).union(set(new_clean.columns)))\n",
    "\n",
    "# Align both dataframes to same columns, fill missing with NaN\n",
    "original_aligned = original_clean.reindex(columns=all_columns)\n",
    "new_aligned = new_clean.reindex(columns=all_columns)\n",
    "\n",
    "# Concatenate datasets\n",
    "combined_df = pd.concat([original_aligned, new_aligned], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26bdf1a3-5c90-4ba1-b3f9-38b2694f3892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "# X = combined_df.drop(columns=['PCOS_Y_N'])\n",
    "X = combined_df.drop(columns=['PCOS_Y_N'])\n",
    "y = combined_df['PCOS_Y_N']\n",
    "\n",
    "# Initialize KNNImputer (e.g., with 5 nearest neighbors)\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "X = pd.DataFrame(knn_imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Sanitize feature names\n",
    "X.columns = [str(col).replace(' ', '_')\n",
    "                        .replace('\"', '')\n",
    "                        .replace(\"'\", '')\n",
    "                        .replace('[', '')\n",
    "                        .replace(']', '')\n",
    "                        .replace('{', '')\n",
    "                        .replace('}', '')\n",
    "                        .replace(':', '')\n",
    "                        .replace(',', '')\n",
    "                        for col in X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5791e93-16c2-486c-9d03-954ec9896528",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(X_scaled, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32f841b0-10b0-4791-9245-e9e0bf03cead",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 20/20 [00:00<00:00, 73.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: ['Follicle_No_R', 'Menstrual_Irregularity', 'Weight_gainY_N', 'Antral_Follicle_Count', 'Testosterone_Levelng_dL', 'Follicle_No_L', 'Skin_darkening_Y_N', 'hair_growthY_N', 'CycleR_I', 'BMI', 'Fast_food_Y_N', 'AMHng_mL', 'Weight_Kg', 'PimplesY_N', 'Hipinch', 'Cycle_lengthdays', 'Waistinch', 'Hair_lossY_N', 'Avg_F_size_L_mm', 'Vit_D3_ng_mL']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "selected_features = mrmr_classif(X=X, y=y, K=20)\n",
    "print(\"Selected features:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9915e0cb-219a-4dd9-86bb-d53dffb566d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Follicle_No_R</th>\n",
       "      <th>Menstrual_Irregularity</th>\n",
       "      <th>Weight_gainY_N</th>\n",
       "      <th>Antral_Follicle_Count</th>\n",
       "      <th>Testosterone_Levelng_dL</th>\n",
       "      <th>Follicle_No_L</th>\n",
       "      <th>Skin_darkening_Y_N</th>\n",
       "      <th>hair_growthY_N</th>\n",
       "      <th>CycleR_I</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Fast_food_Y_N</th>\n",
       "      <th>AMHng_mL</th>\n",
       "      <th>Weight_Kg</th>\n",
       "      <th>PimplesY_N</th>\n",
       "      <th>Hipinch</th>\n",
       "      <th>Cycle_lengthdays</th>\n",
       "      <th>Waistinch</th>\n",
       "      <th>Hair_lossY_N</th>\n",
       "      <th>Avg_F_size_L_mm</th>\n",
       "      <th>Vit_D3_ng_mL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.122920</td>\n",
       "      <td>0.656224</td>\n",
       "      <td>-1.087760</td>\n",
       "      <td>-0.416818</td>\n",
       "      <td>0.921052</td>\n",
       "      <td>-1.005156</td>\n",
       "      <td>-0.985893</td>\n",
       "      <td>-0.943971</td>\n",
       "      <td>-0.956554</td>\n",
       "      <td>-1.339000</td>\n",
       "      <td>1.307316</td>\n",
       "      <td>-0.905453</td>\n",
       "      <td>-1.586104</td>\n",
       "      <td>-1.401337</td>\n",
       "      <td>-0.862759</td>\n",
       "      <td>0.114870</td>\n",
       "      <td>-1.509019</td>\n",
       "      <td>-1.391155</td>\n",
       "      <td>1.248587</td>\n",
       "      <td>-0.103081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.496297</td>\n",
       "      <td>-0.745034</td>\n",
       "      <td>-1.087760</td>\n",
       "      <td>-0.551229</td>\n",
       "      <td>-0.683885</td>\n",
       "      <td>-1.005156</td>\n",
       "      <td>-0.985893</td>\n",
       "      <td>-0.943971</td>\n",
       "      <td>-0.956554</td>\n",
       "      <td>-0.159445</td>\n",
       "      <td>-1.446339</td>\n",
       "      <td>-1.033395</td>\n",
       "      <td>0.187682</td>\n",
       "      <td>-1.401337</td>\n",
       "      <td>-0.262582</td>\n",
       "      <td>0.114870</td>\n",
       "      <td>-0.852609</td>\n",
       "      <td>-1.391155</td>\n",
       "      <td>0.055793</td>\n",
       "      <td>0.102239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.636818</td>\n",
       "      <td>1.123310</td>\n",
       "      <td>-1.087760</td>\n",
       "      <td>0.154429</td>\n",
       "      <td>0.412467</td>\n",
       "      <td>2.298768</td>\n",
       "      <td>-0.985893</td>\n",
       "      <td>-0.943971</td>\n",
       "      <td>-0.956554</td>\n",
       "      <td>-0.075192</td>\n",
       "      <td>1.307316</td>\n",
       "      <td>0.174942</td>\n",
       "      <td>0.518093</td>\n",
       "      <td>1.415596</td>\n",
       "      <td>0.337595</td>\n",
       "      <td>0.114870</td>\n",
       "      <td>0.460211</td>\n",
       "      <td>1.612166</td>\n",
       "      <td>1.248587</td>\n",
       "      <td>0.048354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.436231</td>\n",
       "      <td>0.656224</td>\n",
       "      <td>-1.087760</td>\n",
       "      <td>-0.215202</td>\n",
       "      <td>-0.414873</td>\n",
       "      <td>-1.335549</td>\n",
       "      <td>-0.985893</td>\n",
       "      <td>-0.943971</td>\n",
       "      <td>-0.956554</td>\n",
       "      <td>0.851601</td>\n",
       "      <td>-1.446339</td>\n",
       "      <td>-1.106843</td>\n",
       "      <td>0.187682</td>\n",
       "      <td>-1.401337</td>\n",
       "      <td>0.937772</td>\n",
       "      <td>0.114870</td>\n",
       "      <td>0.460211</td>\n",
       "      <td>-1.391155</td>\n",
       "      <td>0.055793</td>\n",
       "      <td>-0.027364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.809608</td>\n",
       "      <td>-0.277948</td>\n",
       "      <td>-1.087760</td>\n",
       "      <td>-0.248804</td>\n",
       "      <td>-0.029120</td>\n",
       "      <td>-1.005156</td>\n",
       "      <td>-0.985893</td>\n",
       "      <td>-0.943971</td>\n",
       "      <td>-0.956554</td>\n",
       "      <td>-1.170492</td>\n",
       "      <td>-1.446339</td>\n",
       "      <td>-0.860437</td>\n",
       "      <td>-0.942672</td>\n",
       "      <td>-1.401337</td>\n",
       "      <td>-0.562671</td>\n",
       "      <td>0.114870</td>\n",
       "      <td>-1.509019</td>\n",
       "      <td>1.612166</td>\n",
       "      <td>0.453391</td>\n",
       "      <td>0.020947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>-0.370972</td>\n",
       "      <td>1.123310</td>\n",
       "      <td>-1.087760</td>\n",
       "      <td>0.927292</td>\n",
       "      <td>1.825542</td>\n",
       "      <td>-0.674764</td>\n",
       "      <td>0.196872</td>\n",
       "      <td>-0.309580</td>\n",
       "      <td>-0.956554</td>\n",
       "      <td>-1.528571</td>\n",
       "      <td>-0.895608</td>\n",
       "      <td>-0.135435</td>\n",
       "      <td>-1.499154</td>\n",
       "      <td>-1.401337</td>\n",
       "      <td>-2.123131</td>\n",
       "      <td>0.114870</td>\n",
       "      <td>-2.362353</td>\n",
       "      <td>-0.790491</td>\n",
       "      <td>0.811229</td>\n",
       "      <td>-0.056443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>-0.182985</td>\n",
       "      <td>1.123310</td>\n",
       "      <td>0.454317</td>\n",
       "      <td>-1.760928</td>\n",
       "      <td>-1.585330</td>\n",
       "      <td>0.250335</td>\n",
       "      <td>-0.394511</td>\n",
       "      <td>-0.309580</td>\n",
       "      <td>-0.355269</td>\n",
       "      <td>0.683094</td>\n",
       "      <td>-1.446339</td>\n",
       "      <td>-0.599341</td>\n",
       "      <td>0.196377</td>\n",
       "      <td>-0.274564</td>\n",
       "      <td>0.457630</td>\n",
       "      <td>-0.080080</td>\n",
       "      <td>0.591493</td>\n",
       "      <td>-0.189827</td>\n",
       "      <td>0.214832</td>\n",
       "      <td>-0.054213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>-0.370972</td>\n",
       "      <td>-1.212120</td>\n",
       "      <td>-0.059708</td>\n",
       "      <td>1.767361</td>\n",
       "      <td>-1.387377</td>\n",
       "      <td>-0.146136</td>\n",
       "      <td>-0.985893</td>\n",
       "      <td>-0.309580</td>\n",
       "      <td>-0.355269</td>\n",
       "      <td>0.556713</td>\n",
       "      <td>-0.344877</td>\n",
       "      <td>-0.143490</td>\n",
       "      <td>0.568524</td>\n",
       "      <td>-0.837951</td>\n",
       "      <td>0.517648</td>\n",
       "      <td>0.504769</td>\n",
       "      <td>0.460211</td>\n",
       "      <td>-0.189827</td>\n",
       "      <td>0.453391</td>\n",
       "      <td>-0.036951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>-0.809608</td>\n",
       "      <td>-1.212120</td>\n",
       "      <td>1.482369</td>\n",
       "      <td>-1.424901</td>\n",
       "      <td>1.820466</td>\n",
       "      <td>-0.344371</td>\n",
       "      <td>0.788254</td>\n",
       "      <td>-0.309580</td>\n",
       "      <td>0.847301</td>\n",
       "      <td>0.346078</td>\n",
       "      <td>1.307316</td>\n",
       "      <td>0.044631</td>\n",
       "      <td>0.648518</td>\n",
       "      <td>-0.274564</td>\n",
       "      <td>0.817736</td>\n",
       "      <td>0.114870</td>\n",
       "      <td>1.182263</td>\n",
       "      <td>-0.189827</td>\n",
       "      <td>0.135312</td>\n",
       "      <td>-0.061831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>0.819611</td>\n",
       "      <td>1.123310</td>\n",
       "      <td>-0.059708</td>\n",
       "      <td>-1.760928</td>\n",
       "      <td>0.972824</td>\n",
       "      <td>-0.278293</td>\n",
       "      <td>-0.394511</td>\n",
       "      <td>0.959203</td>\n",
       "      <td>0.246016</td>\n",
       "      <td>-0.791350</td>\n",
       "      <td>0.205854</td>\n",
       "      <td>-0.188033</td>\n",
       "      <td>-0.768771</td>\n",
       "      <td>-0.274564</td>\n",
       "      <td>0.277577</td>\n",
       "      <td>-0.859878</td>\n",
       "      <td>0.197647</td>\n",
       "      <td>0.410837</td>\n",
       "      <td>-0.023727</td>\n",
       "      <td>-0.095742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1541 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Follicle_No_R  Menstrual_Irregularity  Weight_gainY_N  \\\n",
       "0         -1.122920                0.656224       -1.087760   \n",
       "1         -0.496297               -0.745034       -1.087760   \n",
       "2          2.636818                1.123310       -1.087760   \n",
       "3         -1.436231                0.656224       -1.087760   \n",
       "4         -0.809608               -0.277948       -1.087760   \n",
       "...             ...                     ...             ...   \n",
       "1536      -0.370972                1.123310       -1.087760   \n",
       "1537      -0.182985                1.123310        0.454317   \n",
       "1538      -0.370972               -1.212120       -0.059708   \n",
       "1539      -0.809608               -1.212120        1.482369   \n",
       "1540       0.819611                1.123310       -0.059708   \n",
       "\n",
       "      Antral_Follicle_Count  Testosterone_Levelng_dL  Follicle_No_L  \\\n",
       "0                 -0.416818                 0.921052      -1.005156   \n",
       "1                 -0.551229                -0.683885      -1.005156   \n",
       "2                  0.154429                 0.412467       2.298768   \n",
       "3                 -0.215202                -0.414873      -1.335549   \n",
       "4                 -0.248804                -0.029120      -1.005156   \n",
       "...                     ...                      ...            ...   \n",
       "1536               0.927292                 1.825542      -0.674764   \n",
       "1537              -1.760928                -1.585330       0.250335   \n",
       "1538               1.767361                -1.387377      -0.146136   \n",
       "1539              -1.424901                 1.820466      -0.344371   \n",
       "1540              -1.760928                 0.972824      -0.278293   \n",
       "\n",
       "      Skin_darkening_Y_N  hair_growthY_N  CycleR_I       BMI  Fast_food_Y_N  \\\n",
       "0              -0.985893       -0.943971 -0.956554 -1.339000       1.307316   \n",
       "1              -0.985893       -0.943971 -0.956554 -0.159445      -1.446339   \n",
       "2              -0.985893       -0.943971 -0.956554 -0.075192       1.307316   \n",
       "3              -0.985893       -0.943971 -0.956554  0.851601      -1.446339   \n",
       "4              -0.985893       -0.943971 -0.956554 -1.170492      -1.446339   \n",
       "...                  ...             ...       ...       ...            ...   \n",
       "1536            0.196872       -0.309580 -0.956554 -1.528571      -0.895608   \n",
       "1537           -0.394511       -0.309580 -0.355269  0.683094      -1.446339   \n",
       "1538           -0.985893       -0.309580 -0.355269  0.556713      -0.344877   \n",
       "1539            0.788254       -0.309580  0.847301  0.346078       1.307316   \n",
       "1540           -0.394511        0.959203  0.246016 -0.791350       0.205854   \n",
       "\n",
       "      AMHng_mL  Weight_Kg  PimplesY_N   Hipinch  Cycle_lengthdays  Waistinch  \\\n",
       "0    -0.905453  -1.586104   -1.401337 -0.862759          0.114870  -1.509019   \n",
       "1    -1.033395   0.187682   -1.401337 -0.262582          0.114870  -0.852609   \n",
       "2     0.174942   0.518093    1.415596  0.337595          0.114870   0.460211   \n",
       "3    -1.106843   0.187682   -1.401337  0.937772          0.114870   0.460211   \n",
       "4    -0.860437  -0.942672   -1.401337 -0.562671          0.114870  -1.509019   \n",
       "...        ...        ...         ...       ...               ...        ...   \n",
       "1536 -0.135435  -1.499154   -1.401337 -2.123131          0.114870  -2.362353   \n",
       "1537 -0.599341   0.196377   -0.274564  0.457630         -0.080080   0.591493   \n",
       "1538 -0.143490   0.568524   -0.837951  0.517648          0.504769   0.460211   \n",
       "1539  0.044631   0.648518   -0.274564  0.817736          0.114870   1.182263   \n",
       "1540 -0.188033  -0.768771   -0.274564  0.277577         -0.859878   0.197647   \n",
       "\n",
       "      Hair_lossY_N  Avg_F_size_L_mm  Vit_D3_ng_mL  \n",
       "0        -1.391155         1.248587     -0.103081  \n",
       "1        -1.391155         0.055793      0.102239  \n",
       "2         1.612166         1.248587      0.048354  \n",
       "3        -1.391155         0.055793     -0.027364  \n",
       "4         1.612166         0.453391      0.020947  \n",
       "...            ...              ...           ...  \n",
       "1536     -0.790491         0.811229     -0.056443  \n",
       "1537     -0.189827         0.214832     -0.054213  \n",
       "1538     -0.189827         0.453391     -0.036951  \n",
       "1539     -0.189827         0.135312     -0.061831  \n",
       "1540      0.410837        -0.023727     -0.095742  \n",
       "\n",
       "[1541 rows x 20 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X[selected_features]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94cfbf1f-1bfc-4940-831f-ec7d4411d941",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.15, stratify=y, shuffle=True, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1b7c089-3ca2-4422-971e-3ff87d3b8a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    param = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-3, 10.0, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-3, 10.0, log=True),\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"random_state\": 8,\n",
    "        \"use_label_encoder\": False,\n",
    "    }\n",
    "\n",
    "    train_pool = xgb.DMatrix(x_train, y_train)\n",
    "    valid_pool = xgb.DMatrix(x_test, y_test)\n",
    "    \n",
    "    # Train model\n",
    "    model = xgb.XGBClassifier(**param)\n",
    "    model.fit(x_train, y_train,\n",
    "              eval_set=[(x_test, y_test)],\n",
    "              verbose=False)\n",
    "\n",
    "    # Predict\n",
    "    preds = model.predict(x_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "\n",
    "    return 1.0 - acc  # Optuna minimizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5353a8f1-c50f-4861-95cc-5dbb7e8c888a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 21:19:07,583] A new study created in memory with name: no-name-167082d4-5ecc-4d74-8618-4f6879dc8a93\n",
      "[I 2025-05-31 21:19:08,233] Trial 0 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.014697917087638446, 'n_estimators': 575, 'max_depth': 6, 'subsample': 0.7210979024447284, 'colsample_bytree': 0.89988407213509, 'reg_alpha': 0.003512649780635479, 'reg_lambda': 0.019140631628833987}. Best is trial 0 with value: 0.03879310344827591.\n",
      "[I 2025-05-31 21:19:08,624] Trial 1 finished with value: 0.0431034482758621 and parameters: {'learning_rate': 0.09360433294120321, 'n_estimators': 355, 'max_depth': 11, 'subsample': 0.9219560138646214, 'colsample_bytree': 0.7355085055740559, 'reg_alpha': 0.0932284115096075, 'reg_lambda': 0.01901415811875373}. Best is trial 0 with value: 0.03879310344827591.\n",
      "[I 2025-05-31 21:19:08,855] Trial 2 finished with value: 0.0431034482758621 and parameters: {'learning_rate': 0.08492137650458435, 'n_estimators': 153, 'max_depth': 10, 'subsample': 0.884208467657643, 'colsample_bytree': 0.9029429817136538, 'reg_alpha': 0.012027735871607489, 'reg_lambda': 0.06801875219579802}. Best is trial 0 with value: 0.03879310344827591.\n",
      "[I 2025-05-31 21:19:09,164] Trial 3 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.19022381059883506, 'n_estimators': 296, 'max_depth': 12, 'subsample': 0.6780048577007122, 'colsample_bytree': 0.9113132178323893, 'reg_alpha': 1.3724141174879971, 'reg_lambda': 2.372654147450662}. Best is trial 3 with value: 0.03448275862068961.\n",
      "[I 2025-05-31 21:19:10,031] Trial 4 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.044544208491745604, 'n_estimators': 848, 'max_depth': 7, 'subsample': 0.828977305398274, 'colsample_bytree': 0.7707499800191835, 'reg_alpha': 0.003861570754393327, 'reg_lambda': 1.0353733102008795}. Best is trial 3 with value: 0.03448275862068961.\n",
      "[I 2025-05-31 21:19:10,601] Trial 5 finished with value: 0.06034482758620685 and parameters: {'learning_rate': 0.03706328282631779, 'n_estimators': 858, 'max_depth': 3, 'subsample': 0.7289324263786123, 'colsample_bytree': 0.6433766621711506, 'reg_alpha': 0.002169414832214576, 'reg_lambda': 0.6979832136334493}. Best is trial 3 with value: 0.03448275862068961.\n",
      "[I 2025-05-31 21:19:10,766] Trial 6 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.01652358718984332, 'n_estimators': 120, 'max_depth': 7, 'subsample': 0.6117666298608431, 'colsample_bytree': 0.9687810330538446, 'reg_alpha': 1.7970437210051817, 'reg_lambda': 0.04543924837539632}. Best is trial 3 with value: 0.03448275862068961.\n",
      "[I 2025-05-31 21:19:10,972] Trial 7 finished with value: 0.05603448275862066 and parameters: {'learning_rate': 0.03113172691967601, 'n_estimators': 240, 'max_depth': 4, 'subsample': 0.9097241150813274, 'colsample_bytree': 0.7140233690455335, 'reg_alpha': 0.1805601114542817, 'reg_lambda': 7.403280791627014}. Best is trial 3 with value: 0.03448275862068961.\n",
      "[I 2025-05-31 21:19:11,595] Trial 8 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.10288919970502351, 'n_estimators': 770, 'max_depth': 9, 'subsample': 0.6643963328994316, 'colsample_bytree': 0.7771979912696835, 'reg_alpha': 0.03295758981060871, 'reg_lambda': 0.021794250743950538}. Best is trial 3 with value: 0.03448275862068961.\n",
      "[I 2025-05-31 21:19:12,104] Trial 9 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.12120287267367591, 'n_estimators': 642, 'max_depth': 11, 'subsample': 0.7908851807747844, 'colsample_bytree': 0.8416936152868704, 'reg_alpha': 1.1124389342227705, 'reg_lambda': 0.0018504601031673284}. Best is trial 3 with value: 0.03448275862068961.\n",
      "[I 2025-05-31 21:19:12,319] Trial 10 finished with value: 0.051724137931034475 and parameters: {'learning_rate': 0.24970019178477645, 'n_estimators': 392, 'max_depth': 12, 'subsample': 0.63624053516221, 'colsample_bytree': 0.9677849133450275, 'reg_alpha': 9.777593313788316, 'reg_lambda': 9.143708962313916}. Best is trial 3 with value: 0.03448275862068961.\n",
      "[I 2025-05-31 21:19:12,803] Trial 11 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.2618449692166259, 'n_estimators': 713, 'max_depth': 10, 'subsample': 0.6878346783030758, 'colsample_bytree': 0.8553025103313819, 'reg_alpha': 0.0858198084899538, 'reg_lambda': 0.00241381605757547}. Best is trial 11 with value: 0.030172413793103425.\n",
      "[I 2025-05-31 21:19:13,379] Trial 12 finished with value: 0.04741379310344829 and parameters: {'learning_rate': 0.29283013681139586, 'n_estimators': 977, 'max_depth': 12, 'subsample': 0.7098739187935135, 'colsample_bytree': 0.8610671481701703, 'reg_alpha': 0.3865026260949495, 'reg_lambda': 0.0012412936001222085}. Best is trial 11 with value: 0.030172413793103425.\n",
      "[I 2025-05-31 21:19:13,654] Trial 13 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.18893801291282097, 'n_estimators': 433, 'max_depth': 9, 'subsample': 0.779127847650799, 'colsample_bytree': 0.9254574718193525, 'reg_alpha': 6.044316434338083, 'reg_lambda': 0.5116068863175313}. Best is trial 11 with value: 0.030172413793103425.\n",
      "[I 2025-05-31 21:19:13,915] Trial 14 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.16389838718877825, 'n_estimators': 473, 'max_depth': 9, 'subsample': 0.7865582136545065, 'colsample_bytree': 0.9987769159573584, 'reg_alpha': 9.57649076774106, 'reg_lambda': 0.27268044834131533}. Best is trial 11 with value: 0.030172413793103425.\n",
      "[I 2025-05-31 21:19:14,591] Trial 15 finished with value: 0.04741379310344829 and parameters: {'learning_rate': 0.0627696731805202, 'n_estimators': 678, 'max_depth': 9, 'subsample': 0.9926925200541472, 'colsample_bytree': 0.8467058105618185, 'reg_alpha': 0.03702684656231844, 'reg_lambda': 0.004005590786790549}. Best is trial 11 with value: 0.030172413793103425.\n",
      "[I 2025-05-31 21:19:15,020] Trial 16 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.16854375144338984, 'n_estimators': 490, 'max_depth': 8, 'subsample': 0.7536295652585414, 'colsample_bytree': 0.8152286533762692, 'reg_alpha': 0.36403530573771714, 'reg_lambda': 0.16683894442848085}. Best is trial 11 with value: 0.030172413793103425.\n",
      "[I 2025-05-31 21:19:15,491] Trial 17 finished with value: 0.0431034482758621 and parameters: {'learning_rate': 0.22454746834092268, 'n_estimators': 683, 'max_depth': 5, 'subsample': 0.8357186812001047, 'colsample_bytree': 0.9441892606636868, 'reg_alpha': 0.015037296397821271, 'reg_lambda': 0.006044429127748118}. Best is trial 11 with value: 0.030172413793103425.\n",
      "[I 2025-05-31 21:19:15,916] Trial 18 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.13915282865374567, 'n_estimators': 529, 'max_depth': 10, 'subsample': 0.7636912769184134, 'colsample_bytree': 0.6269838883933532, 'reg_alpha': 2.7748181772864338, 'reg_lambda': 0.4378368956636672}. Best is trial 18 with value: 0.025862068965517238.\n",
      "[I 2025-05-31 21:19:16,496] Trial 19 finished with value: 0.0431034482758621 and parameters: {'learning_rate': 0.13175475808117923, 'n_estimators': 597, 'max_depth': 10, 'subsample': 0.6781142623351979, 'colsample_bytree': 0.6123015442602816, 'reg_alpha': 0.07821690027723963, 'reg_lambda': 2.027943781695783}. Best is trial 18 with value: 0.025862068965517238.\n",
      "[I 2025-05-31 21:19:17,154] Trial 20 finished with value: 0.04741379310344829 and parameters: {'learning_rate': 0.06595922286656412, 'n_estimators': 759, 'max_depth': 10, 'subsample': 0.8425260752444916, 'colsample_bytree': 0.6803572604730617, 'reg_alpha': 3.0216150713015764, 'reg_lambda': 0.0045664137934141955}. Best is trial 18 with value: 0.025862068965517238.\n",
      "[I 2025-05-31 21:19:17,438] Trial 21 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.273449253601176, 'n_estimators': 490, 'max_depth': 8, 'subsample': 0.7700540361809333, 'colsample_bytree': 0.8828872428344601, 'reg_alpha': 3.6999565797315155, 'reg_lambda': 0.40259368840362986}. Best is trial 18 with value: 0.025862068965517238.\n",
      "[I 2025-05-31 21:19:17,815] Trial 22 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.15066904191893304, 'n_estimators': 403, 'max_depth': 11, 'subsample': 0.7417613521687417, 'colsample_bytree': 0.8066889722978948, 'reg_alpha': 0.6199399465136098, 'reg_lambda': 0.3253887764823744}. Best is trial 18 with value: 0.025862068965517238.\n",
      "[I 2025-05-31 21:19:18,165] Trial 23 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.1992811840467019, 'n_estimators': 549, 'max_depth': 9, 'subsample': 0.6923072045228291, 'colsample_bytree': 0.9267350385398181, 'reg_alpha': 4.0076237736203515, 'reg_lambda': 0.12359833366360266}. Best is trial 18 with value: 0.025862068965517238.\n",
      "[I 2025-05-31 21:19:18,807] Trial 24 finished with value: 0.02155172413793105 and parameters: {'learning_rate': 0.12608060183320494, 'n_estimators': 735, 'max_depth': 10, 'subsample': 0.6448944285234446, 'colsample_bytree': 0.8697910770454482, 'reg_alpha': 0.15198286950691367, 'reg_lambda': 1.1540636059453475}. Best is trial 24 with value: 0.02155172413793105.\n",
      "[I 2025-05-31 21:19:19,646] Trial 25 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.07463462646743602, 'n_estimators': 781, 'max_depth': 10, 'subsample': 0.6397138469100203, 'colsample_bytree': 0.7575970121405166, 'reg_alpha': 0.20596303997016327, 'reg_lambda': 1.686915838767628}. Best is trial 24 with value: 0.02155172413793105.\n",
      "[I 2025-05-31 21:19:20,582] Trial 26 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.11617605846535858, 'n_estimators': 985, 'max_depth': 11, 'subsample': 0.6102855982164636, 'colsample_bytree': 0.6755841048518548, 'reg_alpha': 0.04059279414168509, 'reg_lambda': 3.8335705823244415}. Best is trial 24 with value: 0.02155172413793105.\n",
      "[I 2025-05-31 21:19:21,474] Trial 27 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.11937260983803667, 'n_estimators': 974, 'max_depth': 11, 'subsample': 0.6010562614575033, 'colsample_bytree': 0.6681369212094543, 'reg_alpha': 0.009761827836925207, 'reg_lambda': 3.9496395634630828}. Best is trial 24 with value: 0.02155172413793105.\n",
      "[I 2025-05-31 21:19:22,409] Trial 28 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.05025963800625777, 'n_estimators': 857, 'max_depth': 8, 'subsample': 0.6378470265147544, 'colsample_bytree': 0.6161798788473845, 'reg_alpha': 0.03750798647839968, 'reg_lambda': 1.3265812104887968}. Best is trial 24 with value: 0.02155172413793105.\n",
      "[I 2025-05-31 21:19:23,790] Trial 29 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.011634531706419886, 'n_estimators': 915, 'max_depth': 11, 'subsample': 0.6507909954486457, 'colsample_bytree': 0.7070588400552381, 'reg_alpha': 0.0010218553550460261, 'reg_lambda': 4.148182831783892}. Best is trial 24 with value: 0.02155172413793105.\n",
      "[I 2025-05-31 21:19:24,381] Trial 30 finished with value: 0.0431034482758621 and parameters: {'learning_rate': 0.10457071602307212, 'n_estimators': 561, 'max_depth': 6, 'subsample': 0.7117327508156961, 'colsample_bytree': 0.6539684429726396, 'reg_alpha': 0.7079986555396628, 'reg_lambda': 4.981076686644902}. Best is trial 24 with value: 0.02155172413793105.\n",
      "[I 2025-05-31 21:19:24,988] Trial 31 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.15363498950225218, 'n_estimators': 716, 'max_depth': 10, 'subsample': 0.6168995093672043, 'colsample_bytree': 0.8766642589317, 'reg_alpha': 0.1554441322775948, 'reg_lambda': 0.941367789663253}. Best is trial 24 with value: 0.02155172413793105.\n",
      "[I 2025-05-31 21:19:25,614] Trial 32 finished with value: 0.0431034482758621 and parameters: {'learning_rate': 0.08014869554708827, 'n_estimators': 618, 'max_depth': 12, 'subsample': 0.6982695536910254, 'colsample_bytree': 0.6015774956144645, 'reg_alpha': 0.05624406629627985, 'reg_lambda': 0.1915239600547003}. Best is trial 24 with value: 0.02155172413793105.\n",
      "[I 2025-05-31 21:19:26,169] Trial 33 finished with value: 0.04741379310344829 and parameters: {'learning_rate': 0.2282611087692911, 'n_estimators': 818, 'max_depth': 10, 'subsample': 0.6633581507677448, 'colsample_bytree': 0.8284242520701849, 'reg_alpha': 0.022174699721793728, 'reg_lambda': 0.07180940277893981}. Best is trial 24 with value: 0.02155172413793105.\n",
      "[I 2025-05-31 21:19:26,845] Trial 34 finished with value: 0.0431034482758621 and parameters: {'learning_rate': 0.13675923870792733, 'n_estimators': 893, 'max_depth': 11, 'subsample': 0.7285339202582793, 'colsample_bytree': 0.6320748896015015, 'reg_alpha': 0.007458666815138128, 'reg_lambda': 0.013753015593071861}. Best is trial 24 with value: 0.02155172413793105.\n",
      "[I 2025-05-31 21:19:27,576] Trial 35 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.09868588459371813, 'n_estimators': 713, 'max_depth': 11, 'subsample': 0.6241935165985404, 'colsample_bytree': 0.6840162009508906, 'reg_alpha': 0.09703240347808678, 'reg_lambda': 2.9075118932020607}. Best is trial 24 with value: 0.02155172413793105.\n",
      "[I 2025-05-31 21:19:28,131] Trial 36 finished with value: 0.0431034482758621 and parameters: {'learning_rate': 0.0846424772380658, 'n_estimators': 544, 'max_depth': 10, 'subsample': 0.6777309746939334, 'colsample_bytree': 0.7827511588366846, 'reg_alpha': 0.005119708846915401, 'reg_lambda': 0.6754013810488063}. Best is trial 24 with value: 0.02155172413793105.\n",
      "[I 2025-05-31 21:19:28,688] Trial 37 finished with value: 0.04741379310344829 and parameters: {'learning_rate': 0.022023506927924267, 'n_estimators': 301, 'max_depth': 12, 'subsample': 0.8612644484647662, 'colsample_bytree': 0.6325636952553174, 'reg_alpha': 0.06133546607453996, 'reg_lambda': 1.1290105607544816}. Best is trial 24 with value: 0.02155172413793105.\n",
      "[I 2025-05-31 21:19:29,240] Trial 38 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.1992164603109598, 'n_estimators': 818, 'max_depth': 7, 'subsample': 0.8136918395446651, 'colsample_bytree': 0.7401717432316383, 'reg_alpha': 0.3638319933468082, 'reg_lambda': 0.036322587284164445}. Best is trial 24 with value: 0.02155172413793105.\n",
      "[I 2025-05-31 21:19:30,288] Trial 39 finished with value: 0.0431034482758621 and parameters: {'learning_rate': 0.04064113833483952, 'n_estimators': 997, 'max_depth': 9, 'subsample': 0.7567045959577616, 'colsample_bytree': 0.8942034128293784, 'reg_alpha': 0.1460434307516924, 'reg_lambda': 0.6138250048682412}. Best is trial 24 with value: 0.02155172413793105.\n",
      "[I 2025-05-31 21:19:31,275] Trial 40 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.059377091149056295, 'n_estimators': 924, 'max_depth': 11, 'subsample': 0.6579356663429361, 'colsample_bytree': 0.7278558841716634, 'reg_alpha': 0.02131512018251007, 'reg_lambda': 2.5890287583128364}. Best is trial 24 with value: 0.02155172413793105.\n",
      "[I 2025-05-31 21:19:31,616] Trial 41 finished with value: 0.04741379310344829 and parameters: {'learning_rate': 0.17039482454804872, 'n_estimators': 421, 'max_depth': 9, 'subsample': 0.8005990413430761, 'colsample_bytree': 0.9132417564562734, 'reg_alpha': 1.8011040293397753, 'reg_lambda': 0.46352687303234097}. Best is trial 24 with value: 0.02155172413793105.\n",
      "[I 2025-05-31 21:19:31,870] Trial 42 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.2015445567465475, 'n_estimators': 336, 'max_depth': 10, 'subsample': 0.7692189036494842, 'colsample_bytree': 0.8651641554292071, 'reg_alpha': 6.330676492355841, 'reg_lambda': 5.994824717309499}. Best is trial 24 with value: 0.02155172413793105.\n",
      "[I 2025-05-31 21:19:32,129] Trial 43 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.11672601404520817, 'n_estimators': 189, 'max_depth': 10, 'subsample': 0.602050081368387, 'colsample_bytree': 0.8641025352577146, 'reg_alpha': 1.0851982585432256, 'reg_lambda': 6.720866575948913}. Best is trial 24 with value: 0.02155172413793105.\n",
      "[I 2025-05-31 21:19:32,486] Trial 44 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.26358388535355065, 'n_estimators': 337, 'max_depth': 12, 'subsample': 0.6918994848541845, 'colsample_bytree': 0.8374139396985397, 'reg_alpha': 0.24276806857285935, 'reg_lambda': 5.422402508837801}. Best is trial 24 with value: 0.02155172413793105.\n",
      "[I 2025-05-31 21:19:32,708] Trial 45 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.22401576197863726, 'n_estimators': 185, 'max_depth': 10, 'subsample': 0.7424186917967077, 'colsample_bytree': 0.7980499765780951, 'reg_alpha': 2.0617549103381587, 'reg_lambda': 3.414714577980854}. Best is trial 24 with value: 0.02155172413793105.\n",
      "[I 2025-05-31 21:19:33,101] Trial 46 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.14216942437501673, 'n_estimators': 662, 'max_depth': 11, 'subsample': 0.8126038106304734, 'colsample_bytree': 0.8582836097620383, 'reg_alpha': 6.8000291351112505, 'reg_lambda': 1.7953045685574536}. Best is trial 24 with value: 0.02155172413793105.\n",
      "[I 2025-05-31 21:19:33,281] Trial 47 finished with value: 0.06896551724137934 and parameters: {'learning_rate': 0.29963007410810927, 'n_estimators': 246, 'max_depth': 3, 'subsample': 0.625617911153889, 'colsample_bytree': 0.8257031292648461, 'reg_alpha': 0.12596481777078566, 'reg_lambda': 9.356025294367914}. Best is trial 24 with value: 0.02155172413793105.\n",
      "[I 2025-05-31 21:19:33,698] Trial 48 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.18208482898871078, 'n_estimators': 733, 'max_depth': 8, 'subsample': 0.723462545668448, 'colsample_bytree': 0.8899002407784532, 'reg_alpha': 5.03939392930515, 'reg_lambda': 0.8497714844124873}. Best is trial 24 with value: 0.02155172413793105.\n",
      "[I 2025-05-31 21:19:33,823] Trial 49 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.10945837163410646, 'n_estimators': 108, 'max_depth': 6, 'subsample': 0.7634072017408888, 'colsample_bytree': 0.8945562316136131, 'reg_alpha': 5.546287042304131, 'reg_lambda': 1.2604816959793146}. Best is trial 24 with value: 0.02155172413793105.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:\n",
      "{'learning_rate': 0.12608060183320494, 'n_estimators': 735, 'max_depth': 10, 'subsample': 0.6448944285234446, 'colsample_bytree': 0.8697910770454482, 'reg_alpha': 0.15198286950691367, 'reg_lambda': 1.1540636059453475}\n",
      "Best accuracy:\n",
      "0.978448275862069\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')  # Because we return 1 - accuracy\n",
    "study.optimize(objective, n_trials=50)  # Try 50 combinations (or more!)\n",
    "\n",
    "print(\"Best hyperparameters:\")\n",
    "print(study.best_params)\n",
    "\n",
    "print(\"Best accuracy:\")\n",
    "print(1 - study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42b8bbb5-0f46-4dfe-b5c4-57ba49252dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final evaluation on test set:\n",
      "Accuracy: 96.98\n",
      "Precision: 94.64\n",
      "Recall: 92.98\n",
      "F1 Score: 93.81\n"
     ]
    }
   ],
   "source": [
    "# Get the data\n",
    "best_model = xgb.XGBClassifier(**study.best_params)\n",
    "best_model.fit(x_train, y_train,\n",
    "          eval_set=[(x_test, y_test)],\n",
    "          verbose=False)\n",
    "\n",
    "# Predict\n",
    "preds = best_model.predict(x_test)\n",
    "\n",
    "# Compute final scores\n",
    "acc = accuracy_score(y_test, preds)\n",
    "precision = precision_score(y_test, preds, average='binary')\n",
    "recall = recall_score(y_test, preds, average='binary')\n",
    "f1 = f1_score(y_test, preds, average='binary')\n",
    "\n",
    "print(\"\\nFinal evaluation on test set:\")\n",
    "print(f\"Accuracy: {acc * 100:.2f}\")\n",
    "print(f\"Precision: {precision * 100:.2f}\")\n",
    "print(f\"Recall: {recall * 100:.2f}\")\n",
    "print(f\"F1 Score: {f1 * 100:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1660a7-a8e4-4cbc-b132-0bca779ede92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
