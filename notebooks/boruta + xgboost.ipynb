{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae468260-b8b2-419c-9917-d9aeee35901f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import optuna\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "import joblib\n",
    "from boruta import BorutaPy\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20864616-0095-40a0-94bc-c10071e3900e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load both datasets\n",
    "original = pd.read_csv(\"PCOS_data.csv\")\n",
    "new = pd.read_csv(\"pcos_dataset.csv\")\n",
    "\n",
    "# Set max columns to show is unlimited\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da865d79-aa70-4b23-9d0a-2b45791d685b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df = df.copy()  # avoid SettingWithCopyWarning\n",
    "\n",
    "    # 1. Clean column names\n",
    "    df.columns = df.columns.str.strip() \\\n",
    "                           .str.replace(' ', '_') \\\n",
    "                           .str.replace('(', '') \\\n",
    "                           .str.replace(')', '') \\\n",
    "                           .str.replace('.', '') \\\n",
    "                           .str.replace('-', '_') \\\n",
    "                           .str.replace('/', '_')\n",
    "    df.rename(columns={'II____beta_HCGmIU_mL': 'II_beta_HCG'}, inplace=True)\n",
    "\n",
    "    # 2. Drop irrelevant columns\n",
    "    df.drop(columns=['Sl_No', 'Patient_File_No'], inplace=True, errors='ignore')\n",
    "    df = df.loc[:, ~df.columns.str.startswith('Unnamed')]\n",
    "\n",
    "    # 3. Merge Age columns\n",
    "    if 'Age' not in df.columns and 'Age_yrs' in df.columns:\n",
    "        df.rename(columns={'Age_yrs': 'Age'}, inplace=True)\n",
    "    elif 'Age' in df.columns and 'Age_yrs' in df.columns:\n",
    "        df['Age'] = df['Age'].fillna(df['Age_yrs'])\n",
    "        df.drop(columns=['Age_yrs'], inplace=True)\n",
    "\n",
    "    # 4. Merge PCOS diagnosis columns\n",
    "    if 'PCOS_Diagnosis' in df.columns:\n",
    "        df.rename(columns={'PCOS_Diagnosis': 'PCOS_Y_N'}, inplace=True)\n",
    "\n",
    "    # 5. Handle missing values\n",
    "    if 'Marraige_Status_Yrs' in df.columns:\n",
    "        df.loc[:, 'Marraige_Status_Yrs'] = df['Marraige_Status_Yrs'].fillna(df['Marraige_Status_Yrs'].median())\n",
    "\n",
    "    if 'Fast_food_Y_N' not in df.columns and 'Fast_food_YN' in df.columns:\n",
    "        df.rename(columns={'Fast_food_YN': 'Fast_food_Y_N'}, inplace=True)\n",
    "    if 'Fast_food_Y_N' in df.columns:\n",
    "        df.loc[:, 'Fast_food_Y_N'] = df['Fast_food_Y_N'].fillna(df['Fast_food_Y_N'].mode()[0])\n",
    "\n",
    "    # 6. Convert to numeric and fill missing values\n",
    "    if 'II_beta_HCG' not in df.columns and 'II_beta_HCGmIU_mL' in df.columns:\n",
    "        df.rename(columns={'II_beta_HCGmIU_mL': 'II_beta_HCG'}, inplace=True)\n",
    "    if 'II_beta_HCG' in df.columns:\n",
    "        df.loc[:, 'II_beta_HCG'] = pd.to_numeric(df['II_beta_HCG'], errors='coerce')\n",
    "        df['II_beta_HCG'] = df['II_beta_HCG'].astype(float)\n",
    "        df.loc[:, 'II_beta_HCG'] = df['II_beta_HCG'].fillna(df['II_beta_HCG'].median())\n",
    "\n",
    "    if 'AMHng_mL' in df.columns:\n",
    "        df.loc[:, 'AMHng_mL'] = pd.to_numeric(df['AMHng_mL'], errors='coerce')\n",
    "        df['AMHng_mL'] = df['AMHng_mL'].astype(float)\n",
    "        df.loc[:, 'AMHng_mL'] = df['AMHng_mL'].fillna(df['AMHng_mL'].median())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9783e46b-bfee-4ba4-96d8-1c2241513935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing\n",
    "original_clean = preprocess(original)\n",
    "new_clean = preprocess(new)\n",
    "\n",
    "# Ensure consistent columns across both\n",
    "all_columns = list(set(original_clean.columns).union(set(new_clean.columns)))\n",
    "\n",
    "# Align both dataframes to same columns, fill missing with NaN\n",
    "original_aligned = original_clean.reindex(columns=all_columns)\n",
    "new_aligned = new_clean.reindex(columns=all_columns)\n",
    "\n",
    "# Concatenate datasets\n",
    "combined_df = pd.concat([original_aligned, new_aligned], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26bdf1a3-5c90-4ba1-b3f9-38b2694f3892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "# X = combined_df.drop(columns=['PCOS_Y_N'])\n",
    "X = combined_df.drop(columns=['PCOS_Y_N'])\n",
    "y = combined_df['PCOS_Y_N']\n",
    "\n",
    "# Initialize KNNImputer (e.g., with 5 nearest neighbors)\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "X = pd.DataFrame(knn_imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Sanitize feature names\n",
    "X.columns = [str(col).replace(' ', '_')\n",
    "                        .replace('\"', '')\n",
    "                        .replace(\"'\", '')\n",
    "                        .replace('[', '')\n",
    "                        .replace(']', '')\n",
    "                        .replace('{', '')\n",
    "                        .replace('}', '')\n",
    "                        .replace(':', '')\n",
    "                        .replace(',', '')\n",
    "                        for col in X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caaf795e-75c2-4ba5-85d0-59a5d1c8a6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(X_scaled, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5791e93-16c2-486c-9d03-954ec9896528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BorutaPy(estimator=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                                 colsample_bylevel=None, colsample_bynode=None,\n",
       "                                 colsample_bytree=None, device=None,\n",
       "                                 early_stopping_rounds=None,\n",
       "                                 enable_categorical=False, eval_metric=None,\n",
       "                                 feature_types=None, feature_weights=None,\n",
       "                                 gamma=None, grow_policy=None,\n",
       "                                 importance_type=None,\n",
       "                                 interaction_constraints=None,\n",
       "                                 learning_rate=None, max_bin=None,\n",
       "                                 max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                                 max_delta_step=None, max_depth=None,\n",
       "                                 max_leaves=None, min_child_weight=None,\n",
       "                                 missing=nan, monotone_constraints=None,\n",
       "                                 multi_strategy=None, n_estimators=1000,\n",
       "                                 n_jobs=None, num_parallel_tree=None, ...),\n",
       "         random_state=RandomState(MT19937) at 0x11005D440)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>BorutaPy</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>BorutaPy(estimator=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                                 colsample_bylevel=None, colsample_bynode=None,\n",
       "                                 colsample_bytree=None, device=None,\n",
       "                                 early_stopping_rounds=None,\n",
       "                                 enable_categorical=False, eval_metric=None,\n",
       "                                 feature_types=None, feature_weights=None,\n",
       "                                 gamma=None, grow_policy=None,\n",
       "                                 importance_type=None,\n",
       "                                 interaction_constraints=None,\n",
       "                                 learning_rate=None, max_bin=None,\n",
       "                                 max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                                 max_delta_step=None, max_depth=None,\n",
       "                                 max_leaves=None, min_child_weight=None,\n",
       "                                 missing=nan, monotone_constraints=None,\n",
       "                                 multi_strategy=None, n_estimators=1000,\n",
       "                                 n_jobs=None, num_parallel_tree=None, ...),\n",
       "         random_state=RandomState(MT19937) at 0x11005D440)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>estimator: XGBClassifier</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              feature_weights=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=1000,\n",
       "              n_jobs=None, num_parallel_tree=None, ...)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              feature_weights=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=1000,\n",
       "              n_jobs=None, num_parallel_tree=None, ...)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BorutaPy(estimator=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                                 colsample_bylevel=None, colsample_bynode=None,\n",
       "                                 colsample_bytree=None, device=None,\n",
       "                                 early_stopping_rounds=None,\n",
       "                                 enable_categorical=False, eval_metric=None,\n",
       "                                 feature_types=None, feature_weights=None,\n",
       "                                 gamma=None, grow_policy=None,\n",
       "                                 importance_type=None,\n",
       "                                 interaction_constraints=None,\n",
       "                                 learning_rate=None, max_bin=None,\n",
       "                                 max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                                 max_delta_step=None, max_depth=None,\n",
       "                                 max_leaves=None, min_child_weight=None,\n",
       "                                 missing=nan, monotone_constraints=None,\n",
       "                                 multi_strategy=None, n_estimators=1000,\n",
       "                                 n_jobs=None, num_parallel_tree=None, ...),\n",
       "         random_state=RandomState(MT19937) at 0x11005D440)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBClassifier()\n",
    "boruta_selector = BorutaPy(model)\n",
    "boruta_selector.fit(X.values, y.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbc54fa1-8221-4f0f-aa26-40482350c9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: ['Menstrual_Irregularity', 'BMI', 'CycleR_I', 'Skin_darkening_Y_N', 'Follicle_No_R', 'Weight_gainY_N', 'PimplesY_N', 'Cycle_lengthdays', 'hair_growthY_N', 'Follicle_No_L', 'Testosterone_Levelng_dL', 'Antral_Follicle_Count']\n"
     ]
    }
   ],
   "source": [
    "# Selected features\n",
    "selected_features = X.columns[boruta_selector.support_].tolist()\n",
    "print(\"Selected Features:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b25ba6d0-e37d-4ee6-9f25-74cbbaa46be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Menstrual_Irregularity</th>\n",
       "      <th>BMI</th>\n",
       "      <th>CycleR_I</th>\n",
       "      <th>Skin_darkening_Y_N</th>\n",
       "      <th>Follicle_No_R</th>\n",
       "      <th>Weight_gainY_N</th>\n",
       "      <th>PimplesY_N</th>\n",
       "      <th>Cycle_lengthdays</th>\n",
       "      <th>hair_growthY_N</th>\n",
       "      <th>Follicle_No_L</th>\n",
       "      <th>Testosterone_Levelng_dL</th>\n",
       "      <th>Antral_Follicle_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.656038</td>\n",
       "      <td>-1.339000</td>\n",
       "      <td>-0.959987</td>\n",
       "      <td>-0.982136</td>\n",
       "      <td>-1.121520</td>\n",
       "      <td>-1.086229</td>\n",
       "      <td>-1.401411</td>\n",
       "      <td>0.119674</td>\n",
       "      <td>-0.946588</td>\n",
       "      <td>-1.005664</td>\n",
       "      <td>0.920402</td>\n",
       "      <td>-0.416886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.744823</td>\n",
       "      <td>-0.159445</td>\n",
       "      <td>-0.959987</td>\n",
       "      <td>-0.982136</td>\n",
       "      <td>-0.495882</td>\n",
       "      <td>-1.086229</td>\n",
       "      <td>-1.401411</td>\n",
       "      <td>0.119674</td>\n",
       "      <td>-0.946588</td>\n",
       "      <td>-1.005664</td>\n",
       "      <td>-0.683750</td>\n",
       "      <td>-0.551277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.122992</td>\n",
       "      <td>-0.075192</td>\n",
       "      <td>-0.959987</td>\n",
       "      <td>-0.982136</td>\n",
       "      <td>2.632309</td>\n",
       "      <td>-1.086229</td>\n",
       "      <td>1.414935</td>\n",
       "      <td>0.119674</td>\n",
       "      <td>-0.946588</td>\n",
       "      <td>2.292051</td>\n",
       "      <td>0.412065</td>\n",
       "      <td>0.154275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.656038</td>\n",
       "      <td>0.851601</td>\n",
       "      <td>-0.959987</td>\n",
       "      <td>-0.982136</td>\n",
       "      <td>-1.434340</td>\n",
       "      <td>-1.086229</td>\n",
       "      <td>-1.401411</td>\n",
       "      <td>0.119674</td>\n",
       "      <td>-0.946588</td>\n",
       "      <td>-1.335436</td>\n",
       "      <td>-0.414870</td>\n",
       "      <td>-0.215300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.277869</td>\n",
       "      <td>-1.170492</td>\n",
       "      <td>-0.959987</td>\n",
       "      <td>-0.982136</td>\n",
       "      <td>-0.808701</td>\n",
       "      <td>-1.086229</td>\n",
       "      <td>-1.401411</td>\n",
       "      <td>0.119674</td>\n",
       "      <td>-0.946588</td>\n",
       "      <td>-1.005664</td>\n",
       "      <td>-0.029305</td>\n",
       "      <td>-0.248898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>1.122992</td>\n",
       "      <td>-1.528571</td>\n",
       "      <td>-0.959987</td>\n",
       "      <td>0.200726</td>\n",
       "      <td>-0.370755</td>\n",
       "      <td>-1.086229</td>\n",
       "      <td>-1.401411</td>\n",
       "      <td>0.119674</td>\n",
       "      <td>-0.312374</td>\n",
       "      <td>-0.675893</td>\n",
       "      <td>1.824450</td>\n",
       "      <td>0.927022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>1.122992</td>\n",
       "      <td>0.683094</td>\n",
       "      <td>-0.358140</td>\n",
       "      <td>-0.390705</td>\n",
       "      <td>-0.183063</td>\n",
       "      <td>0.455096</td>\n",
       "      <td>-0.274872</td>\n",
       "      <td>-0.074859</td>\n",
       "      <td>-0.312374</td>\n",
       "      <td>0.247468</td>\n",
       "      <td>-1.584755</td>\n",
       "      <td>-1.760795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>-1.211777</td>\n",
       "      <td>0.556713</td>\n",
       "      <td>-0.358140</td>\n",
       "      <td>-0.982136</td>\n",
       "      <td>-0.370755</td>\n",
       "      <td>-0.058679</td>\n",
       "      <td>-0.838142</td>\n",
       "      <td>0.508740</td>\n",
       "      <td>-0.312374</td>\n",
       "      <td>-0.148258</td>\n",
       "      <td>-1.386899</td>\n",
       "      <td>1.766965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>-1.211777</td>\n",
       "      <td>0.346078</td>\n",
       "      <td>0.845554</td>\n",
       "      <td>0.792156</td>\n",
       "      <td>-0.808701</td>\n",
       "      <td>1.482646</td>\n",
       "      <td>-0.274872</td>\n",
       "      <td>0.119674</td>\n",
       "      <td>-0.312374</td>\n",
       "      <td>-0.346121</td>\n",
       "      <td>1.819377</td>\n",
       "      <td>-1.424818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>1.122992</td>\n",
       "      <td>-0.791350</td>\n",
       "      <td>0.243707</td>\n",
       "      <td>-0.390705</td>\n",
       "      <td>0.630267</td>\n",
       "      <td>-0.058679</td>\n",
       "      <td>0.288397</td>\n",
       "      <td>-0.463925</td>\n",
       "      <td>0.956054</td>\n",
       "      <td>-0.082304</td>\n",
       "      <td>0.972149</td>\n",
       "      <td>-1.760795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1541 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Menstrual_Irregularity       BMI  CycleR_I  Skin_darkening_Y_N  \\\n",
       "0                   0.656038 -1.339000 -0.959987           -0.982136   \n",
       "1                  -0.744823 -0.159445 -0.959987           -0.982136   \n",
       "2                   1.122992 -0.075192 -0.959987           -0.982136   \n",
       "3                   0.656038  0.851601 -0.959987           -0.982136   \n",
       "4                  -0.277869 -1.170492 -0.959987           -0.982136   \n",
       "...                      ...       ...       ...                 ...   \n",
       "1536                1.122992 -1.528571 -0.959987            0.200726   \n",
       "1537                1.122992  0.683094 -0.358140           -0.390705   \n",
       "1538               -1.211777  0.556713 -0.358140           -0.982136   \n",
       "1539               -1.211777  0.346078  0.845554            0.792156   \n",
       "1540                1.122992 -0.791350  0.243707           -0.390705   \n",
       "\n",
       "      Follicle_No_R  Weight_gainY_N  PimplesY_N  Cycle_lengthdays  \\\n",
       "0         -1.121520       -1.086229   -1.401411          0.119674   \n",
       "1         -0.495882       -1.086229   -1.401411          0.119674   \n",
       "2          2.632309       -1.086229    1.414935          0.119674   \n",
       "3         -1.434340       -1.086229   -1.401411          0.119674   \n",
       "4         -0.808701       -1.086229   -1.401411          0.119674   \n",
       "...             ...             ...         ...               ...   \n",
       "1536      -0.370755       -1.086229   -1.401411          0.119674   \n",
       "1537      -0.183063        0.455096   -0.274872         -0.074859   \n",
       "1538      -0.370755       -0.058679   -0.838142          0.508740   \n",
       "1539      -0.808701        1.482646   -0.274872          0.119674   \n",
       "1540       0.630267       -0.058679    0.288397         -0.463925   \n",
       "\n",
       "      hair_growthY_N  Follicle_No_L  Testosterone_Levelng_dL  \\\n",
       "0          -0.946588      -1.005664                 0.920402   \n",
       "1          -0.946588      -1.005664                -0.683750   \n",
       "2          -0.946588       2.292051                 0.412065   \n",
       "3          -0.946588      -1.335436                -0.414870   \n",
       "4          -0.946588      -1.005664                -0.029305   \n",
       "...              ...            ...                      ...   \n",
       "1536       -0.312374      -0.675893                 1.824450   \n",
       "1537       -0.312374       0.247468                -1.584755   \n",
       "1538       -0.312374      -0.148258                -1.386899   \n",
       "1539       -0.312374      -0.346121                 1.819377   \n",
       "1540        0.956054      -0.082304                 0.972149   \n",
       "\n",
       "      Antral_Follicle_Count  \n",
       "0                 -0.416886  \n",
       "1                 -0.551277  \n",
       "2                  0.154275  \n",
       "3                 -0.215300  \n",
       "4                 -0.248898  \n",
       "...                     ...  \n",
       "1536               0.927022  \n",
       "1537              -1.760795  \n",
       "1538               1.766965  \n",
       "1539              -1.424818  \n",
       "1540              -1.760795  \n",
       "\n",
       "[1541 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X[selected_features]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4da0238a-c924-41db-9a99-ca17ccaefcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.15, stratify=y, shuffle=True, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df956112-bafc-47fc-8869-e2fa71eacc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    param = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-3, 10.0, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-3, 10.0, log=True),\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"random_state\": 8,\n",
    "        \"use_label_encoder\": False,\n",
    "    }\n",
    "\n",
    "    train_pool = xgb.DMatrix(x_train, y_train)\n",
    "    valid_pool = xgb.DMatrix(x_test, y_test)\n",
    "    \n",
    "    # Train model\n",
    "    model = xgb.XGBClassifier(**param)\n",
    "    model.fit(x_train, y_train,\n",
    "              eval_set=[(x_test, y_test)],\n",
    "              verbose=False)\n",
    "\n",
    "    # Predict\n",
    "    preds = model.predict(x_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "\n",
    "    return 1.0 - acc  # Optuna minimizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5b8a2c6-8681-4607-8045-3d20f3fc62a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 20:50:54,172] A new study created in memory with name: no-name-d894acee-0616-4298-819f-5b0340042281\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:50:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:50:54,647] Trial 0 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.07801618083421254, 'n_estimators': 434, 'max_depth': 7, 'subsample': 0.6643559720679422, 'colsample_bytree': 0.8302036318968138, 'reg_alpha': 0.02186851181928189, 'reg_lambda': 0.0010589361714544233}. Best is trial 0 with value: 0.03879310344827591.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:50:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:50:54,901] Trial 1 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.1481011540340735, 'n_estimators': 215, 'max_depth': 11, 'subsample': 0.6844347083520116, 'colsample_bytree': 0.8694194558740401, 'reg_alpha': 1.0839501422177773, 'reg_lambda': 0.0010875781880839465}. Best is trial 0 with value: 0.03879310344827591.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:50:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:50:56,232] Trial 2 finished with value: 0.051724137931034475 and parameters: {'learning_rate': 0.01375412134284642, 'n_estimators': 786, 'max_depth': 11, 'subsample': 0.9454414525033774, 'colsample_bytree': 0.7095438947527655, 'reg_alpha': 0.004064536515426466, 'reg_lambda': 0.837068948161784}. Best is trial 0 with value: 0.03879310344827591.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:50:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:50:56,679] Trial 3 finished with value: 0.0431034482758621 and parameters: {'learning_rate': 0.06286418837788513, 'n_estimators': 330, 'max_depth': 12, 'subsample': 0.7966058499828284, 'colsample_bytree': 0.8811896950625001, 'reg_alpha': 0.0033495335117681305, 'reg_lambda': 0.23223637718526255}. Best is trial 0 with value: 0.03879310344827591.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:50:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:50:57,260] Trial 4 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.022001403982896683, 'n_estimators': 601, 'max_depth': 5, 'subsample': 0.629731792225122, 'colsample_bytree': 0.875812018934792, 'reg_alpha': 3.000692181977428, 'reg_lambda': 0.0021580605881325646}. Best is trial 4 with value: 0.030172413793103425.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:50:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:50:58,185] Trial 5 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.03270016281520333, 'n_estimators': 718, 'max_depth': 10, 'subsample': 0.7742040715321588, 'colsample_bytree': 0.979852393631608, 'reg_alpha': 0.1735489760072626, 'reg_lambda': 0.21308084908674835}. Best is trial 4 with value: 0.030172413793103425.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:50:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:50:58,592] Trial 6 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.21072784082379348, 'n_estimators': 931, 'max_depth': 8, 'subsample': 0.9246200111504804, 'colsample_bytree': 0.6928522037409764, 'reg_alpha': 8.20349425613628, 'reg_lambda': 8.426541252391143}. Best is trial 4 with value: 0.030172413793103425.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:50:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:50:58,947] Trial 7 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.04358261092464663, 'n_estimators': 252, 'max_depth': 12, 'subsample': 0.8777193106937922, 'colsample_bytree': 0.9825386786615795, 'reg_alpha': 4.0195876289646435, 'reg_lambda': 1.4728055259924953}. Best is trial 4 with value: 0.030172413793103425.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:50:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:50:59,286] Trial 8 finished with value: 0.051724137931034475 and parameters: {'learning_rate': 0.051119754140285904, 'n_estimators': 177, 'max_depth': 11, 'subsample': 0.9505991510418276, 'colsample_bytree': 0.6039768437966682, 'reg_alpha': 0.1336534866957097, 'reg_lambda': 2.8516038077372423}. Best is trial 4 with value: 0.030172413793103425.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:50:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:50:59,455] Trial 9 finished with value: 0.0431034482758621 and parameters: {'learning_rate': 0.05722309790826331, 'n_estimators': 159, 'max_depth': 5, 'subsample': 0.8906997311062128, 'colsample_bytree': 0.7251377352385245, 'reg_alpha': 1.2945261951511329, 'reg_lambda': 0.017154391271181485}. Best is trial 4 with value: 0.030172413793103425.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:50:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:50:59,877] Trial 10 finished with value: 0.0431034482758621 and parameters: {'learning_rate': 0.012851369399117627, 'n_estimators': 574, 'max_depth': 3, 'subsample': 0.6328289122689437, 'colsample_bytree': 0.9221185040557665, 'reg_alpha': 0.6412306398669816, 'reg_lambda': 0.014638342383662416}. Best is trial 4 with value: 0.030172413793103425.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:50:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:51:00,386] Trial 11 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.02581006014290097, 'n_estimators': 528, 'max_depth': 6, 'subsample': 0.85984114371372, 'colsample_bytree': 0.9777024401731814, 'reg_alpha': 8.240127888058227, 'reg_lambda': 0.0203488997370492}. Best is trial 4 with value: 0.030172413793103425.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:51:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:51:00,846] Trial 12 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.023257692907959367, 'n_estimators': 642, 'max_depth': 3, 'subsample': 0.7479653182919385, 'colsample_bytree': 0.9307270288121409, 'reg_alpha': 2.6909239800509694, 'reg_lambda': 1.2112553570108198}. Best is trial 4 with value: 0.030172413793103425.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:51:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:51:01,365] Trial 13 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.0316880407511911, 'n_estimators': 362, 'max_depth': 8, 'subsample': 0.6005459530656375, 'colsample_bytree': 0.7965693738439804, 'reg_alpha': 0.37086951933448165, 'reg_lambda': 0.005396765944432651}. Best is trial 4 with value: 0.030172413793103425.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:51:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:51:01,768] Trial 14 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.10841987358498228, 'n_estimators': 470, 'max_depth': 4, 'subsample': 0.847254543901712, 'colsample_bytree': 0.9977150103433324, 'reg_alpha': 0.031245588068489642, 'reg_lambda': 0.079957713682551}. Best is trial 14 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:51:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:51:02,197] Trial 15 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.10947945968723284, 'n_estimators': 453, 'max_depth': 5, 'subsample': 0.7115082613129202, 'colsample_bytree': 0.7864774540236006, 'reg_alpha': 0.021948753672842342, 'reg_lambda': 0.07422703281604875}. Best is trial 14 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:51:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:51:02,600] Trial 16 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.10657957383557841, 'n_estimators': 454, 'max_depth': 4, 'subsample': 0.7348672631318776, 'colsample_bytree': 0.7709191758822367, 'reg_alpha': 0.03242059042629364, 'reg_lambda': 0.06674529848746674}. Best is trial 14 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:51:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:51:02,992] Trial 17 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.23579209785871783, 'n_estimators': 448, 'max_depth': 5, 'subsample': 0.8516011038777809, 'colsample_bytree': 0.6424759505045171, 'reg_alpha': 0.015519749512314673, 'reg_lambda': 0.06499368984493047}. Best is trial 14 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:51:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:51:03,729] Trial 18 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.12563222322920525, 'n_estimators': 843, 'max_depth': 7, 'subsample': 0.7173025529940998, 'colsample_bytree': 0.7548039555129968, 'reg_alpha': 0.0010379547886502326, 'reg_lambda': 0.24211499007658915}. Best is trial 14 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:51:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:51:04,023] Trial 19 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.08687149686951974, 'n_estimators': 326, 'max_depth': 4, 'subsample': 0.826918973407722, 'colsample_bytree': 0.8323768282137952, 'reg_alpha': 0.055859526617841784, 'reg_lambda': 0.04007948812211581}. Best is trial 14 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:51:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:51:04,618] Trial 20 finished with value: 0.0431034482758621 and parameters: {'learning_rate': 0.16469099436352985, 'n_estimators': 682, 'max_depth': 6, 'subsample': 0.7764523734421725, 'colsample_bytree': 0.6676217256857251, 'reg_alpha': 0.0072885953211197455, 'reg_lambda': 0.005565005345943128}. Best is trial 14 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:51:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:51:05,151] Trial 21 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.09164444756665116, 'n_estimators': 556, 'max_depth': 5, 'subsample': 0.6727747671772787, 'colsample_bytree': 0.9126979708305357, 'reg_alpha': 0.0683428226239135, 'reg_lambda': 0.004531790012842951}. Best is trial 14 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:51:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:51:05,672] Trial 22 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.01883744127902824, 'n_estimators': 587, 'max_depth': 4, 'subsample': 0.605273957202465, 'colsample_bytree': 0.8486916170424299, 'reg_alpha': 0.01141831611090933, 'reg_lambda': 0.14236139940895118}. Best is trial 14 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:51:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:51:06,133] Trial 23 finished with value: 0.02155172413793105 and parameters: {'learning_rate': 0.17763404020550788, 'n_estimators': 490, 'max_depth': 6, 'subsample': 0.6969951035211401, 'colsample_bytree': 0.7920213967702483, 'reg_alpha': 0.034912035085883496, 'reg_lambda': 0.0336597173916792}. Best is trial 23 with value: 0.02155172413793105.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:51:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:51:06,498] Trial 24 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.2982941962613191, 'n_estimators': 396, 'max_depth': 6, 'subsample': 0.6886726466197068, 'colsample_bytree': 0.7923876020215421, 'reg_alpha': 0.037105822818058846, 'reg_lambda': 0.5568231540472781}. Best is trial 23 with value: 0.02155172413793105.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:51:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:51:06,861] Trial 25 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.16268287092959974, 'n_estimators': 487, 'max_depth': 3, 'subsample': 0.8199382120733184, 'colsample_bytree': 0.7544234355492614, 'reg_alpha': 0.16576781743169783, 'reg_lambda': 0.03402785414870691}. Best is trial 23 with value: 0.02155172413793105.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:51:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:51:07,031] Trial 26 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.11840644282182801, 'n_estimators': 101, 'max_depth': 9, 'subsample': 0.7153024762697922, 'colsample_bytree': 0.8126666796736319, 'reg_alpha': 0.007553408878708629, 'reg_lambda': 0.10608587386007833}. Best is trial 23 with value: 0.02155172413793105.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:51:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:51:07,483] Trial 27 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.20605334128300287, 'n_estimators': 505, 'max_depth': 6, 'subsample': 0.7504304251504833, 'colsample_bytree': 0.7284128725836121, 'reg_alpha': 0.07726202767799376, 'reg_lambda': 0.01077768047029519}. Best is trial 23 with value: 0.02155172413793105.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:51:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:51:07,775] Trial 28 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.0706675540938401, 'n_estimators': 293, 'max_depth': 4, 'subsample': 0.784183787499755, 'colsample_bytree': 0.7744665557224168, 'reg_alpha': 0.024968932106341716, 'reg_lambda': 0.41631354102235235}. Best is trial 23 with value: 0.02155172413793105.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:51:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:51:08,142] Trial 29 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.2987684319431933, 'n_estimators': 390, 'max_depth': 7, 'subsample': 0.7104930939513275, 'colsample_bytree': 0.8405259618387785, 'reg_alpha': 0.30847683350183963, 'reg_lambda': 0.03678877614103022}. Best is trial 23 with value: 0.02155172413793105.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:51:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:51:08,615] Trial 30 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.09311797773581285, 'n_estimators': 413, 'max_depth': 7, 'subsample': 0.6491364370733625, 'colsample_bytree': 0.8137914187794486, 'reg_alpha': 0.002395192542987604, 'reg_lambda': 0.05744111943854867}. Best is trial 23 with value: 0.02155172413793105.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:51:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:51:08,993] Trial 31 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.26777762714633463, 'n_estimators': 407, 'max_depth': 6, 'subsample': 0.6890666222858005, 'colsample_bytree': 0.801665477143255, 'reg_alpha': 0.03796912752102115, 'reg_lambda': 0.4614443747010751}. Best is trial 23 with value: 0.02155172413793105.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:51:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:51:09,455] Trial 32 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.18055844270810303, 'n_estimators': 480, 'max_depth': 5, 'subsample': 0.684792687839578, 'colsample_bytree': 0.7600351263930631, 'reg_alpha': 0.01860887429095514, 'reg_lambda': 0.4473598689219885}. Best is trial 23 with value: 0.02155172413793105.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:51:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:51:09,798] Trial 33 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.1405874080226255, 'n_estimators': 299, 'max_depth': 6, 'subsample': 0.6590726496411122, 'colsample_bytree': 0.7916506157982852, 'reg_alpha': 0.042986320189544576, 'reg_lambda': 0.10184033969730787}. Best is trial 23 with value: 0.02155172413793105.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:51:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:51:10,149] Trial 34 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.2414638741604413, 'n_estimators': 358, 'max_depth': 7, 'subsample': 0.6941533128707623, 'colsample_bytree': 0.8984302832471349, 'reg_alpha': 0.009649440050481746, 'reg_lambda': 0.1611458661491151}. Best is trial 23 with value: 0.02155172413793105.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:51:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:51:10,414] Trial 35 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.1964241788137598, 'n_estimators': 256, 'max_depth': 4, 'subsample': 0.9860822325226876, 'colsample_bytree': 0.8594187113792984, 'reg_alpha': 0.09932851856650705, 'reg_lambda': 0.02523582008261625}. Best is trial 23 with value: 0.02155172413793105.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:51:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:51:11,053] Trial 36 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.13963720380466704, 'n_estimators': 628, 'max_depth': 5, 'subsample': 0.754814840415865, 'colsample_bytree': 0.7391231448014589, 'reg_alpha': 0.005280387094772991, 'reg_lambda': 2.4358774735829845}. Best is trial 23 with value: 0.02155172413793105.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:51:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:51:11,548] Trial 37 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.2994616179040518, 'n_estimators': 528, 'max_depth': 8, 'subsample': 0.8016461444571484, 'colsample_bytree': 0.7008567279817303, 'reg_alpha': 0.022257497130010413, 'reg_lambda': 0.7392859132172418}. Best is trial 23 with value: 0.02155172413793105.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:51:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:51:12,269] Trial 38 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.07293827909781966, 'n_estimators': 712, 'max_depth': 6, 'subsample': 0.6412387931496323, 'colsample_bytree': 0.7836323967145816, 'reg_alpha': 0.012848716251740791, 'reg_lambda': 0.28535196221164255}. Best is trial 23 with value: 0.02155172413793105.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:51:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:51:12,766] Trial 39 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.10318548011475934, 'n_estimators': 453, 'max_depth': 9, 'subsample': 0.7263632878843322, 'colsample_bytree': 0.9524352531326817, 'reg_alpha': 0.0020538567546935825, 'reg_lambda': 0.01009417066917087}. Best is trial 23 with value: 0.02155172413793105.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:51:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:51:13,133] Trial 40 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.22765087728935485, 'n_estimators': 369, 'max_depth': 5, 'subsample': 0.9028746734721254, 'colsample_bytree': 0.8770835437222336, 'reg_alpha': 0.22108696066287864, 'reg_lambda': 0.07255648077262308}. Best is trial 23 with value: 0.02155172413793105.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:51:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:51:13,618] Trial 41 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.19535581896223092, 'n_estimators': 508, 'max_depth': 6, 'subsample': 0.74815796998566, 'colsample_bytree': 0.7351703325177213, 'reg_alpha': 0.068509483115918, 'reg_lambda': 0.008522061110252619}. Best is trial 23 with value: 0.02155172413793105.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:51:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:51:14,105] Trial 42 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.15529159019197025, 'n_estimators': 491, 'max_depth': 6, 'subsample': 0.7029524773790523, 'colsample_bytree': 0.6802602438841668, 'reg_alpha': 0.08840327234999741, 'reg_lambda': 0.0017595477172540398}. Best is trial 23 with value: 0.02155172413793105.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:51:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:51:14,661] Trial 43 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.12481987852502971, 'n_estimators': 435, 'max_depth': 7, 'subsample': 0.7593686836718947, 'colsample_bytree': 0.8156282705404961, 'reg_alpha': 0.028952738903551573, 'reg_lambda': 6.587534321639247}. Best is trial 23 with value: 0.02155172413793105.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:51:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:51:15,165] Trial 44 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.183276525111076, 'n_estimators': 545, 'max_depth': 5, 'subsample': 0.8230759700450051, 'colsample_bytree': 0.7135568927057369, 'reg_alpha': 0.04342101728808264, 'reg_lambda': 0.01059477249022255}. Best is trial 23 with value: 0.02155172413793105.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:51:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:51:15,670] Trial 45 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.2570022186551506, 'n_estimators': 613, 'max_depth': 4, 'subsample': 0.6670507323139997, 'colsample_bytree': 0.7341334365153005, 'reg_alpha': 0.02055226023739734, 'reg_lambda': 0.021603007730881855}. Best is trial 23 with value: 0.02155172413793105.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:51:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:51:16,699] Trial 46 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.043639696365278174, 'n_estimators': 989, 'max_depth': 6, 'subsample': 0.7341549009425861, 'colsample_bytree': 0.8284027543316966, 'reg_alpha': 0.12858667974545, 'reg_lambda': 0.04749423403323109}. Best is trial 23 with value: 0.02155172413793105.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:51:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:51:16,980] Trial 47 finished with value: 0.051724137931034475 and parameters: {'learning_rate': 0.010163196666789616, 'n_estimators': 334, 'max_depth': 3, 'subsample': 0.7977702269698087, 'colsample_bytree': 0.6418212422038607, 'reg_alpha': 0.0597552203143855, 'reg_lambda': 0.13098962235586234}. Best is trial 23 with value: 0.02155172413793105.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:51:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:51:17,532] Trial 48 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.21708587813751104, 'n_estimators': 662, 'max_depth': 5, 'subsample': 0.8507813485707345, 'colsample_bytree': 0.7136624729601699, 'reg_alpha': 0.5545739241723403, 'reg_lambda': 0.014058681248322163}. Best is trial 23 with value: 0.02155172413793105.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:51:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:51:17,888] Trial 49 finished with value: 0.0431034482758621 and parameters: {'learning_rate': 0.057489340111429726, 'n_estimators': 220, 'max_depth': 8, 'subsample': 0.7681381916608266, 'colsample_bytree': 0.7622454698076773, 'reg_alpha': 0.09729768300186992, 'reg_lambda': 0.0036461985596920508}. Best is trial 23 with value: 0.02155172413793105.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:\n",
      "{'learning_rate': 0.17763404020550788, 'n_estimators': 490, 'max_depth': 6, 'subsample': 0.6969951035211401, 'colsample_bytree': 0.7920213967702483, 'reg_alpha': 0.034912035085883496, 'reg_lambda': 0.0336597173916792}\n",
      "Best accuracy:\n",
      "0.978448275862069\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')  # Because we return 1 - accuracy\n",
    "study.optimize(objective, n_trials=50)  # Try 50 combinations (or more!)\n",
    "\n",
    "print(\"Best hyperparameters:\")\n",
    "print(study.best_params)\n",
    "\n",
    "print(\"Best accuracy:\")\n",
    "print(1 - study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddffb71f-341f-49af-8a9a-5a2b2c60def1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final evaluation on test set:\n",
      "Accuracy: 96.12\n",
      "Precision: 94.44\n",
      "Recall: 89.47\n",
      "F1 Score: 91.89\n"
     ]
    }
   ],
   "source": [
    "# Get the data\n",
    "best_model = xgb.XGBClassifier(**study.best_params)\n",
    "best_model.fit(x_train, y_train,\n",
    "          eval_set=[(x_test, y_test)],\n",
    "          verbose=False)\n",
    "\n",
    "# Predict\n",
    "preds = best_model.predict(x_test)\n",
    "\n",
    "# Compute final scores\n",
    "acc = accuracy_score(y_test, preds)\n",
    "precision = precision_score(y_test, preds, average='binary')\n",
    "recall = recall_score(y_test, preds, average='binary')\n",
    "f1 = f1_score(y_test, preds, average='binary')\n",
    "\n",
    "print(\"\\nFinal evaluation on test set:\")\n",
    "print(f\"Accuracy: {acc * 100:.2f}\")\n",
    "print(f\"Precision: {precision * 100:.2f}\")\n",
    "print(f\"Recall: {recall * 100:.2f}\")\n",
    "print(f\"F1 Score: {f1 * 100:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b5ec62-1390-4aab-949e-fc9751037d9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
