{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5677d290-4f65-45a3-8b6b-b760f2e46260",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "import joblib\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91fdd9dd-2ea7-4224-9d76-7ed3237a070f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load both datasets\n",
    "original = pd.read_csv(\"PCOS_data.csv\")\n",
    "new = pd.read_csv(\"pcos_dataset.csv\")\n",
    "\n",
    "# Set max columns to show is unlimited\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5cacc0a-036f-49e7-b8ea-2bc2a6206294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df = df.copy()  # avoid SettingWithCopyWarning\n",
    "\n",
    "    # 1. Clean column names\n",
    "    df.columns = df.columns.str.strip() \\\n",
    "                           .str.replace(' ', '_') \\\n",
    "                           .str.replace('(', '') \\\n",
    "                           .str.replace(')', '') \\\n",
    "                           .str.replace('.', '') \\\n",
    "                           .str.replace('-', '_') \\\n",
    "                           .str.replace('/', '_')\n",
    "    df.rename(columns={'II____beta_HCGmIU_mL': 'II_beta_HCG'}, inplace=True)\n",
    "\n",
    "    # 2. Drop irrelevant columns\n",
    "    df.drop(columns=['Sl_No', 'Patient_File_No'], inplace=True, errors='ignore')\n",
    "    df = df.loc[:, ~df.columns.str.startswith('Unnamed')]\n",
    "\n",
    "    # 3. Merge Age columns\n",
    "    if 'Age' not in df.columns and 'Age_yrs' in df.columns:\n",
    "        df.rename(columns={'Age_yrs': 'Age'}, inplace=True)\n",
    "    elif 'Age' in df.columns and 'Age_yrs' in df.columns:\n",
    "        df['Age'] = df['Age'].fillna(df['Age_yrs'])\n",
    "        df.drop(columns=['Age_yrs'], inplace=True)\n",
    "\n",
    "    # 4. Merge PCOS diagnosis columns\n",
    "    if 'PCOS_Diagnosis' in df.columns:\n",
    "        df.rename(columns={'PCOS_Diagnosis': 'PCOS_Y_N'}, inplace=True)\n",
    "\n",
    "    # 5. Handle missing values\n",
    "    if 'Marraige_Status_Yrs' in df.columns:\n",
    "        df.loc[:, 'Marraige_Status_Yrs'] = df['Marraige_Status_Yrs'].fillna(df['Marraige_Status_Yrs'].median())\n",
    "\n",
    "    if 'Fast_food_Y_N' not in df.columns and 'Fast_food_YN' in df.columns:\n",
    "        df.rename(columns={'Fast_food_YN': 'Fast_food_Y_N'}, inplace=True)\n",
    "    if 'Fast_food_Y_N' in df.columns:\n",
    "        df.loc[:, 'Fast_food_Y_N'] = df['Fast_food_Y_N'].fillna(df['Fast_food_Y_N'].mode()[0])\n",
    "\n",
    "    # 6. Convert to numeric and fill missing values\n",
    "    if 'II_beta_HCG' not in df.columns and 'II_beta_HCGmIU_mL' in df.columns:\n",
    "        df.rename(columns={'II_beta_HCGmIU_mL': 'II_beta_HCG'}, inplace=True)\n",
    "    if 'II_beta_HCG' in df.columns:\n",
    "        df.loc[:, 'II_beta_HCG'] = pd.to_numeric(df['II_beta_HCG'], errors='coerce')\n",
    "        df['II_beta_HCG'] = df['II_beta_HCG'].astype(float)\n",
    "        df.loc[:, 'II_beta_HCG'] = df['II_beta_HCG'].fillna(df['II_beta_HCG'].median())\n",
    "\n",
    "    if 'AMHng_mL' in df.columns:\n",
    "        df.loc[:, 'AMHng_mL'] = pd.to_numeric(df['AMHng_mL'], errors='coerce')\n",
    "        df['AMHng_mL'] = df['AMHng_mL'].astype(float)\n",
    "        df.loc[:, 'AMHng_mL'] = df['AMHng_mL'].fillna(df['AMHng_mL'].median())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a1c1d35-21e0-4bdf-9b1d-f04f8f44ce37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing\n",
    "original_clean = preprocess(original)\n",
    "new_clean = preprocess(new)\n",
    "\n",
    "# Ensure consistent columns across both\n",
    "all_columns = list(set(original_clean.columns).union(set(new_clean.columns)))\n",
    "\n",
    "# Align both dataframes to same columns, fill missing with NaN\n",
    "original_aligned = original_clean.reindex(columns=all_columns)\n",
    "new_aligned = new_clean.reindex(columns=all_columns)\n",
    "\n",
    "# Concatenate datasets\n",
    "combined_df = pd.concat([original_aligned, new_aligned], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29c6f538-f61c-4e43-b1ea-628f509e0dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "# X = combined_df.drop(columns=['PCOS_Y_N'])\n",
    "X = combined_df.drop(columns=['PCOS_Y_N'])\n",
    "y = combined_df['PCOS_Y_N']\n",
    "\n",
    "# Initialize KNNImputer (e.g., with 5 nearest neighbors)\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "X = pd.DataFrame(knn_imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Sanitize feature names\n",
    "X.columns = [str(col).replace(' ', '_')\n",
    "                        .replace('\"', '')\n",
    "                        .replace(\"'\", '')\n",
    "                        .replace('[', '')\n",
    "                        .replace(']', '')\n",
    "                        .replace('{', '')\n",
    "                        .replace('}', '')\n",
    "                        .replace(':', '')\n",
    "                        .replace(',', '')\n",
    "                        for col in X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48584812-f34f-4513-9f96-7e810f026ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(X_scaled, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07f2ad47-797c-477d-be9d-1d83f791b44b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              feature_weights=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              feature_weights=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_parallel_tree=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              feature_weights=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model = xgb.XGBClassifier()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "684e37cc-7dce-413b-9c23-7663a9c863ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use SHAP\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6a11de7-c5a4-4900-9df3-c4a1d1e7b10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_df = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': np.abs(shap_values).mean(axis=0)\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Select top N features\n",
    "top_features = shap_df['feature'].head(20).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ec74a0a-299e-43f4-ac6c-be38567fa194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Menstrual_Irregularity',\n",
       " 'BMI',\n",
       " 'Follicle_No_R',\n",
       " 'Testosterone_Levelng_dL',\n",
       " 'Antral_Follicle_Count',\n",
       " 'hair_growthY_N',\n",
       " 'Weight_gainY_N',\n",
       " 'CycleR_I',\n",
       " 'Skin_darkening_Y_N',\n",
       " 'PimplesY_N',\n",
       " 'Follicle_No_L',\n",
       " 'FSH_LH',\n",
       " 'AMHng_mL',\n",
       " 'Avg_F_size_R_mm',\n",
       " 'Weight_Kg',\n",
       " 'RBSmg_dl',\n",
       " 'LHmIU_mL',\n",
       " 'PRLng_mL',\n",
       " 'Age',\n",
       " 'Waistinch']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0d29e92-2a5a-4743-914b-49bdf5ad6d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Menstrual_Irregularity</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Follicle_No_R</th>\n",
       "      <th>Testosterone_Levelng_dL</th>\n",
       "      <th>Antral_Follicle_Count</th>\n",
       "      <th>hair_growthY_N</th>\n",
       "      <th>Weight_gainY_N</th>\n",
       "      <th>CycleR_I</th>\n",
       "      <th>Skin_darkening_Y_N</th>\n",
       "      <th>PimplesY_N</th>\n",
       "      <th>Follicle_No_L</th>\n",
       "      <th>FSH_LH</th>\n",
       "      <th>AMHng_mL</th>\n",
       "      <th>Avg_F_size_R_mm</th>\n",
       "      <th>Weight_Kg</th>\n",
       "      <th>RBSmg_dl</th>\n",
       "      <th>LHmIU_mL</th>\n",
       "      <th>PRLng_mL</th>\n",
       "      <th>Age</th>\n",
       "      <th>Waistinch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.656038</td>\n",
       "      <td>-1.339000</td>\n",
       "      <td>-1.122836</td>\n",
       "      <td>0.920872</td>\n",
       "      <td>-0.416975</td>\n",
       "      <td>-0.946420</td>\n",
       "      <td>-1.086381</td>\n",
       "      <td>-0.959723</td>\n",
       "      <td>-0.988198</td>\n",
       "      <td>-1.399962</td>\n",
       "      <td>-1.006224</td>\n",
       "      <td>-0.112472</td>\n",
       "      <td>-0.911381</td>\n",
       "      <td>1.182416</td>\n",
       "      <td>-1.586049</td>\n",
       "      <td>-0.558343</td>\n",
       "      <td>-0.021249</td>\n",
       "      <td>2.151234</td>\n",
       "      <td>-0.484837</td>\n",
       "      <td>-1.508897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.744823</td>\n",
       "      <td>-0.159445</td>\n",
       "      <td>-0.496464</td>\n",
       "      <td>-0.683807</td>\n",
       "      <td>-0.551388</td>\n",
       "      <td>-0.946420</td>\n",
       "      <td>-1.086381</td>\n",
       "      <td>-0.959723</td>\n",
       "      <td>-0.988198</td>\n",
       "      <td>-1.399962</td>\n",
       "      <td>-1.006224</td>\n",
       "      <td>-0.009411</td>\n",
       "      <td>-1.039082</td>\n",
       "      <td>-0.535430</td>\n",
       "      <td>0.188001</td>\n",
       "      <td>-0.558343</td>\n",
       "      <td>-0.068930</td>\n",
       "      <td>-0.317319</td>\n",
       "      <td>0.577375</td>\n",
       "      <td>-0.851891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.122992</td>\n",
       "      <td>-0.075192</td>\n",
       "      <td>2.635397</td>\n",
       "      <td>0.412368</td>\n",
       "      <td>0.154278</td>\n",
       "      <td>-0.946420</td>\n",
       "      <td>-1.086381</td>\n",
       "      <td>-0.959723</td>\n",
       "      <td>-0.988198</td>\n",
       "      <td>1.419355</td>\n",
       "      <td>2.291223</td>\n",
       "      <td>-0.006070</td>\n",
       "      <td>0.166979</td>\n",
       "      <td>2.041339</td>\n",
       "      <td>0.518461</td>\n",
       "      <td>-1.061131</td>\n",
       "      <td>-0.072796</td>\n",
       "      <td>-1.259643</td>\n",
       "      <td>0.179046</td>\n",
       "      <td>0.462121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.656038</td>\n",
       "      <td>0.851601</td>\n",
       "      <td>-1.436022</td>\n",
       "      <td>-0.414839</td>\n",
       "      <td>-0.215357</td>\n",
       "      <td>-0.946420</td>\n",
       "      <td>-1.086381</td>\n",
       "      <td>-0.959723</td>\n",
       "      <td>-0.988198</td>\n",
       "      <td>-1.399962</td>\n",
       "      <td>-1.335969</td>\n",
       "      <td>-0.080089</td>\n",
       "      <td>-1.112391</td>\n",
       "      <td>-0.535430</td>\n",
       "      <td>0.188001</td>\n",
       "      <td>-1.563919</td>\n",
       "      <td>-0.045550</td>\n",
       "      <td>1.337902</td>\n",
       "      <td>0.710152</td>\n",
       "      <td>0.462121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.277869</td>\n",
       "      <td>-1.170492</td>\n",
       "      <td>-0.809650</td>\n",
       "      <td>-0.029147</td>\n",
       "      <td>-0.248960</td>\n",
       "      <td>-0.946420</td>\n",
       "      <td>-1.086381</td>\n",
       "      <td>-0.959723</td>\n",
       "      <td>-0.988198</td>\n",
       "      <td>-1.399962</td>\n",
       "      <td>-1.006224</td>\n",
       "      <td>-0.054388</td>\n",
       "      <td>-0.866449</td>\n",
       "      <td>-0.535430</td>\n",
       "      <td>-0.942521</td>\n",
       "      <td>-1.061131</td>\n",
       "      <td>-0.072428</td>\n",
       "      <td>0.667345</td>\n",
       "      <td>-0.883166</td>\n",
       "      <td>-1.508897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>1.122992</td>\n",
       "      <td>-1.528571</td>\n",
       "      <td>-0.371189</td>\n",
       "      <td>1.825216</td>\n",
       "      <td>0.927150</td>\n",
       "      <td>-0.312870</td>\n",
       "      <td>-1.086381</td>\n",
       "      <td>-0.959723</td>\n",
       "      <td>0.194570</td>\n",
       "      <td>-1.399962</td>\n",
       "      <td>-0.676480</td>\n",
       "      <td>-0.079266</td>\n",
       "      <td>-0.142813</td>\n",
       "      <td>0.323493</td>\n",
       "      <td>-1.499086</td>\n",
       "      <td>0.070142</td>\n",
       "      <td>-0.046507</td>\n",
       "      <td>0.569667</td>\n",
       "      <td>0.311822</td>\n",
       "      <td>-2.363005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>1.122992</td>\n",
       "      <td>0.683094</td>\n",
       "      <td>-0.183278</td>\n",
       "      <td>-1.585107</td>\n",
       "      <td>-1.761101</td>\n",
       "      <td>-0.312870</td>\n",
       "      <td>0.454214</td>\n",
       "      <td>-0.358286</td>\n",
       "      <td>-0.396814</td>\n",
       "      <td>-0.272235</td>\n",
       "      <td>0.246806</td>\n",
       "      <td>-0.001187</td>\n",
       "      <td>-0.605846</td>\n",
       "      <td>-0.020076</td>\n",
       "      <td>0.196697</td>\n",
       "      <td>-0.068124</td>\n",
       "      <td>-0.054939</td>\n",
       "      <td>-0.988269</td>\n",
       "      <td>1.772363</td>\n",
       "      <td>0.593523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>-1.211777</td>\n",
       "      <td>0.556713</td>\n",
       "      <td>-0.371189</td>\n",
       "      <td>-1.387187</td>\n",
       "      <td>1.767228</td>\n",
       "      <td>-0.312870</td>\n",
       "      <td>-0.059318</td>\n",
       "      <td>-0.358286</td>\n",
       "      <td>-0.988198</td>\n",
       "      <td>-0.836099</td>\n",
       "      <td>-0.148888</td>\n",
       "      <td>-0.072584</td>\n",
       "      <td>-0.150854</td>\n",
       "      <td>0.151708</td>\n",
       "      <td>0.568900</td>\n",
       "      <td>0.849464</td>\n",
       "      <td>-0.064033</td>\n",
       "      <td>-0.542610</td>\n",
       "      <td>0.710152</td>\n",
       "      <td>0.462121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>-1.211777</td>\n",
       "      <td>0.346078</td>\n",
       "      <td>-0.809650</td>\n",
       "      <td>1.820141</td>\n",
       "      <td>-1.425069</td>\n",
       "      <td>-0.312870</td>\n",
       "      <td>1.481277</td>\n",
       "      <td>0.844587</td>\n",
       "      <td>0.785954</td>\n",
       "      <td>-0.272235</td>\n",
       "      <td>-0.346735</td>\n",
       "      <td>-0.127327</td>\n",
       "      <td>0.036914</td>\n",
       "      <td>-0.277753</td>\n",
       "      <td>0.648906</td>\n",
       "      <td>-0.633761</td>\n",
       "      <td>-0.022243</td>\n",
       "      <td>-0.176315</td>\n",
       "      <td>1.241257</td>\n",
       "      <td>1.184828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>1.122992</td>\n",
       "      <td>-0.791350</td>\n",
       "      <td>0.631006</td>\n",
       "      <td>0.972635</td>\n",
       "      <td>-1.761101</td>\n",
       "      <td>0.954232</td>\n",
       "      <td>-0.059318</td>\n",
       "      <td>0.243151</td>\n",
       "      <td>-0.396814</td>\n",
       "      <td>0.291628</td>\n",
       "      <td>-0.082939</td>\n",
       "      <td>-0.112112</td>\n",
       "      <td>-0.115381</td>\n",
       "      <td>0.323493</td>\n",
       "      <td>-0.681632</td>\n",
       "      <td>-0.030415</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>0.312472</td>\n",
       "      <td>-1.281495</td>\n",
       "      <td>-0.194885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1541 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Menstrual_Irregularity       BMI  Follicle_No_R  \\\n",
       "0                   0.656038 -1.339000      -1.122836   \n",
       "1                  -0.744823 -0.159445      -0.496464   \n",
       "2                   1.122992 -0.075192       2.635397   \n",
       "3                   0.656038  0.851601      -1.436022   \n",
       "4                  -0.277869 -1.170492      -0.809650   \n",
       "...                      ...       ...            ...   \n",
       "1536                1.122992 -1.528571      -0.371189   \n",
       "1537                1.122992  0.683094      -0.183278   \n",
       "1538               -1.211777  0.556713      -0.371189   \n",
       "1539               -1.211777  0.346078      -0.809650   \n",
       "1540                1.122992 -0.791350       0.631006   \n",
       "\n",
       "      Testosterone_Levelng_dL  Antral_Follicle_Count  hair_growthY_N  \\\n",
       "0                    0.920872              -0.416975       -0.946420   \n",
       "1                   -0.683807              -0.551388       -0.946420   \n",
       "2                    0.412368               0.154278       -0.946420   \n",
       "3                   -0.414839              -0.215357       -0.946420   \n",
       "4                   -0.029147              -0.248960       -0.946420   \n",
       "...                       ...                    ...             ...   \n",
       "1536                 1.825216               0.927150       -0.312870   \n",
       "1537                -1.585107              -1.761101       -0.312870   \n",
       "1538                -1.387187               1.767228       -0.312870   \n",
       "1539                 1.820141              -1.425069       -0.312870   \n",
       "1540                 0.972635              -1.761101        0.954232   \n",
       "\n",
       "      Weight_gainY_N  CycleR_I  Skin_darkening_Y_N  PimplesY_N  Follicle_No_L  \\\n",
       "0          -1.086381 -0.959723           -0.988198   -1.399962      -1.006224   \n",
       "1          -1.086381 -0.959723           -0.988198   -1.399962      -1.006224   \n",
       "2          -1.086381 -0.959723           -0.988198    1.419355       2.291223   \n",
       "3          -1.086381 -0.959723           -0.988198   -1.399962      -1.335969   \n",
       "4          -1.086381 -0.959723           -0.988198   -1.399962      -1.006224   \n",
       "...              ...       ...                 ...         ...            ...   \n",
       "1536       -1.086381 -0.959723            0.194570   -1.399962      -0.676480   \n",
       "1537        0.454214 -0.358286           -0.396814   -0.272235       0.246806   \n",
       "1538       -0.059318 -0.358286           -0.988198   -0.836099      -0.148888   \n",
       "1539        1.481277  0.844587            0.785954   -0.272235      -0.346735   \n",
       "1540       -0.059318  0.243151           -0.396814    0.291628      -0.082939   \n",
       "\n",
       "        FSH_LH  AMHng_mL  Avg_F_size_R_mm  Weight_Kg  RBSmg_dl  LHmIU_mL  \\\n",
       "0    -0.112472 -0.911381         1.182416  -1.586049 -0.558343 -0.021249   \n",
       "1    -0.009411 -1.039082        -0.535430   0.188001 -0.558343 -0.068930   \n",
       "2    -0.006070  0.166979         2.041339   0.518461 -1.061131 -0.072796   \n",
       "3    -0.080089 -1.112391        -0.535430   0.188001 -1.563919 -0.045550   \n",
       "4    -0.054388 -0.866449        -0.535430  -0.942521 -1.061131 -0.072428   \n",
       "...        ...       ...              ...        ...       ...       ...   \n",
       "1536 -0.079266 -0.142813         0.323493  -1.499086  0.070142 -0.046507   \n",
       "1537 -0.001187 -0.605846        -0.020076   0.196697 -0.068124 -0.054939   \n",
       "1538 -0.072584 -0.150854         0.151708   0.568900  0.849464 -0.064033   \n",
       "1539 -0.127327  0.036914        -0.277753   0.648906 -0.633761 -0.022243   \n",
       "1540 -0.112112 -0.115381         0.323493  -0.681632 -0.030415 -0.046875   \n",
       "\n",
       "      PRLng_mL       Age  Waistinch  \n",
       "0     2.151234 -0.484837  -1.508897  \n",
       "1    -0.317319  0.577375  -0.851891  \n",
       "2    -1.259643  0.179046   0.462121  \n",
       "3     1.337902  0.710152   0.462121  \n",
       "4     0.667345 -0.883166  -1.508897  \n",
       "...        ...       ...        ...  \n",
       "1536  0.569667  0.311822  -2.363005  \n",
       "1537 -0.988269  1.772363   0.593523  \n",
       "1538 -0.542610  0.710152   0.462121  \n",
       "1539 -0.176315  1.241257   1.184828  \n",
       "1540  0.312472 -1.281495  -0.194885  \n",
       "\n",
       "[1541 rows x 20 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X[top_features]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6309222-bd7e-49c2-9087-2881b7a8e722",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.15, stratify=y, shuffle=True, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f525dd75-8236-420f-901e-64dfbc124653",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    param = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-3, 10.0, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-3, 10.0, log=True),\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"random_state\": 8,\n",
    "        \"use_label_encoder\": False,\n",
    "    }\n",
    "\n",
    "    train_pool = xgb.DMatrix(x_train, y_train)\n",
    "    valid_pool = xgb.DMatrix(x_test, y_test)\n",
    "    \n",
    "    # Train model\n",
    "    model = xgb.XGBClassifier(**param)\n",
    "    model.fit(x_train, y_train,\n",
    "              eval_set=[(x_test, y_test)],\n",
    "              verbose=False)\n",
    "\n",
    "    # Predict\n",
    "    preds = model.predict(x_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "\n",
    "    return 1.0 - acc  # Optuna minimizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "431000a4-6309-4710-9a45-39073fd06ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 20:07:50,664] A new study created in memory with name: no-name-4d7021d7-f5f9-40cd-825e-fdb0d838a93c\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:07:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:07:51,043] Trial 0 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.22362521127598226, 'n_estimators': 650, 'max_depth': 7, 'subsample': 0.85498117630046, 'colsample_bytree': 0.8491602164265448, 'reg_alpha': 0.8413912529457798, 'reg_lambda': 0.0013793988161473257}. Best is trial 0 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:07:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:07:51,311] Trial 1 finished with value: 0.0431034482758621 and parameters: {'learning_rate': 0.01669729585203327, 'n_estimators': 151, 'max_depth': 10, 'subsample': 0.9020933175549183, 'colsample_bytree': 0.8895556722369756, 'reg_alpha': 2.3267126691477764, 'reg_lambda': 1.025888551919279}. Best is trial 0 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:07:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:07:51,566] Trial 2 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.1163789854040138, 'n_estimators': 223, 'max_depth': 10, 'subsample': 0.7540871200950863, 'colsample_bytree': 0.6610400492082242, 'reg_alpha': 0.07595761139084005, 'reg_lambda': 0.006379613202204761}. Best is trial 0 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:07:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:07:52,218] Trial 3 finished with value: 0.051724137931034475 and parameters: {'learning_rate': 0.08939155901967692, 'n_estimators': 750, 'max_depth': 11, 'subsample': 0.8007792304243473, 'colsample_bytree': 0.980757754394397, 'reg_alpha': 0.05440752360059862, 'reg_lambda': 0.07640623886827935}. Best is trial 0 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:07:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:07:52,344] Trial 4 finished with value: 0.0431034482758621 and parameters: {'learning_rate': 0.0862787406260274, 'n_estimators': 119, 'max_depth': 5, 'subsample': 0.9550205379064834, 'colsample_bytree': 0.6905315968078731, 'reg_alpha': 0.5626844896503415, 'reg_lambda': 0.004380312873859732}. Best is trial 0 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:07:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:07:53,100] Trial 5 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.13326265273051952, 'n_estimators': 846, 'max_depth': 12, 'subsample': 0.9222196910556267, 'colsample_bytree': 0.6980872219763526, 'reg_alpha': 0.004694431929619772, 'reg_lambda': 1.7686974540099194}. Best is trial 0 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:07:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:07:53,280] Trial 6 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.25792842332777377, 'n_estimators': 197, 'max_depth': 8, 'subsample': 0.695739394505134, 'colsample_bytree': 0.9997216043310084, 'reg_alpha': 0.11461735521998674, 'reg_lambda': 0.06336598079062539}. Best is trial 0 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:07:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:07:53,761] Trial 7 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.05263800629733127, 'n_estimators': 579, 'max_depth': 4, 'subsample': 0.9247105708324357, 'colsample_bytree': 0.8616196615152532, 'reg_alpha': 0.11177562879022317, 'reg_lambda': 0.33328316096716665}. Best is trial 0 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:07:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:07:54,260] Trial 8 finished with value: 0.0431034482758621 and parameters: {'learning_rate': 0.2244338709363744, 'n_estimators': 714, 'max_depth': 8, 'subsample': 0.7608599786270219, 'colsample_bytree': 0.7211970567299762, 'reg_alpha': 0.08667939626392901, 'reg_lambda': 0.06278929756671066}. Best is trial 0 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:07:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:07:54,633] Trial 9 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.2043086783793511, 'n_estimators': 696, 'max_depth': 7, 'subsample': 0.9422893260767933, 'colsample_bytree': 0.9742476558201298, 'reg_alpha': 0.8302122666063134, 'reg_lambda': 0.0024668920585210357}. Best is trial 0 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:07:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:07:55,331] Trial 10 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.0345074404962086, 'n_estimators': 989, 'max_depth': 6, 'subsample': 0.8410327452939406, 'colsample_bytree': 0.7891090100951095, 'reg_alpha': 9.479767161514117, 'reg_lambda': 8.691173211848746}. Best is trial 0 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:07:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:07:55,661] Trial 11 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.0380847389982951, 'n_estimators': 465, 'max_depth': 3, 'subsample': 0.8673649254062996, 'colsample_bytree': 0.8596470644353829, 'reg_alpha': 0.007851626353028131, 'reg_lambda': 0.4301165491293431}. Best is trial 0 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:07:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:07:55,997] Trial 12 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.052609864616852964, 'n_estimators': 468, 'max_depth': 3, 'subsample': 0.9785364004784157, 'colsample_bytree': 0.840293861221553, 'reg_alpha': 0.42062407307949834, 'reg_lambda': 0.023372490596358406}. Best is trial 0 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:07:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:07:56,600] Trial 13 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.016185429575376237, 'n_estimators': 607, 'max_depth': 5, 'subsample': 0.6028554283874522, 'colsample_bytree': 0.7785884642175751, 'reg_alpha': 0.02226056602412923, 'reg_lambda': 0.24304797552810795}. Best is trial 0 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:07:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:07:56,906] Trial 14 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.0239125221815387, 'n_estimators': 339, 'max_depth': 4, 'subsample': 0.9960402651867789, 'colsample_bytree': 0.9038277540218946, 'reg_alpha': 3.5029074043169683, 'reg_lambda': 0.0010713655515185029}. Best is trial 0 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:07:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:07:57,459] Trial 15 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.06261819479234704, 'n_estimators': 549, 'max_depth': 7, 'subsample': 0.8707834770188472, 'colsample_bytree': 0.9317914921874724, 'reg_alpha': 0.0017622754336911236, 'reg_lambda': 0.013950123667175572}. Best is trial 0 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:07:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:07:58,283] Trial 16 finished with value: 0.0431034482758621 and parameters: {'learning_rate': 0.15576872605686998, 'n_estimators': 887, 'max_depth': 9, 'subsample': 0.804315258995952, 'colsample_bytree': 0.8117322917825943, 'reg_alpha': 0.2652424428277752, 'reg_lambda': 3.1653718147658276}. Best is trial 0 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:07:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:07:58,670] Trial 17 finished with value: 0.02155172413793105 and parameters: {'learning_rate': 0.0658972959950069, 'n_estimators': 400, 'max_depth': 5, 'subsample': 0.8915997089588472, 'colsample_bytree': 0.7515852606768445, 'reg_alpha': 1.5119170362713468, 'reg_lambda': 0.24058890593202276}. Best is trial 17 with value: 0.02155172413793105.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:07:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:07:59,133] Trial 18 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.01064387246408792, 'n_estimators': 375, 'max_depth': 6, 'subsample': 0.7251260096500224, 'colsample_bytree': 0.6142932149225044, 'reg_alpha': 1.8075187711676906, 'reg_lambda': 0.015931676352430438}. Best is trial 17 with value: 0.02155172413793105.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:07:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:07:59,330] Trial 19 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.17392612138711508, 'n_estimators': 317, 'max_depth': 6, 'subsample': 0.8367405010836582, 'colsample_bytree': 0.7455808948822626, 'reg_alpha': 8.546338324678429, 'reg_lambda': 0.15856843634107778}. Best is trial 17 with value: 0.02155172413793105.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:07:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:07:59,599] Trial 20 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.2954883882747569, 'n_estimators': 457, 'max_depth': 5, 'subsample': 0.8828295861038534, 'colsample_bytree': 0.7469747619516263, 'reg_alpha': 1.2741580683879496, 'reg_lambda': 0.001031416470195825}. Best is trial 17 with value: 0.02155172413793105.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:07:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:08:00,105] Trial 21 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.053351656933940415, 'n_estimators': 590, 'max_depth': 4, 'subsample': 0.9143465656616845, 'colsample_bytree': 0.824797021889549, 'reg_alpha': 0.22376228241644783, 'reg_lambda': 0.5612475966410677}. Best is trial 17 with value: 0.02155172413793105.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:08:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:08:00,472] Trial 22 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.07535285693573063, 'n_estimators': 533, 'max_depth': 4, 'subsample': 0.8442220829502098, 'colsample_bytree': 0.8697281130156294, 'reg_alpha': 4.221214471750738, 'reg_lambda': 0.2739889611502317}. Best is trial 17 with value: 0.02155172413793105.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:08:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:08:01,235] Trial 23 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.028596033043425294, 'n_estimators': 643, 'max_depth': 6, 'subsample': 0.9367597059857062, 'colsample_bytree': 0.9153657095157132, 'reg_alpha': 0.20669201469135173, 'reg_lambda': 1.007583171035028}. Best is trial 17 with value: 0.02155172413793105.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:08:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:08:02,014] Trial 24 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.04164357108887388, 'n_estimators': 815, 'max_depth': 5, 'subsample': 0.8982549708855359, 'colsample_bytree': 0.7616982720053638, 'reg_alpha': 0.033514173996021905, 'reg_lambda': 0.03254891058480461}. Best is trial 17 with value: 0.02155172413793105.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:08:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:08:02,316] Trial 25 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.1060783634589393, 'n_estimators': 398, 'max_depth': 3, 'subsample': 0.9712640577125446, 'colsample_bytree': 0.8499496352925578, 'reg_alpha': 0.833190458735832, 'reg_lambda': 0.1334537935145024}. Best is trial 17 with value: 0.02155172413793105.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:08:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:08:02,696] Trial 26 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.06465819216628979, 'n_estimators': 274, 'max_depth': 7, 'subsample': 0.8232467916796278, 'colsample_bytree': 0.8020615271546703, 'reg_alpha': 0.022931317811552165, 'reg_lambda': 4.882681423415846}. Best is trial 17 with value: 0.02155172413793105.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:08:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:08:03,262] Trial 27 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.022714791344772976, 'n_estimators': 652, 'max_depth': 4, 'subsample': 0.8704082779760934, 'colsample_bytree': 0.9433989043503557, 'reg_alpha': 0.3995781082825428, 'reg_lambda': 0.4922678186560487}. Best is trial 17 with value: 0.02155172413793105.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:08:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:08:03,947] Trial 28 finished with value: 0.02155172413793105 and parameters: {'learning_rate': 0.046027172869372156, 'n_estimators': 534, 'max_depth': 8, 'subsample': 0.9156853389236759, 'colsample_bytree': 0.8873801364095821, 'reg_alpha': 0.1478436135387372, 'reg_lambda': 1.4331909148153248}. Best is trial 17 with value: 0.02155172413793105.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:08:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:08:04,724] Trial 29 finished with value: 0.017241379310344862 and parameters: {'learning_rate': 0.01625669577357544, 'n_estimators': 479, 'max_depth': 9, 'subsample': 0.7720251785180374, 'colsample_bytree': 0.9012143267773818, 'reg_alpha': 2.2774305893018276, 'reg_lambda': 2.6271042155977593}. Best is trial 29 with value: 0.017241379310344862.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:08:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:08:05,494] Trial 30 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.011226564480184354, 'n_estimators': 495, 'max_depth': 9, 'subsample': 0.6497334430776303, 'colsample_bytree': 0.949301438009563, 'reg_alpha': 3.5339033039837653, 'reg_lambda': 1.9182671693170954}. Best is trial 29 with value: 0.017241379310344862.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:08:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:08:06,122] Trial 31 finished with value: 0.02155172413793105 and parameters: {'learning_rate': 0.016039962049553196, 'n_estimators': 376, 'max_depth': 9, 'subsample': 0.7889005999604658, 'colsample_bytree': 0.8839567246781964, 'reg_alpha': 1.7179823355563715, 'reg_lambda': 1.5294934322383897}. Best is trial 29 with value: 0.017241379310344862.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:08:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:08:06,798] Trial 32 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.014456099276267032, 'n_estimators': 406, 'max_depth': 9, 'subsample': 0.7779372263880069, 'colsample_bytree': 0.8940922614126819, 'reg_alpha': 1.4266366144690548, 'reg_lambda': 1.1174877562479681}. Best is trial 29 with value: 0.017241379310344862.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:08:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:08:07,282] Trial 33 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.02250674233559439, 'n_estimators': 291, 'max_depth': 10, 'subsample': 0.7349016981310827, 'colsample_bytree': 0.8813538790135418, 'reg_alpha': 5.4495292801882576, 'reg_lambda': 9.421155342850025}. Best is trial 29 with value: 0.017241379310344862.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:08:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:08:08,058] Trial 34 finished with value: 0.02155172413793105 and parameters: {'learning_rate': 0.01837537364683423, 'n_estimators': 508, 'max_depth': 8, 'subsample': 0.7789324805062129, 'colsample_bytree': 0.9207774998963266, 'reg_alpha': 2.466319563188373, 'reg_lambda': 3.9693973472816753}. Best is trial 29 with value: 0.017241379310344862.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:08:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:08:08,722] Trial 35 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.02900629178314147, 'n_estimators': 424, 'max_depth': 10, 'subsample': 0.808360460438559, 'colsample_bytree': 0.8307207617896599, 'reg_alpha': 0.8660551979070993, 'reg_lambda': 0.8539140105323855}. Best is trial 29 with value: 0.017241379310344862.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:08:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:08:09,130] Trial 36 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.012163943040988525, 'n_estimators': 232, 'max_depth': 9, 'subsample': 0.6911206844622789, 'colsample_bytree': 0.9677903099746291, 'reg_alpha': 2.2008306299456124, 'reg_lambda': 2.3485655721298673}. Best is trial 29 with value: 0.017241379310344862.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:08:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:08:09,761] Trial 37 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.01364627371700171, 'n_estimators': 365, 'max_depth': 12, 'subsample': 0.8918308736315524, 'colsample_bytree': 0.8856650445454869, 'reg_alpha': 6.023660671145164, 'reg_lambda': 1.5842504352732254}. Best is trial 29 with value: 0.017241379310344862.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:08:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:08:10,515] Trial 38 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.01914083713763536, 'n_estimators': 432, 'max_depth': 11, 'subsample': 0.7730272656219697, 'colsample_bytree': 0.6662675038131062, 'reg_alpha': 0.536946593100947, 'reg_lambda': 5.281188582929375}. Best is trial 29 with value: 0.017241379310344862.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:08:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:08:10,823] Trial 39 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.04424403263516192, 'n_estimators': 166, 'max_depth': 11, 'subsample': 0.7356542679383556, 'colsample_bytree': 0.7094128899257945, 'reg_alpha': 1.1531365870582486, 'reg_lambda': 0.8030306749345857}. Best is trial 29 with value: 0.017241379310344862.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:08:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:08:11,163] Trial 40 finished with value: 0.02155172413793105 and parameters: {'learning_rate': 0.08415054105025567, 'n_estimators': 237, 'max_depth': 8, 'subsample': 0.8222722082276207, 'colsample_bytree': 0.9579463855403156, 'reg_alpha': 0.057945028264904254, 'reg_lambda': 1.4372166570997347}. Best is trial 29 with value: 0.017241379310344862.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:08:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:08:11,962] Trial 41 finished with value: 0.017241379310344862 and parameters: {'learning_rate': 0.016271719405357765, 'n_estimators': 521, 'max_depth': 8, 'subsample': 0.7871073295514182, 'colsample_bytree': 0.9186088606640301, 'reg_alpha': 2.800800322609744, 'reg_lambda': 3.5578300665674925}. Best is trial 29 with value: 0.017241379310344862.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:08:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:08:12,717] Trial 42 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.029466663445521964, 'n_estimators': 537, 'max_depth': 9, 'subsample': 0.707018704573648, 'colsample_bytree': 0.9066379320905913, 'reg_alpha': 2.362646950678874, 'reg_lambda': 2.7388128783240773}. Best is trial 29 with value: 0.017241379310344862.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:08:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:08:13,450] Trial 43 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.015624595620633432, 'n_estimators': 493, 'max_depth': 8, 'subsample': 0.7892535539852849, 'colsample_bytree': 0.9942745827925044, 'reg_alpha': 6.18510922907275, 'reg_lambda': 7.521528655801671}. Best is trial 29 with value: 0.017241379310344862.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:08:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:08:13,951] Trial 44 finished with value: 0.02155172413793105 and parameters: {'learning_rate': 0.0203971800547673, 'n_estimators': 343, 'max_depth': 7, 'subsample': 0.7600997604872608, 'colsample_bytree': 0.9319734779769375, 'reg_alpha': 2.909138829446483, 'reg_lambda': 5.161006069008585}. Best is trial 29 with value: 0.017241379310344862.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:08:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:08:14,485] Trial 45 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.11050546011207973, 'n_estimators': 618, 'max_depth': 10, 'subsample': 0.8134075561455558, 'colsample_bytree': 0.8736044141058485, 'reg_alpha': 1.6374601382484046, 'reg_lambda': 0.5965159963559897}. Best is trial 29 with value: 0.017241379310344862.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:08:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:08:15,422] Trial 46 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.01280880627072188, 'n_estimators': 566, 'max_depth': 9, 'subsample': 0.7533445527315693, 'colsample_bytree': 0.7810508955590867, 'reg_alpha': 0.12694262613055132, 'reg_lambda': 2.802421435357955}. Best is trial 29 with value: 0.017241379310344862.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:08:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:08:16,405] Trial 47 finished with value: 0.02155172413793105 and parameters: {'learning_rate': 0.026350451319862387, 'n_estimators': 682, 'max_depth': 10, 'subsample': 0.8596010005450679, 'colsample_bytree': 0.851833692749789, 'reg_alpha': 0.6201820232055896, 'reg_lambda': 1.2191635536820165}. Best is trial 29 with value: 0.017241379310344862.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:08:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:08:17,030] Trial 48 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.033807841364099554, 'n_estimators': 446, 'max_depth': 8, 'subsample': 0.9540450956226906, 'colsample_bytree': 0.7303110938861432, 'reg_alpha': 0.010997247845042493, 'reg_lambda': 0.1922023352408893}. Best is trial 29 with value: 0.017241379310344862.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:08:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:08:17,911] Trial 49 finished with value: 0.02155172413793105 and parameters: {'learning_rate': 0.016537203430660237, 'n_estimators': 513, 'max_depth': 11, 'subsample': 0.9071602196418487, 'colsample_bytree': 0.8906488521912972, 'reg_alpha': 0.0011922450853209703, 'reg_lambda': 2.013988501382346}. Best is trial 29 with value: 0.017241379310344862.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:\n",
      "{'learning_rate': 0.01625669577357544, 'n_estimators': 479, 'max_depth': 9, 'subsample': 0.7720251785180374, 'colsample_bytree': 0.9012143267773818, 'reg_alpha': 2.2774305893018276, 'reg_lambda': 2.6271042155977593}\n",
      "Best accuracy:\n",
      "0.9827586206896551\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')  # Because we return 1 - accuracy\n",
    "study.optimize(objective, n_trials=50)  # Try 50 combinations (or more!)\n",
    "\n",
    "print(\"Best hyperparameters:\")\n",
    "print(study.best_params)\n",
    "\n",
    "print(\"Best accuracy:\")\n",
    "print(1 - study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32a77c30-8678-4f82-a28f-3c79936be098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final evaluation on test set:\n",
      "Accuracy: 97.41\n",
      "Precision: 96.36\n",
      "Recall: 92.98\n",
      "F1 Score: 94.64\n"
     ]
    }
   ],
   "source": [
    "# Get the data\n",
    "best_model = xgb.XGBClassifier(**study.best_params)\n",
    "best_model.fit(x_train, y_train,\n",
    "          eval_set=[(x_test, y_test)],\n",
    "          verbose=False)\n",
    "\n",
    "# Predict\n",
    "preds = best_model.predict(x_test)\n",
    "\n",
    "# Compute final scores\n",
    "acc = accuracy_score(y_test, preds)\n",
    "precision = precision_score(y_test, preds, average='binary')\n",
    "recall = recall_score(y_test, preds, average='binary')\n",
    "f1 = f1_score(y_test, preds, average='binary')\n",
    "\n",
    "print(\"\\nFinal evaluation on test set:\")\n",
    "print(f\"Accuracy: {acc * 100:.2f}\")\n",
    "print(f\"Precision: {precision * 100:.2f}\")\n",
    "print(f\"Recall: {recall * 100:.2f}\")\n",
    "print(f\"F1 Score: {f1 * 100:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a711a2-15ed-4aab-9c37-e7a3252fb059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c731a19-f393-4700-8d6d-2042b283392d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5c6717-c78e-421e-87dd-2e1623f9d383",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
