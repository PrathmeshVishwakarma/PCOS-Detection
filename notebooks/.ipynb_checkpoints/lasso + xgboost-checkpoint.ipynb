{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae468260-b8b2-419c-9917-d9aeee35901f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import optuna\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "import joblib\n",
    "from sklearn.linear_model import LassoCV\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20864616-0095-40a0-94bc-c10071e3900e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load both datasets\n",
    "original = pd.read_csv(\"PCOS_data.csv\")\n",
    "new = pd.read_csv(\"pcos_dataset.csv\")\n",
    "\n",
    "# Set max columns to show is unlimited\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da865d79-aa70-4b23-9d0a-2b45791d685b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df = df.copy()  # avoid SettingWithCopyWarning\n",
    "\n",
    "    # 1. Clean column names\n",
    "    df.columns = df.columns.str.strip() \\\n",
    "                           .str.replace(' ', '_') \\\n",
    "                           .str.replace('(', '') \\\n",
    "                           .str.replace(')', '') \\\n",
    "                           .str.replace('.', '') \\\n",
    "                           .str.replace('-', '_') \\\n",
    "                           .str.replace('/', '_')\n",
    "    df.rename(columns={'II____beta_HCGmIU_mL': 'II_beta_HCG'}, inplace=True)\n",
    "\n",
    "    # 2. Drop irrelevant columns\n",
    "    df.drop(columns=['Sl_No', 'Patient_File_No'], inplace=True, errors='ignore')\n",
    "    df = df.loc[:, ~df.columns.str.startswith('Unnamed')]\n",
    "\n",
    "    # 3. Merge Age columns\n",
    "    if 'Age' not in df.columns and 'Age_yrs' in df.columns:\n",
    "        df.rename(columns={'Age_yrs': 'Age'}, inplace=True)\n",
    "    elif 'Age' in df.columns and 'Age_yrs' in df.columns:\n",
    "        df['Age'] = df['Age'].fillna(df['Age_yrs'])\n",
    "        df.drop(columns=['Age_yrs'], inplace=True)\n",
    "\n",
    "    # 4. Merge PCOS diagnosis columns\n",
    "    if 'PCOS_Diagnosis' in df.columns:\n",
    "        df.rename(columns={'PCOS_Diagnosis': 'PCOS_Y_N'}, inplace=True)\n",
    "\n",
    "    # 5. Handle missing values\n",
    "    if 'Marraige_Status_Yrs' in df.columns:\n",
    "        df.loc[:, 'Marraige_Status_Yrs'] = df['Marraige_Status_Yrs'].fillna(df['Marraige_Status_Yrs'].median())\n",
    "\n",
    "    if 'Fast_food_Y_N' not in df.columns and 'Fast_food_YN' in df.columns:\n",
    "        df.rename(columns={'Fast_food_YN': 'Fast_food_Y_N'}, inplace=True)\n",
    "    if 'Fast_food_Y_N' in df.columns:\n",
    "        df.loc[:, 'Fast_food_Y_N'] = df['Fast_food_Y_N'].fillna(df['Fast_food_Y_N'].mode()[0])\n",
    "\n",
    "    # 6. Convert to numeric and fill missing values\n",
    "    if 'II_beta_HCG' not in df.columns and 'II_beta_HCGmIU_mL' in df.columns:\n",
    "        df.rename(columns={'II_beta_HCGmIU_mL': 'II_beta_HCG'}, inplace=True)\n",
    "    if 'II_beta_HCG' in df.columns:\n",
    "        df.loc[:, 'II_beta_HCG'] = pd.to_numeric(df['II_beta_HCG'], errors='coerce')\n",
    "        df['II_beta_HCG'] = df['II_beta_HCG'].astype(float)\n",
    "        df.loc[:, 'II_beta_HCG'] = df['II_beta_HCG'].fillna(df['II_beta_HCG'].median())\n",
    "\n",
    "    if 'AMHng_mL' in df.columns:\n",
    "        df.loc[:, 'AMHng_mL'] = pd.to_numeric(df['AMHng_mL'], errors='coerce')\n",
    "        df['AMHng_mL'] = df['AMHng_mL'].astype(float)\n",
    "        df.loc[:, 'AMHng_mL'] = df['AMHng_mL'].fillna(df['AMHng_mL'].median())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9783e46b-bfee-4ba4-96d8-1c2241513935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing\n",
    "original_clean = preprocess(original)\n",
    "new_clean = preprocess(new)\n",
    "\n",
    "# Ensure consistent columns across both\n",
    "all_columns = list(set(original_clean.columns).union(set(new_clean.columns)))\n",
    "\n",
    "# Align both dataframes to same columns, fill missing with NaN\n",
    "original_aligned = original_clean.reindex(columns=all_columns)\n",
    "new_aligned = new_clean.reindex(columns=all_columns)\n",
    "\n",
    "# Concatenate datasets\n",
    "combined_df = pd.concat([original_aligned, new_aligned], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26bdf1a3-5c90-4ba1-b3f9-38b2694f3892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "# X = combined_df.drop(columns=['PCOS_Y_N'])\n",
    "X = combined_df.drop(columns=['PCOS_Y_N'])\n",
    "y = combined_df['PCOS_Y_N']\n",
    "\n",
    "# Initialize KNNImputer (e.g., with 5 nearest neighbors)\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "X = pd.DataFrame(knn_imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Sanitize feature names\n",
    "X.columns = [str(col).replace(' ', '_')\n",
    "                        .replace('\"', '')\n",
    "                        .replace(\"'\", '')\n",
    "                        .replace('[', '')\n",
    "                        .replace(']', '')\n",
    "                        .replace('{', '')\n",
    "                        .replace('}', '')\n",
    "                        .replace(':', '')\n",
    "                        .replace(',', '')\n",
    "                        for col in X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5791e93-16c2-486c-9d03-954ec9896528",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(X_scaled, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "149db8fe-89f9-4b5e-b4e0-03a4a5161d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.058039141634139924, tolerance: 0.02152694805194805\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04906085836790908, tolerance: 0.021966098945660997\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.05663576143990667, tolerance: 0.021966098945660997\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.057744913249564433, tolerance: 0.021966098945660997\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.05762391630264574, tolerance: 0.021966098945660997\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.057272700216500994, tolerance: 0.021966098945660997\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.056876865639537755, tolerance: 0.021966098945660997\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.056473317555784774, tolerance: 0.021966098945660997\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.05607154431081085, tolerance: 0.021966098945660997\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.035419089160939166, tolerance: 0.023646877534468785\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.037042582882577335, tolerance: 0.023646877534468785\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03702510453206287, tolerance: 0.023646877534468785\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03764154310408685, tolerance: 0.023646877534468785\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.037782319931892516, tolerance: 0.023646877534468785\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03753598934051183, tolerance: 0.023646877534468785\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03724053553185058, tolerance: 0.023646877534468785\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03694499422311992, tolerance: 0.023646877534468785\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.02610094919410244, tolerance: 0.02320600162206002\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.02630754446335004, tolerance: 0.02320600162206002\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03692355502394662, tolerance: 0.02325563665855636\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.038012155396444314, tolerance: 0.02325563665855636\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.037739618008032494, tolerance: 0.02325563665855636\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.037409022514992785, tolerance: 0.02325563665855636\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03711379950371452, tolerance: 0.02325563665855636\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03681790986394162, tolerance: 0.02325563665855636\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.036519600140337616, tolerance: 0.02325563665855636\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03622131889568436, tolerance: 0.02325563665855636\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.035925591356146924, tolerance: 0.02325563665855636\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.035634518917021296, tolerance: 0.02325563665855636\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LassoCV(cv=5, random_state=8)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LassoCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LassoCV.html\">?<span>Documentation for LassoCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LassoCV(cv=5, random_state=8)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LassoCV(cv=5, random_state=8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = LassoCV(cv=5, random_state=8)\n",
    "lasso.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e65b1e95-3e4c-4684-80a3-131b01ad6f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: ['Weight_gainY_N', 'Menstrual_Irregularity', 'Antral_Follicle_Count', 'LHmIU_mL', 'AMHng_mL', 'Follicle_No_R', 'Testosterone_Levelng_dL', 'BMI', 'Fast_food_Y_N', 'Follicle_No_L', 'CycleR_I', 'hair_growthY_N', 'Skin_darkening_Y_N']\n"
     ]
    }
   ],
   "source": [
    "selected_mask = lasso.coef_ != 0\n",
    "selected_features = list(X.columns[selected_mask])\n",
    "print(\"Selected Features:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2eeab3a9-9b39-4e43-ba15-48bdeadf9d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight_gainY_N</th>\n",
       "      <th>Menstrual_Irregularity</th>\n",
       "      <th>Antral_Follicle_Count</th>\n",
       "      <th>LHmIU_mL</th>\n",
       "      <th>AMHng_mL</th>\n",
       "      <th>Follicle_No_R</th>\n",
       "      <th>Testosterone_Levelng_dL</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Fast_food_Y_N</th>\n",
       "      <th>Follicle_No_L</th>\n",
       "      <th>CycleR_I</th>\n",
       "      <th>hair_growthY_N</th>\n",
       "      <th>Skin_darkening_Y_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.084998</td>\n",
       "      <td>0.656240</td>\n",
       "      <td>-0.416187</td>\n",
       "      <td>-0.021308</td>\n",
       "      <td>-0.906254</td>\n",
       "      <td>-1.120297</td>\n",
       "      <td>0.920706</td>\n",
       "      <td>-1.339000</td>\n",
       "      <td>1.306100</td>\n",
       "      <td>-1.002388</td>\n",
       "      <td>-0.960148</td>\n",
       "      <td>-0.945282</td>\n",
       "      <td>-0.982636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.084998</td>\n",
       "      <td>-0.744405</td>\n",
       "      <td>-0.550662</td>\n",
       "      <td>-0.068990</td>\n",
       "      <td>-1.033958</td>\n",
       "      <td>-0.493776</td>\n",
       "      <td>-0.683566</td>\n",
       "      <td>-0.159445</td>\n",
       "      <td>-1.444241</td>\n",
       "      <td>-1.002388</td>\n",
       "      <td>-0.960148</td>\n",
       "      <td>-0.945282</td>\n",
       "      <td>-0.982636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.084998</td>\n",
       "      <td>1.123121</td>\n",
       "      <td>0.155331</td>\n",
       "      <td>-0.072856</td>\n",
       "      <td>0.172134</td>\n",
       "      <td>2.638827</td>\n",
       "      <td>0.412332</td>\n",
       "      <td>-0.075192</td>\n",
       "      <td>1.306100</td>\n",
       "      <td>2.298775</td>\n",
       "      <td>-0.960148</td>\n",
       "      <td>-0.945282</td>\n",
       "      <td>-0.982636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.084998</td>\n",
       "      <td>0.656240</td>\n",
       "      <td>-0.214475</td>\n",
       "      <td>-0.045609</td>\n",
       "      <td>-1.107270</td>\n",
       "      <td>-1.433557</td>\n",
       "      <td>-0.414665</td>\n",
       "      <td>0.851601</td>\n",
       "      <td>-1.444241</td>\n",
       "      <td>-1.332504</td>\n",
       "      <td>-0.960148</td>\n",
       "      <td>-0.945282</td>\n",
       "      <td>-0.982636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.084998</td>\n",
       "      <td>-0.277523</td>\n",
       "      <td>-0.248094</td>\n",
       "      <td>-0.072488</td>\n",
       "      <td>-0.861321</td>\n",
       "      <td>-0.807037</td>\n",
       "      <td>-0.029071</td>\n",
       "      <td>-1.170492</td>\n",
       "      <td>-1.444241</td>\n",
       "      <td>-1.002388</td>\n",
       "      <td>-0.960148</td>\n",
       "      <td>-0.945282</td>\n",
       "      <td>-0.982636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>-1.084998</td>\n",
       "      <td>1.123121</td>\n",
       "      <td>0.928562</td>\n",
       "      <td>-0.046567</td>\n",
       "      <td>-0.137666</td>\n",
       "      <td>-0.368472</td>\n",
       "      <td>1.824822</td>\n",
       "      <td>-1.528571</td>\n",
       "      <td>-0.894173</td>\n",
       "      <td>-0.672272</td>\n",
       "      <td>-0.960148</td>\n",
       "      <td>-0.310563</td>\n",
       "      <td>0.201754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>0.456473</td>\n",
       "      <td>1.123121</td>\n",
       "      <td>-1.760936</td>\n",
       "      <td>-0.054998</td>\n",
       "      <td>-0.600711</td>\n",
       "      <td>-0.180516</td>\n",
       "      <td>-1.584637</td>\n",
       "      <td>0.683094</td>\n",
       "      <td>-1.444241</td>\n",
       "      <td>0.252054</td>\n",
       "      <td>-0.358078</td>\n",
       "      <td>-0.310563</td>\n",
       "      <td>-0.390441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>-0.057351</td>\n",
       "      <td>-1.211286</td>\n",
       "      <td>1.769030</td>\n",
       "      <td>-0.064093</td>\n",
       "      <td>-0.145707</td>\n",
       "      <td>-0.368472</td>\n",
       "      <td>-1.386766</td>\n",
       "      <td>0.556713</td>\n",
       "      <td>-0.344105</td>\n",
       "      <td>-0.144086</td>\n",
       "      <td>-0.358078</td>\n",
       "      <td>-0.310563</td>\n",
       "      <td>-0.982636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>1.484119</td>\n",
       "      <td>-1.211286</td>\n",
       "      <td>-1.424749</td>\n",
       "      <td>-0.022303</td>\n",
       "      <td>0.042065</td>\n",
       "      <td>-0.807037</td>\n",
       "      <td>1.819748</td>\n",
       "      <td>0.346078</td>\n",
       "      <td>1.306100</td>\n",
       "      <td>-0.342156</td>\n",
       "      <td>0.846063</td>\n",
       "      <td>-0.310563</td>\n",
       "      <td>0.793948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>-0.057351</td>\n",
       "      <td>1.123121</td>\n",
       "      <td>-1.760936</td>\n",
       "      <td>-0.046935</td>\n",
       "      <td>-0.110234</td>\n",
       "      <td>0.633961</td>\n",
       "      <td>0.972457</td>\n",
       "      <td>-0.791350</td>\n",
       "      <td>0.205963</td>\n",
       "      <td>-0.078063</td>\n",
       "      <td>0.243993</td>\n",
       "      <td>0.958875</td>\n",
       "      <td>-0.390441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1541 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Weight_gainY_N  Menstrual_Irregularity  Antral_Follicle_Count  LHmIU_mL  \\\n",
       "0          -1.084998                0.656240              -0.416187 -0.021308   \n",
       "1          -1.084998               -0.744405              -0.550662 -0.068990   \n",
       "2          -1.084998                1.123121               0.155331 -0.072856   \n",
       "3          -1.084998                0.656240              -0.214475 -0.045609   \n",
       "4          -1.084998               -0.277523              -0.248094 -0.072488   \n",
       "...              ...                     ...                    ...       ...   \n",
       "1536       -1.084998                1.123121               0.928562 -0.046567   \n",
       "1537        0.456473                1.123121              -1.760936 -0.054998   \n",
       "1538       -0.057351               -1.211286               1.769030 -0.064093   \n",
       "1539        1.484119               -1.211286              -1.424749 -0.022303   \n",
       "1540       -0.057351                1.123121              -1.760936 -0.046935   \n",
       "\n",
       "      AMHng_mL  Follicle_No_R  Testosterone_Levelng_dL       BMI  \\\n",
       "0    -0.906254      -1.120297                 0.920706 -1.339000   \n",
       "1    -1.033958      -0.493776                -0.683566 -0.159445   \n",
       "2     0.172134       2.638827                 0.412332 -0.075192   \n",
       "3    -1.107270      -1.433557                -0.414665  0.851601   \n",
       "4    -0.861321      -0.807037                -0.029071 -1.170492   \n",
       "...        ...            ...                      ...       ...   \n",
       "1536 -0.137666      -0.368472                 1.824822 -1.528571   \n",
       "1537 -0.600711      -0.180516                -1.584637  0.683094   \n",
       "1538 -0.145707      -0.368472                -1.386766  0.556713   \n",
       "1539  0.042065      -0.807037                 1.819748  0.346078   \n",
       "1540 -0.110234       0.633961                 0.972457 -0.791350   \n",
       "\n",
       "      Fast_food_Y_N  Follicle_No_L  CycleR_I  hair_growthY_N  \\\n",
       "0          1.306100      -1.002388 -0.960148       -0.945282   \n",
       "1         -1.444241      -1.002388 -0.960148       -0.945282   \n",
       "2          1.306100       2.298775 -0.960148       -0.945282   \n",
       "3         -1.444241      -1.332504 -0.960148       -0.945282   \n",
       "4         -1.444241      -1.002388 -0.960148       -0.945282   \n",
       "...             ...            ...       ...             ...   \n",
       "1536      -0.894173      -0.672272 -0.960148       -0.310563   \n",
       "1537      -1.444241       0.252054 -0.358078       -0.310563   \n",
       "1538      -0.344105      -0.144086 -0.358078       -0.310563   \n",
       "1539       1.306100      -0.342156  0.846063       -0.310563   \n",
       "1540       0.205963      -0.078063  0.243993        0.958875   \n",
       "\n",
       "      Skin_darkening_Y_N  \n",
       "0              -0.982636  \n",
       "1              -0.982636  \n",
       "2              -0.982636  \n",
       "3              -0.982636  \n",
       "4              -0.982636  \n",
       "...                  ...  \n",
       "1536            0.201754  \n",
       "1537           -0.390441  \n",
       "1538           -0.982636  \n",
       "1539            0.793948  \n",
       "1540           -0.390441  \n",
       "\n",
       "[1541 rows x 13 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X[selected_features]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee6c307b-23f7-4c95-9672-3d1a0c36ca2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.15, stratify=y, shuffle=True, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c85bf01-e475-4455-8a4d-fecb6c3a2730",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    param = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-3, 10.0, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-3, 10.0, log=True),\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"random_state\": 8,\n",
    "        \"use_label_encoder\": False,\n",
    "    }\n",
    "\n",
    "    train_pool = xgb.DMatrix(x_train, y_train)\n",
    "    valid_pool = xgb.DMatrix(x_test, y_test)\n",
    "    \n",
    "    # Train model\n",
    "    model = xgb.XGBClassifier(**param)\n",
    "    model.fit(x_train, y_train,\n",
    "              eval_set=[(x_test, y_test)],\n",
    "              verbose=False)\n",
    "\n",
    "    # Predict\n",
    "    preds = model.predict(x_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "\n",
    "    return 1.0 - acc  # Optuna minimizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ccb3aef-cb73-49a4-8903-30663ad7dd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 21:07:54,863] A new study created in memory with name: no-name-51cb754b-d612-404b-93ae-6c8c9811a45b\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:07:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:07:55,610] Trial 0 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.08858518917718178, 'n_estimators': 850, 'max_depth': 6, 'subsample': 0.8374161100377073, 'colsample_bytree': 0.9234225299209516, 'reg_alpha': 0.5059954280466167, 'reg_lambda': 0.013347213662294157}. Best is trial 0 with value: 0.03879310344827591.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:07:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:07:55,878] Trial 1 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.01544149221874914, 'n_estimators': 179, 'max_depth': 8, 'subsample': 0.7691741904842508, 'colsample_bytree': 0.9991095387159918, 'reg_alpha': 0.0012852149048061914, 'reg_lambda': 0.0010007628158952063}. Best is trial 1 with value: 0.03448275862068961.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:07:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:07:56,750] Trial 2 finished with value: 0.04741379310344829 and parameters: {'learning_rate': 0.017021234881765032, 'n_estimators': 622, 'max_depth': 9, 'subsample': 0.7111309912340146, 'colsample_bytree': 0.7696671591521554, 'reg_alpha': 0.010155343691175557, 'reg_lambda': 0.23997340309521722}. Best is trial 1 with value: 0.03448275862068961.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:07:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:07:57,524] Trial 3 finished with value: 0.04741379310344829 and parameters: {'learning_rate': 0.05698246837987471, 'n_estimators': 825, 'max_depth': 10, 'subsample': 0.7517860513383314, 'colsample_bytree': 0.9427837791420496, 'reg_alpha': 0.005897088103063911, 'reg_lambda': 0.0016996499707246677}. Best is trial 1 with value: 0.03448275862068961.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:07:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:07:58,712] Trial 4 finished with value: 0.0431034482758621 and parameters: {'learning_rate': 0.011784186529003794, 'n_estimators': 668, 'max_depth': 11, 'subsample': 0.8961373478900467, 'colsample_bytree': 0.9524119594499579, 'reg_alpha': 0.0019046704293443622, 'reg_lambda': 0.0028168848308252874}. Best is trial 1 with value: 0.03448275862068961.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:07:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:07:59,585] Trial 5 finished with value: 0.04741379310344829 and parameters: {'learning_rate': 0.017813913387277152, 'n_estimators': 997, 'max_depth': 4, 'subsample': 0.9804991418152899, 'colsample_bytree': 0.666554302920192, 'reg_alpha': 0.001405561719582261, 'reg_lambda': 0.035716377337014764}. Best is trial 1 with value: 0.03448275862068961.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:07:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:07:59,781] Trial 6 finished with value: 0.051724137931034475 and parameters: {'learning_rate': 0.05182840290701417, 'n_estimators': 268, 'max_depth': 3, 'subsample': 0.6759793907520809, 'colsample_bytree': 0.6421541064724023, 'reg_alpha': 0.13840077801158363, 'reg_lambda': 0.006614918551000325}. Best is trial 1 with value: 0.03448275862068961.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:07:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:08:00,681] Trial 7 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.011819498198277361, 'n_estimators': 709, 'max_depth': 7, 'subsample': 0.6741963434787387, 'colsample_bytree': 0.9377952840268361, 'reg_alpha': 0.09209280157114201, 'reg_lambda': 0.2923062339460462}. Best is trial 1 with value: 0.03448275862068961.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:08:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:08:01,134] Trial 8 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.03225097255399738, 'n_estimators': 389, 'max_depth': 10, 'subsample': 0.6706987699567433, 'colsample_bytree': 0.7709755507595977, 'reg_alpha': 7.140423338664215, 'reg_lambda': 4.52718011046223}. Best is trial 1 with value: 0.03448275862068961.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:08:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:08:01,642] Trial 9 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.02020807891740947, 'n_estimators': 308, 'max_depth': 11, 'subsample': 0.880987170566317, 'colsample_bytree': 0.8012785175281869, 'reg_alpha': 1.1245845011790825, 'reg_lambda': 0.7158542949143887}. Best is trial 1 with value: 0.03448275862068961.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:08:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:08:01,761] Trial 10 finished with value: 0.0431034482758621 and parameters: {'learning_rate': 0.20783372271875397, 'n_estimators': 112, 'max_depth': 5, 'subsample': 0.612175514454374, 'colsample_bytree': 0.8529454485300278, 'reg_alpha': 0.028206240637027827, 'reg_lambda': 0.03775262479066097}. Best is trial 1 with value: 0.03448275862068961.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:08:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:08:02,191] Trial 11 finished with value: 0.04741379310344829 and parameters: {'learning_rate': 0.03626243362888801, 'n_estimators': 417, 'max_depth': 8, 'subsample': 0.7776806050336262, 'colsample_bytree': 0.7501513765686666, 'reg_alpha': 9.73250425242579, 'reg_lambda': 7.892258086034567}. Best is trial 1 with value: 0.03448275862068961.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:08:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:08:02,723] Trial 12 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.029328461100474486, 'n_estimators': 415, 'max_depth': 12, 'subsample': 0.6040667265084343, 'colsample_bytree': 0.848141190804413, 'reg_alpha': 5.208767728805625, 'reg_lambda': 8.647165237421786}. Best is trial 1 with value: 0.03448275862068961.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:08:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:08:02,893] Trial 13 finished with value: 0.0431034482758621 and parameters: {'learning_rate': 0.029187499053147978, 'n_estimators': 108, 'max_depth': 8, 'subsample': 0.7182428861795257, 'colsample_bytree': 0.7053481446222925, 'reg_alpha': 1.4403530854194901, 'reg_lambda': 1.7916875000162042}. Best is trial 1 with value: 0.03448275862068961.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:08:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:08:03,234] Trial 14 finished with value: 0.0431034482758621 and parameters: {'learning_rate': 0.07835585721797277, 'n_estimators': 241, 'max_depth': 9, 'subsample': 0.8180700314415967, 'colsample_bytree': 0.9950806639947559, 'reg_alpha': 0.1525658205516092, 'reg_lambda': 1.5203065162104705}. Best is trial 1 with value: 0.03448275862068961.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:08:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:08:03,675] Trial 15 finished with value: 0.0431034482758621 and parameters: {'learning_rate': 0.1322453080315702, 'n_estimators': 487, 'max_depth': 7, 'subsample': 0.6571556034544709, 'colsample_bytree': 0.8631185675736756, 'reg_alpha': 0.018481227937418576, 'reg_lambda': 0.0867970969306405}. Best is trial 1 with value: 0.03448275862068961.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:08:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:08:04,032] Trial 16 finished with value: 0.04741379310344829 and parameters: {'learning_rate': 0.039806850743782055, 'n_estimators': 216, 'max_depth': 10, 'subsample': 0.7504882239812725, 'colsample_bytree': 0.6030180565495001, 'reg_alpha': 0.05475523346200175, 'reg_lambda': 0.001289673732919776}. Best is trial 1 with value: 0.03448275862068961.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:08:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:08:04,578] Trial 17 finished with value: 0.0431034482758621 and parameters: {'learning_rate': 0.019308037503970924, 'n_estimators': 332, 'max_depth': 9, 'subsample': 0.9956583201880389, 'colsample_bytree': 0.8130463125563132, 'reg_alpha': 0.004113917565915918, 'reg_lambda': 0.008270618683796839}. Best is trial 1 with value: 0.03448275862068961.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:08:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:08:05,361] Trial 18 finished with value: 0.051724137931034475 and parameters: {'learning_rate': 0.02587465703116386, 'n_estimators': 551, 'max_depth': 12, 'subsample': 0.8502136078050537, 'colsample_bytree': 0.7312492778815421, 'reg_alpha': 2.354016179123494, 'reg_lambda': 2.2690847893564223}. Best is trial 1 with value: 0.03448275862068961.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:08:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:08:05,840] Trial 19 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.012147903354181568, 'n_estimators': 408, 'max_depth': 6, 'subsample': 0.7914379245979667, 'colsample_bytree': 0.7087477756773869, 'reg_alpha': 0.34021483586043233, 'reg_lambda': 0.2511479378950862}. Best is trial 1 with value: 0.03448275862068961.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:08:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:08:06,004] Trial 20 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.2898329754839357, 'n_estimators': 155, 'max_depth': 10, 'subsample': 0.6420272857911655, 'colsample_bytree': 0.8961457012692352, 'reg_alpha': 0.030762115037497005, 'reg_lambda': 0.028019696681816635}. Best is trial 20 with value: 0.030172413793103425.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:08:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:08:06,206] Trial 21 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.2556988093239921, 'n_estimators': 186, 'max_depth': 10, 'subsample': 0.6406046553019469, 'colsample_bytree': 0.8817201348135812, 'reg_alpha': 0.0010306270182141855, 'reg_lambda': 0.03805441264879786}. Best is trial 20 with value: 0.030172413793103425.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:08:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:08:06,387] Trial 22 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.29195685125386167, 'n_estimators': 171, 'max_depth': 11, 'subsample': 0.6380740353035241, 'colsample_bytree': 0.8979483949389018, 'reg_alpha': 0.0010507085601924066, 'reg_lambda': 0.02399888219629935}. Best is trial 20 with value: 0.030172413793103425.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:08:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:08:06,568] Trial 23 finished with value: 0.05603448275862066 and parameters: {'learning_rate': 0.2980885558242101, 'n_estimators': 164, 'max_depth': 11, 'subsample': 0.6304084173199852, 'colsample_bytree': 0.917965620561487, 'reg_alpha': 0.00345424786414116, 'reg_lambda': 0.028805000787021275}. Best is trial 20 with value: 0.030172413793103425.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:08:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:08:06,769] Trial 24 finished with value: 0.0431034482758621 and parameters: {'learning_rate': 0.28071655649489596, 'n_estimators': 186, 'max_depth': 12, 'subsample': 0.712469040821946, 'colsample_bytree': 0.8843387823103014, 'reg_alpha': 0.009868470647950016, 'reg_lambda': 0.08907402777925436}. Best is trial 20 with value: 0.030172413793103425.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:08:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:08:07,083] Trial 25 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.1834389532826162, 'n_estimators': 322, 'max_depth': 10, 'subsample': 0.6532685707195998, 'colsample_bytree': 0.8949203757891415, 'reg_alpha': 0.0025490202500898563, 'reg_lambda': 0.018956450540141168}. Best is trial 20 with value: 0.030172413793103425.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:08:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:08:07,365] Trial 26 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.15375798746140018, 'n_estimators': 260, 'max_depth': 11, 'subsample': 0.6312088564617687, 'colsample_bytree': 0.8283991223123279, 'reg_alpha': 0.0011426599073272497, 'reg_lambda': 0.00398834261436661}. Best is trial 20 with value: 0.030172413793103425.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:08:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:08:07,508] Trial 27 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.22834346653836926, 'n_estimators': 105, 'max_depth': 9, 'subsample': 0.6912083773768379, 'colsample_bytree': 0.89353087551014, 'reg_alpha': 0.030509344297770063, 'reg_lambda': 0.055395630600094024}. Best is trial 20 with value: 0.030172413793103425.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:08:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:08:07,734] Trial 28 finished with value: 0.04741379310344829 and parameters: {'learning_rate': 0.1499789177042926, 'n_estimators': 173, 'max_depth': 11, 'subsample': 0.6380780597313224, 'colsample_bytree': 0.9737119893270956, 'reg_alpha': 0.00674445719661394, 'reg_lambda': 0.01523038540305701}. Best is trial 20 with value: 0.030172413793103425.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:08:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:08:08,231] Trial 29 finished with value: 0.0431034482758621 and parameters: {'learning_rate': 0.11923901860934641, 'n_estimators': 506, 'max_depth': 10, 'subsample': 0.6086909586431699, 'colsample_bytree': 0.9230739115290816, 'reg_alpha': 0.5564211519782086, 'reg_lambda': 0.009034485413208983}. Best is trial 20 with value: 0.030172413793103425.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:08:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:08:08,554] Trial 30 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.2333402034703664, 'n_estimators': 361, 'max_depth': 12, 'subsample': 0.6932428958846113, 'colsample_bytree': 0.879337472095718, 'reg_alpha': 0.014935769846656597, 'reg_lambda': 0.14488625485616866}. Best is trial 20 with value: 0.030172413793103425.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:08:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:08:08,844] Trial 31 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.16758493948080236, 'n_estimators': 274, 'max_depth': 11, 'subsample': 0.6361320766687943, 'colsample_bytree': 0.8278006450533835, 'reg_alpha': 0.0014563809144707315, 'reg_lambda': 0.003952978632835842}. Best is trial 20 with value: 0.030172413793103425.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:08:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:08:09,143] Trial 32 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.10400793414667776, 'n_estimators': 223, 'max_depth': 11, 'subsample': 0.6414229743514657, 'colsample_bytree': 0.8255851572947552, 'reg_alpha': 0.0012669260810238756, 'reg_lambda': 0.0044276114517771276}. Best is trial 20 with value: 0.030172413793103425.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:08:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:08:09,321] Trial 33 finished with value: 0.0431034482758621 and parameters: {'learning_rate': 0.2503564948885686, 'n_estimators': 152, 'max_depth': 9, 'subsample': 0.729831554562286, 'colsample_bytree': 0.9088944758294615, 'reg_alpha': 0.0024352296482794823, 'reg_lambda': 0.01885874296931104}. Best is trial 20 with value: 0.030172413793103425.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:08:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:08:09,621] Trial 34 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.18976913284719302, 'n_estimators': 272, 'max_depth': 10, 'subsample': 0.619417005870319, 'colsample_bytree': 0.8409750635530008, 'reg_alpha': 0.006035593843848629, 'reg_lambda': 0.0024490554037041898}. Best is trial 20 with value: 0.030172413793103425.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:08:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:08:09,937] Trial 35 finished with value: 0.04741379310344829 and parameters: {'learning_rate': 0.0786910999475122, 'n_estimators': 204, 'max_depth': 12, 'subsample': 0.6969287629824067, 'colsample_bytree': 0.7793081360628785, 'reg_alpha': 0.0010648740621746428, 'reg_lambda': 0.011004703944923668}. Best is trial 20 with value: 0.030172413793103425.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:08:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:08:10,130] Trial 36 finished with value: 0.05603448275862066 and parameters: {'learning_rate': 0.2948886342038274, 'n_estimators': 148, 'max_depth': 11, 'subsample': 0.7445625346518383, 'colsample_bytree': 0.8731438045923289, 'reg_alpha': 0.003831069573959624, 'reg_lambda': 0.0484479967335234}. Best is trial 20 with value: 0.030172413793103425.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:08:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:08:10,757] Trial 37 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.1544544305495391, 'n_estimators': 772, 'max_depth': 9, 'subsample': 0.6004223274698955, 'colsample_bytree': 0.9600560320292983, 'reg_alpha': 0.0010381477934858826, 'reg_lambda': 0.12908245815008007}. Best is trial 20 with value: 0.030172413793103425.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:08:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:08:11,048] Trial 38 finished with value: 0.0431034482758621 and parameters: {'learning_rate': 0.24695714547412653, 'n_estimators': 256, 'max_depth': 10, 'subsample': 0.6590402895841043, 'colsample_bytree': 0.7941091084840635, 'reg_alpha': 0.0022483050369964137, 'reg_lambda': 0.026563216280779317}. Best is trial 20 with value: 0.030172413793103425.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:08:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:08:11,534] Trial 39 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.2002571810278531, 'n_estimators': 595, 'max_depth': 8, 'subsample': 0.9142078951131891, 'colsample_bytree': 0.9439211805029408, 'reg_alpha': 0.011804652112623878, 'reg_lambda': 0.005193223834279467}. Best is trial 20 with value: 0.030172413793103425.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:08:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:08:12,025] Trial 40 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.09976339800099723, 'n_estimators': 482, 'max_depth': 12, 'subsample': 0.6735165128778124, 'colsample_bytree': 0.9061523732137035, 'reg_alpha': 0.0017651607080509536, 'reg_lambda': 0.002265500787550066}. Best is trial 20 with value: 0.030172413793103425.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:08:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:08:12,936] Trial 41 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.05348708368201844, 'n_estimators': 965, 'max_depth': 10, 'subsample': 0.9527360115017347, 'colsample_bytree': 0.9972816176265268, 'reg_alpha': 0.0034008884300300397, 'reg_lambda': 0.0011189165311641706}. Best is trial 20 with value: 0.030172413793103425.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:08:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:08:13,093] Trial 42 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.256483012329244, 'n_estimators': 139, 'max_depth': 6, 'subsample': 0.8452977657806141, 'colsample_bytree': 0.9424014065220598, 'reg_alpha': 0.0010112666086328694, 'reg_lambda': 0.0016613830676719197}. Best is trial 20 with value: 0.030172413793103425.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:08:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:08:13,330] Trial 43 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.2060144941739253, 'n_estimators': 210, 'max_depth': 8, 'subsample': 0.7785546049144572, 'colsample_bytree': 0.9779992488044027, 'reg_alpha': 0.0018640612633179332, 'reg_lambda': 0.0029408151818450306}. Best is trial 20 with value: 0.030172413793103425.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:08:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:08:13,741] Trial 44 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.010093242750622159, 'n_estimators': 291, 'max_depth': 7, 'subsample': 0.6237800370792439, 'colsample_bytree': 0.8620557380940289, 'reg_alpha': 0.004498843029124924, 'reg_lambda': 0.006030890937426987}. Best is trial 20 with value: 0.030172413793103425.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:08:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:08:14,058] Trial 45 finished with value: 0.0431034482758621 and parameters: {'learning_rate': 0.06014089938295306, 'n_estimators': 191, 'max_depth': 11, 'subsample': 0.685010144226736, 'colsample_bytree': 0.8309367288505112, 'reg_alpha': 0.007245409615610886, 'reg_lambda': 0.05586615777295208}. Best is trial 20 with value: 0.030172413793103425.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:08:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:08:14,172] Trial 46 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.13929754111017653, 'n_estimators': 107, 'max_depth': 4, 'subsample': 0.6515682068441776, 'colsample_bytree': 0.9246929647350606, 'reg_alpha': 0.0017196867901670305, 'reg_lambda': 0.3769907287476439}. Best is trial 20 with value: 0.030172413793103425.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:08:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:08:14,754] Trial 47 finished with value: 0.04741379310344829 and parameters: {'learning_rate': 0.015165994208302877, 'n_estimators': 346, 'max_depth': 9, 'subsample': 0.8173258024936594, 'colsample_bytree': 0.9653414609491655, 'reg_alpha': 0.002721084960235962, 'reg_lambda': 0.012910626770010872}. Best is trial 20 with value: 0.030172413793103425.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:08:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:08:15,039] Trial 48 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.1748362597621699, 'n_estimators': 247, 'max_depth': 11, 'subsample': 0.7271692941075224, 'colsample_bytree': 0.7883205167391969, 'reg_alpha': 0.06832990111314152, 'reg_lambda': 0.024117141492290245}. Best is trial 20 with value: 0.030172413793103425.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:08:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:08:15,238] Trial 49 finished with value: 0.0431034482758621 and parameters: {'learning_rate': 0.06583717637038715, 'n_estimators': 141, 'max_depth': 7, 'subsample': 0.6620019876629233, 'colsample_bytree': 0.8505663483960055, 'reg_alpha': 0.33175624077157856, 'reg_lambda': 0.0394932644240221}. Best is trial 20 with value: 0.030172413793103425.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:\n",
      "{'learning_rate': 0.2898329754839357, 'n_estimators': 155, 'max_depth': 10, 'subsample': 0.6420272857911655, 'colsample_bytree': 0.8961457012692352, 'reg_alpha': 0.030762115037497005, 'reg_lambda': 0.028019696681816635}\n",
      "Best accuracy:\n",
      "0.9698275862068966\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')  # Because we return 1 - accuracy\n",
    "study.optimize(objective, n_trials=50)  # Try 50 combinations (or more!)\n",
    "\n",
    "print(\"Best hyperparameters:\")\n",
    "print(study.best_params)\n",
    "\n",
    "print(\"Best accuracy:\")\n",
    "print(1 - study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d987a845-bcd2-413a-a95c-a94b4fa09b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final evaluation on test set:\n",
      "Accuracy: 96.98\n",
      "Precision: 94.64\n",
      "Recall: 92.98\n",
      "F1 Score: 93.81\n"
     ]
    }
   ],
   "source": [
    "# Get the data\n",
    "best_model = xgb.XGBClassifier(**study.best_params)\n",
    "best_model.fit(x_train, y_train,\n",
    "          eval_set=[(x_test, y_test)],\n",
    "          verbose=False)\n",
    "\n",
    "# Predict\n",
    "preds = best_model.predict(x_test)\n",
    "\n",
    "# Compute final scores\n",
    "acc = accuracy_score(y_test, preds)\n",
    "precision = precision_score(y_test, preds, average='binary')\n",
    "recall = recall_score(y_test, preds, average='binary')\n",
    "f1 = f1_score(y_test, preds, average='binary')\n",
    "\n",
    "print(\"\\nFinal evaluation on test set:\")\n",
    "print(f\"Accuracy: {acc * 100:.2f}\")\n",
    "print(f\"Precision: {precision * 100:.2f}\")\n",
    "print(f\"Recall: {recall * 100:.2f}\")\n",
    "print(f\"F1 Score: {f1 * 100:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a982119c-232f-43ee-b678-67684a13f1ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8062338e-9afb-4414-b928-c924f41ca993",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
