{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae468260-b8b2-419c-9917-d9aeee35901f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import optuna\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "import joblib\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20864616-0095-40a0-94bc-c10071e3900e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load both datasets\n",
    "original = pd.read_csv(\"PCOS_data.csv\")\n",
    "new = pd.read_csv(\"pcos_dataset.csv\")\n",
    "\n",
    "# Set max columns to show is unlimited\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da865d79-aa70-4b23-9d0a-2b45791d685b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df = df.copy()  # avoid SettingWithCopyWarning\n",
    "\n",
    "    # 1. Clean column names\n",
    "    df.columns = df.columns.str.strip() \\\n",
    "                           .str.replace(' ', '_') \\\n",
    "                           .str.replace('(', '') \\\n",
    "                           .str.replace(')', '') \\\n",
    "                           .str.replace('.', '') \\\n",
    "                           .str.replace('-', '_') \\\n",
    "                           .str.replace('/', '_')\n",
    "    df.rename(columns={'II____beta_HCGmIU_mL': 'II_beta_HCG'}, inplace=True)\n",
    "\n",
    "    # 2. Drop irrelevant columns\n",
    "    df.drop(columns=['Sl_No', 'Patient_File_No'], inplace=True, errors='ignore')\n",
    "    df = df.loc[:, ~df.columns.str.startswith('Unnamed')]\n",
    "\n",
    "    # 3. Merge Age columns\n",
    "    if 'Age' not in df.columns and 'Age_yrs' in df.columns:\n",
    "        df.rename(columns={'Age_yrs': 'Age'}, inplace=True)\n",
    "    elif 'Age' in df.columns and 'Age_yrs' in df.columns:\n",
    "        df['Age'] = df['Age'].fillna(df['Age_yrs'])\n",
    "        df.drop(columns=['Age_yrs'], inplace=True)\n",
    "\n",
    "    # 4. Merge PCOS diagnosis columns\n",
    "    if 'PCOS_Diagnosis' in df.columns:\n",
    "        df.rename(columns={'PCOS_Diagnosis': 'PCOS_Y_N'}, inplace=True)\n",
    "\n",
    "    # 5. Handle missing values\n",
    "    if 'Marraige_Status_Yrs' in df.columns:\n",
    "        df.loc[:, 'Marraige_Status_Yrs'] = df['Marraige_Status_Yrs'].fillna(df['Marraige_Status_Yrs'].median())\n",
    "\n",
    "    if 'Fast_food_Y_N' not in df.columns and 'Fast_food_YN' in df.columns:\n",
    "        df.rename(columns={'Fast_food_YN': 'Fast_food_Y_N'}, inplace=True)\n",
    "    if 'Fast_food_Y_N' in df.columns:\n",
    "        df.loc[:, 'Fast_food_Y_N'] = df['Fast_food_Y_N'].fillna(df['Fast_food_Y_N'].mode()[0])\n",
    "\n",
    "    # 6. Convert to numeric and fill missing values\n",
    "    if 'II_beta_HCG' not in df.columns and 'II_beta_HCGmIU_mL' in df.columns:\n",
    "        df.rename(columns={'II_beta_HCGmIU_mL': 'II_beta_HCG'}, inplace=True)\n",
    "    if 'II_beta_HCG' in df.columns:\n",
    "        df.loc[:, 'II_beta_HCG'] = pd.to_numeric(df['II_beta_HCG'], errors='coerce')\n",
    "        df['II_beta_HCG'] = df['II_beta_HCG'].astype(float)\n",
    "        df.loc[:, 'II_beta_HCG'] = df['II_beta_HCG'].fillna(df['II_beta_HCG'].median())\n",
    "\n",
    "    if 'AMHng_mL' in df.columns:\n",
    "        df.loc[:, 'AMHng_mL'] = pd.to_numeric(df['AMHng_mL'], errors='coerce')\n",
    "        df['AMHng_mL'] = df['AMHng_mL'].astype(float)\n",
    "        df.loc[:, 'AMHng_mL'] = df['AMHng_mL'].fillna(df['AMHng_mL'].median())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9783e46b-bfee-4ba4-96d8-1c2241513935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing\n",
    "original_clean = preprocess(original)\n",
    "new_clean = preprocess(new)\n",
    "\n",
    "# Ensure consistent columns across both\n",
    "all_columns = list(set(original_clean.columns).union(set(new_clean.columns)))\n",
    "\n",
    "# Align both dataframes to same columns, fill missing with NaN\n",
    "original_aligned = original_clean.reindex(columns=all_columns)\n",
    "new_aligned = new_clean.reindex(columns=all_columns)\n",
    "\n",
    "# Concatenate datasets\n",
    "combined_df = pd.concat([original_aligned, new_aligned], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26bdf1a3-5c90-4ba1-b3f9-38b2694f3892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "# X = combined_df.drop(columns=['PCOS_Y_N'])\n",
    "X = combined_df.drop(columns=['PCOS_Y_N'])\n",
    "y = combined_df['PCOS_Y_N']\n",
    "\n",
    "# Initialize KNNImputer (e.g., with 5 nearest neighbors)\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "X = pd.DataFrame(knn_imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Sanitize feature names\n",
    "X.columns = [str(col).replace(' ', '_')\n",
    "                        .replace('\"', '')\n",
    "                        .replace(\"'\", '')\n",
    "                        .replace('[', '')\n",
    "                        .replace(']', '')\n",
    "                        .replace('{', '')\n",
    "                        .replace('}', '')\n",
    "                        .replace(':', '')\n",
    "                        .replace(',', '')\n",
    "                        for col in X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5791e93-16c2-486c-9d03-954ec9896528",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(X_scaled, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd92e283-a614-4e61-a72b-cd5d9e74237e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 14 features.\n",
      "Index(['PimplesY_N', 'hair_growthY_N', 'Skin_darkening_Y_N', 'Follicle_No_R',\n",
      "       'Weight_gainY_N', 'Follicle_No_L', 'Antral_Follicle_Count',\n",
      "       'Testosterone_Levelng_dL', 'CycleR_I', 'BMI', 'Weight_Kg',\n",
      "       'Menstrual_Irregularity'],\n",
      "      dtype='object') 12\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBClassifier()\n",
    "rfecv = RFECV(estimator=model, step=2, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "rfecv.fit(X, y)\n",
    "selected_mask = rfecv.support_\n",
    "selected_features = X.columns[selected_mask]\n",
    "X = X[selected_features]\n",
    "print(selected_features, len(selected_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "591c6b7c-232c-40a2-90bd-56fdf0b29ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.15, stratify=y, shuffle=True, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6784b55-4a3d-4803-a10c-3282ab8bf03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    param = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-3, 10.0, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-3, 10.0, log=True),\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"random_state\": 8,\n",
    "        \"use_label_encoder\": False,\n",
    "    }\n",
    "\n",
    "    train_pool = xgb.DMatrix(x_train, y_train)\n",
    "    valid_pool = xgb.DMatrix(x_test, y_test)\n",
    "    \n",
    "    # Train model\n",
    "    model = xgb.XGBClassifier(**param)\n",
    "    model.fit(x_train, y_train,\n",
    "              eval_set=[(x_test, y_test)],\n",
    "              verbose=False)\n",
    "\n",
    "    # Predict\n",
    "    preds = model.predict(x_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "\n",
    "    return 1.0 - acc  # Optuna minimizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66bf6197-2c5f-4c7f-aab4-dccfe1e7becc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 20:59:37,976] A new study created in memory with name: no-name-b657a4ef-f360-4bfa-aab4-da44dec839ec\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:59:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:59:38,301] Trial 0 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.27814683344316166, 'n_estimators': 519, 'max_depth': 3, 'subsample': 0.6711641222374678, 'colsample_bytree': 0.7064889783835897, 'reg_alpha': 0.0036044286333795196, 'reg_lambda': 0.0784752062548219}. Best is trial 0 with value: 0.03448275862068961.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:59:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:59:39,281] Trial 1 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.011632948401606133, 'n_estimators': 788, 'max_depth': 11, 'subsample': 0.7020494919983379, 'colsample_bytree': 0.8125575462527871, 'reg_alpha': 3.6663988784856683, 'reg_lambda': 0.02303703260753649}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:59:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:59:39,752] Trial 2 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.03920013074607819, 'n_estimators': 446, 'max_depth': 6, 'subsample': 0.6713777752360132, 'colsample_bytree': 0.8862124972174906, 'reg_alpha': 0.9086951134017174, 'reg_lambda': 2.7704940404200133}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:59:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:59:39,973] Trial 3 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.0883707244421531, 'n_estimators': 153, 'max_depth': 9, 'subsample': 0.9902773040283304, 'colsample_bytree': 0.8274957972881404, 'reg_alpha': 0.00791918441109799, 'reg_lambda': 2.843451888315113}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:59:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:59:40,519] Trial 4 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.06288362765939441, 'n_estimators': 520, 'max_depth': 9, 'subsample': 0.779096885619173, 'colsample_bytree': 0.7983979029401409, 'reg_alpha': 0.13421325499287193, 'reg_lambda': 0.028976255959844446}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:59:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:59:40,765] Trial 5 finished with value: 0.0431034482758621 and parameters: {'learning_rate': 0.04165154179474176, 'n_estimators': 314, 'max_depth': 4, 'subsample': 0.9970687173658517, 'colsample_bytree': 0.69723791429098, 'reg_alpha': 0.037091911970284205, 'reg_lambda': 0.05378671035362889}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:59:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:59:40,863] Trial 6 finished with value: 0.051724137931034475 and parameters: {'learning_rate': 0.01295108382688694, 'n_estimators': 115, 'max_depth': 4, 'subsample': 0.683336840196623, 'colsample_bytree': 0.9912637210471337, 'reg_alpha': 1.3277795429175598, 'reg_lambda': 0.0010171262517832968}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:59:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:59:41,350] Trial 7 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.1514948754999416, 'n_estimators': 677, 'max_depth': 8, 'subsample': 0.9699483413314621, 'colsample_bytree': 0.9576554138310416, 'reg_alpha': 1.3726283204220944, 'reg_lambda': 1.9961234177257854}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:59:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:59:42,209] Trial 8 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.028881057234143262, 'n_estimators': 668, 'max_depth': 8, 'subsample': 0.9852919928528134, 'colsample_bytree': 0.790436042523951, 'reg_alpha': 0.012523438650378001, 'reg_lambda': 1.1683183573903473}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:59:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:59:42,677] Trial 9 finished with value: 0.0431034482758621 and parameters: {'learning_rate': 0.019135490490138508, 'n_estimators': 316, 'max_depth': 9, 'subsample': 0.673066540567294, 'colsample_bytree': 0.6405054131151551, 'reg_alpha': 0.002974020820439775, 'reg_lambda': 0.0035070754188089542}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:59:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:59:43,697] Trial 10 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.010388380312465705, 'n_estimators': 942, 'max_depth': 12, 'subsample': 0.7994181757358887, 'colsample_bytree': 0.8779522043845114, 'reg_alpha': 9.855792653595831, 'reg_lambda': 0.009743577004383129}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:59:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:59:44,861] Trial 11 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.022684774029520474, 'n_estimators': 996, 'max_depth': 12, 'subsample': 0.608058883499222, 'colsample_bytree': 0.8962589628076051, 'reg_alpha': 0.8523729685047038, 'reg_lambda': 0.4611186093778872}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:59:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:59:45,477] Trial 12 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.04181004482614068, 'n_estimators': 827, 'max_depth': 6, 'subsample': 0.7421547226715927, 'colsample_bytree': 0.8866075743118137, 'reg_alpha': 8.868877452226709, 'reg_lambda': 0.3097890242768806}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:59:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:59:46,091] Trial 13 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.08714987456220341, 'n_estimators': 740, 'max_depth': 6, 'subsample': 0.8808690749925675, 'colsample_bytree': 0.7450724594616243, 'reg_alpha': 0.28306222657388524, 'reg_lambda': 0.2418627711817796}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:59:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:59:46,504] Trial 14 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.015298475205166282, 'n_estimators': 375, 'max_depth': 6, 'subsample': 0.7208393086839007, 'colsample_bytree': 0.8424937811158726, 'reg_alpha': 3.691478265154199, 'reg_lambda': 9.646380726816627}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:59:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:59:47,082] Trial 15 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.02920315746299927, 'n_estimators': 429, 'max_depth': 11, 'subsample': 0.6134475815123969, 'colsample_bytree': 0.9223476911309328, 'reg_alpha': 0.4878015657298419, 'reg_lambda': 0.014502500066597366}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:59:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:59:47,804] Trial 16 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.13366919546521355, 'n_estimators': 859, 'max_depth': 10, 'subsample': 0.9008220167261236, 'colsample_bytree': 0.752042716322396, 'reg_alpha': 2.9034427841139228, 'reg_lambda': 7.136909761608024}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:59:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:59:48,466] Trial 17 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.03962647504859984, 'n_estimators': 613, 'max_depth': 7, 'subsample': 0.7288979389776566, 'colsample_bytree': 0.8417128542510676, 'reg_alpha': 0.0849728064056198, 'reg_lambda': 0.15209830188174958}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:59:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:59:49,214] Trial 18 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.0157254948615348, 'n_estimators': 787, 'max_depth': 5, 'subsample': 0.858748934653187, 'colsample_bytree': 0.9428420044923442, 'reg_alpha': 3.1199411670448076, 'reg_lambda': 0.8651267401848772}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:59:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:59:49,533] Trial 19 finished with value: 0.0431034482758621 and parameters: {'learning_rate': 0.06373952158556727, 'n_estimators': 217, 'max_depth': 10, 'subsample': 0.6529594417512692, 'colsample_bytree': 0.6002827403917281, 'reg_alpha': 0.341253290918583, 'reg_lambda': 0.005249678414682118}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:59:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:59:50,266] Trial 20 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.010268171928838776, 'n_estimators': 581, 'max_depth': 7, 'subsample': 0.7592913069684883, 'colsample_bytree': 0.7639990487838357, 'reg_alpha': 0.13773644408857447, 'reg_lambda': 0.026759316370432114}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:59:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:59:50,752] Trial 21 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.016240790350536875, 'n_estimators': 434, 'max_depth': 6, 'subsample': 0.721357415102353, 'colsample_bytree': 0.8450850156005647, 'reg_alpha': 2.3049707572853717, 'reg_lambda': 9.30811155394014}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:59:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:59:51,169] Trial 22 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.013045427540674783, 'n_estimators': 403, 'max_depth': 5, 'subsample': 0.7015460595036838, 'colsample_bytree': 0.8669518209709505, 'reg_alpha': 4.716080462150918, 'reg_lambda': 4.342527052405418}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:59:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:59:51,485] Trial 23 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.02552535414589278, 'n_estimators': 309, 'max_depth': 5, 'subsample': 0.639045151368716, 'colsample_bytree': 0.809298150523389, 'reg_alpha': 0.741812091550722, 'reg_lambda': 4.001778002057522}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:59:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:59:52,077] Trial 24 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.019244134560184332, 'n_estimators': 493, 'max_depth': 7, 'subsample': 0.8161399865995609, 'colsample_bytree': 0.9256219692558985, 'reg_alpha': 5.606006816087934, 'reg_lambda': 1.0966385734104795}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:59:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:59:52,366] Trial 25 finished with value: 0.0431034482758621 and parameters: {'learning_rate': 0.013726825246424502, 'n_estimators': 238, 'max_depth': 6, 'subsample': 0.7141812466215588, 'colsample_bytree': 0.8613221633596333, 'reg_alpha': 1.6623154882643087, 'reg_lambda': 9.34681529304465}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:59:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:59:52,790] Trial 26 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.0356432010546661, 'n_estimators': 368, 'max_depth': 8, 'subsample': 0.6375606078004864, 'colsample_bytree': 0.9024825191290504, 'reg_alpha': 4.525533768247057, 'reg_lambda': 0.5283368949559426}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:59:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:59:53,313] Trial 27 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.019641407400713698, 'n_estimators': 638, 'max_depth': 4, 'subsample': 0.7696856116449846, 'colsample_bytree': 0.7093975219289758, 'reg_alpha': 0.8065827072886371, 'reg_lambda': 2.474383801947781}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:59:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:59:53,963] Trial 28 finished with value: 0.0431034482758621 and parameters: {'learning_rate': 0.03113535379345668, 'n_estimators': 463, 'max_depth': 11, 'subsample': 0.6931560036115209, 'colsample_bytree': 0.8270322821256647, 'reg_alpha': 0.23078659970582746, 'reg_lambda': 0.11706898736534614}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:59:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:59:54,348] Trial 29 finished with value: 0.0431034482758621 and parameters: {'learning_rate': 0.010392947980975176, 'n_estimators': 552, 'max_depth': 3, 'subsample': 0.6546164099970904, 'colsample_bytree': 0.776808473609943, 'reg_alpha': 0.0010998549494844717, 'reg_lambda': 0.07594021836129262}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:59:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:59:54,821] Trial 30 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.04901228555701058, 'n_estimators': 721, 'max_depth': 3, 'subsample': 0.8328007852957457, 'colsample_bytree': 0.9782570291846434, 'reg_alpha': 2.1517469506074054, 'reg_lambda': 0.04096301659586998}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:59:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:59:55,439] Trial 31 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.021515314843107935, 'n_estimators': 538, 'max_depth': 7, 'subsample': 0.8145055673361616, 'colsample_bytree': 0.9242771868121108, 'reg_alpha': 5.324727361806368, 'reg_lambda': 1.055006137368827}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:59:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:59:55,697] Trial 32 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.27498445864641397, 'n_estimators': 487, 'max_depth': 7, 'subsample': 0.7478582442860987, 'colsample_bytree': 0.9226154080074271, 'reg_alpha': 7.019282560751718, 'reg_lambda': 5.298453736114744}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:59:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:59:56,104] Trial 33 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.017822348101793666, 'n_estimators': 357, 'max_depth': 6, 'subsample': 0.7952282802055399, 'colsample_bytree': 0.8202014586697394, 'reg_alpha': 4.427824779948652, 'reg_lambda': 1.7190603552713208}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:59:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:59:56,608] Trial 34 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.013277569438715456, 'n_estimators': 510, 'max_depth': 5, 'subsample': 0.8298172573919171, 'colsample_bytree': 0.8540670335105662, 'reg_alpha': 1.2047049787390947, 'reg_lambda': 0.6865960993667641}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:59:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:59:56,997] Trial 35 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.023783074187790843, 'n_estimators': 261, 'max_depth': 9, 'subsample': 0.9234741815984597, 'colsample_bytree': 0.9609824862709127, 'reg_alpha': 3.252390045912995, 'reg_lambda': 4.416181452165455}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:59:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:59:57,546] Trial 36 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.015000975298663557, 'n_estimators': 382, 'max_depth': 8, 'subsample': 0.6769506316866927, 'colsample_bytree': 0.7977906120441998, 'reg_alpha': 0.04573292564924432, 'reg_lambda': 1.6683818298033481}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:59:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:59:57,822] Trial 37 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.0585060200181918, 'n_estimators': 186, 'max_depth': 7, 'subsample': 0.7117283773461633, 'colsample_bytree': 0.9063821521815031, 'reg_alpha': 0.4430494327375341, 'reg_lambda': 3.152585956300324}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:59:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:59:58,331] Trial 38 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.07409813850463401, 'n_estimators': 454, 'max_depth': 9, 'subsample': 0.7348789548248335, 'colsample_bytree': 0.7189739821091289, 'reg_alpha': 1.5739864060516606, 'reg_lambda': 0.0016940238991638582}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:59:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:59:58,812] Trial 39 finished with value: 0.0431034482758621 and parameters: {'learning_rate': 0.012510297671979809, 'n_estimators': 582, 'max_depth': 4, 'subsample': 0.7836531153486025, 'colsample_bytree': 0.9462028714144535, 'reg_alpha': 6.814893675714473, 'reg_lambda': 0.01990672438068039}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:59:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:59:59,141] Trial 40 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.12009167441099591, 'n_estimators': 299, 'max_depth': 8, 'subsample': 0.657789093622674, 'colsample_bytree': 0.8849316268997367, 'reg_alpha': 0.01462753545389309, 'reg_lambda': 0.007586755917718815}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:59:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 20:59:59,759] Trial 41 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.021501069448212885, 'n_estimators': 523, 'max_depth': 7, 'subsample': 0.8309602564181052, 'colsample_bytree': 0.9219740168601926, 'reg_alpha': 5.21708528706747, 'reg_lambda': 0.9955771364987686}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [20:59:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:00:00,323] Trial 42 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.017981142552795284, 'n_estimators': 551, 'max_depth': 6, 'subsample': 0.8151810554782283, 'colsample_bytree': 0.9856022641678027, 'reg_alpha': 8.763517678911969, 'reg_lambda': 1.2897433563166312}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:00:00,928] Trial 43 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.026231387891001726, 'n_estimators': 493, 'max_depth': 7, 'subsample': 0.8558699216933243, 'colsample_bytree': 0.9309609418427099, 'reg_alpha': 3.3470292469661374, 'reg_lambda': 2.4086702291934476}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:00:01,767] Trial 44 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.03425745099716303, 'n_estimators': 697, 'max_depth': 8, 'subsample': 0.7600385849107993, 'colsample_bytree': 0.8752837562847594, 'reg_alpha': 1.0759721244838656, 'reg_lambda': 0.28140529333200553}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:00:02,979] Trial 45 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.02004285666328247, 'n_estimators': 908, 'max_depth': 10, 'subsample': 0.8131050067758694, 'colsample_bytree': 0.8378365009141641, 'reg_alpha': 2.09205136143341, 'reg_lambda': 6.494446722823378}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:00:03,452] Trial 46 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.05068751818564457, 'n_estimators': 651, 'max_depth': 5, 'subsample': 0.7835782401943157, 'colsample_bytree': 0.9066332161274224, 'reg_alpha': 5.921546395005157, 'reg_lambda': 0.42043663351896193}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:00:03,874] Trial 47 finished with value: 0.03879310344827591 and parameters: {'learning_rate': 0.011790467921728554, 'n_estimators': 346, 'max_depth': 6, 'subsample': 0.8652696072044318, 'colsample_bytree': 0.9539641589892437, 'reg_alpha': 0.588118033895607, 'reg_lambda': 0.19230396421885082}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:00:04,373] Trial 48 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.01574948992581491, 'n_estimators': 412, 'max_depth': 7, 'subsample': 0.6979239896164474, 'colsample_bytree': 0.9987077038533954, 'reg_alpha': 9.541035069735653, 'reg_lambda': 0.06737883781720955}. Best is trial 1 with value: 0.025862068965517238.\n",
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-31 21:00:05,291] Trial 49 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.02216610099951264, 'n_estimators': 752, 'max_depth': 11, 'subsample': 0.675600853206965, 'colsample_bytree': 0.7835106343725472, 'reg_alpha': 3.371157769608839, 'reg_lambda': 3.3060693678158617}. Best is trial 1 with value: 0.025862068965517238.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:\n",
      "{'learning_rate': 0.011632948401606133, 'n_estimators': 788, 'max_depth': 11, 'subsample': 0.7020494919983379, 'colsample_bytree': 0.8125575462527871, 'reg_alpha': 3.6663988784856683, 'reg_lambda': 0.02303703260753649}\n",
      "Best accuracy:\n",
      "0.9741379310344828\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')  # Because we return 1 - accuracy\n",
    "study.optimize(objective, n_trials=50)  # Try 50 combinations (or more!)\n",
    "\n",
    "print(\"Best hyperparameters:\")\n",
    "print(study.best_params)\n",
    "\n",
    "print(\"Best accuracy:\")\n",
    "print(1 - study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ee6f2c7-8de9-4f67-8563-47ca783fa4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final evaluation on test set:\n",
      "Accuracy: 96.55\n",
      "Precision: 94.55\n",
      "Recall: 91.23\n",
      "F1 Score: 92.86\n"
     ]
    }
   ],
   "source": [
    "# Get the data\n",
    "best_model = xgb.XGBClassifier(**study.best_params)\n",
    "best_model.fit(x_train, y_train,\n",
    "          eval_set=[(x_test, y_test)],\n",
    "          verbose=False)\n",
    "\n",
    "# Predict\n",
    "preds = best_model.predict(x_test)\n",
    "\n",
    "# Compute final scores\n",
    "acc = accuracy_score(y_test, preds)\n",
    "precision = precision_score(y_test, preds, average='binary')\n",
    "recall = recall_score(y_test, preds, average='binary')\n",
    "f1 = f1_score(y_test, preds, average='binary')\n",
    "\n",
    "print(\"\\nFinal evaluation on test set:\")\n",
    "print(f\"Accuracy: {acc * 100:.2f}\")\n",
    "print(f\"Precision: {precision * 100:.2f}\")\n",
    "print(f\"Recall: {recall * 100:.2f}\")\n",
    "print(f\"F1 Score: {f1 * 100:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338a5f6d-82c1-4a1a-9c01-b306d1e0ee08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5816be-2d7b-4abf-a359-6d838855d774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce3c2ed-a3c2-4394-8792-acd1feba51ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
