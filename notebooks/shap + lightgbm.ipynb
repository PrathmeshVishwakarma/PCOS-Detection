{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d46d700-2151-46eb-8fad-f9f355bf2748",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "import joblib\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d31e9c7e-598e-4469-8070-e103f4fb11a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load both datasets\n",
    "original = pd.read_csv(\"../PCOS_data.csv\")\n",
    "new = pd.read_csv(\"../pcos_dataset.csv\")\n",
    "\n",
    "# Set max columns to show is unlimited\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6c44f3e-fcdd-496d-a01f-417712f275c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df = df.copy()  # avoid SettingWithCopyWarning\n",
    "\n",
    "    # 1. Clean column names\n",
    "    df.columns = df.columns.str.strip() \\\n",
    "                           .str.replace(' ', '_') \\\n",
    "                           .str.replace('(', '') \\\n",
    "                           .str.replace(')', '') \\\n",
    "                           .str.replace('.', '') \\\n",
    "                           .str.replace('-', '_') \\\n",
    "                           .str.replace('/', '_')\n",
    "    df.rename(columns={'II____beta_HCGmIU_mL': 'II_beta_HCG'}, inplace=True)\n",
    "\n",
    "    # 2. Drop irrelevant columns\n",
    "    df.drop(columns=['Sl_No', 'Patient_File_No'], inplace=True, errors='ignore')\n",
    "    df = df.loc[:, ~df.columns.str.startswith('Unnamed')]\n",
    "\n",
    "    # 3. Merge Age columns\n",
    "    if 'Age' not in df.columns and 'Age_yrs' in df.columns:\n",
    "        df.rename(columns={'Age_yrs': 'Age'}, inplace=True)\n",
    "    elif 'Age' in df.columns and 'Age_yrs' in df.columns:\n",
    "        df['Age'] = df['Age'].fillna(df['Age_yrs'])\n",
    "        df.drop(columns=['Age_yrs'], inplace=True)\n",
    "\n",
    "    # 4. Merge PCOS diagnosis columns\n",
    "    if 'PCOS_Diagnosis' in df.columns:\n",
    "        df.rename(columns={'PCOS_Diagnosis': 'PCOS_Y_N'}, inplace=True)\n",
    "\n",
    "    # 5. Handle missing values\n",
    "    if 'Marraige_Status_Yrs' in df.columns:\n",
    "        df.loc[:, 'Marraige_Status_Yrs'] = df['Marraige_Status_Yrs'].fillna(df['Marraige_Status_Yrs'].median())\n",
    "\n",
    "    if 'Fast_food_Y_N' not in df.columns and 'Fast_food_YN' in df.columns:\n",
    "        df.rename(columns={'Fast_food_YN': 'Fast_food_Y_N'}, inplace=True)\n",
    "    if 'Fast_food_Y_N' in df.columns:\n",
    "        df.loc[:, 'Fast_food_Y_N'] = df['Fast_food_Y_N'].fillna(df['Fast_food_Y_N'].mode()[0])\n",
    "\n",
    "    # 6. Convert to numeric and fill missing values\n",
    "    if 'II_beta_HCG' not in df.columns and 'II_beta_HCGmIU_mL' in df.columns:\n",
    "        df.rename(columns={'II_beta_HCGmIU_mL': 'II_beta_HCG'}, inplace=True)\n",
    "    if 'II_beta_HCG' in df.columns:\n",
    "        df.loc[:, 'II_beta_HCG'] = pd.to_numeric(df['II_beta_HCG'], errors='coerce')\n",
    "        df['II_beta_HCG'] = df['II_beta_HCG'].astype(float)\n",
    "        df.loc[:, 'II_beta_HCG'] = df['II_beta_HCG'].fillna(df['II_beta_HCG'].median())\n",
    "\n",
    "    if 'AMHng_mL' in df.columns:\n",
    "        df.loc[:, 'AMHng_mL'] = pd.to_numeric(df['AMHng_mL'], errors='coerce')\n",
    "        df['AMHng_mL'] = df['AMHng_mL'].astype(float)\n",
    "        df.loc[:, 'AMHng_mL'] = df['AMHng_mL'].fillna(df['AMHng_mL'].median())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c98b85c-aeb8-4dcc-b003-5ddbb99d778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing\n",
    "original_clean = preprocess(original)\n",
    "new_clean = preprocess(new)\n",
    "\n",
    "# Ensure consistent columns across both\n",
    "all_columns = list(set(original_clean.columns).union(set(new_clean.columns)))\n",
    "\n",
    "# Align both dataframes to same columns, fill missing with NaN\n",
    "original_aligned = original_clean.reindex(columns=all_columns)\n",
    "new_aligned = new_clean.reindex(columns=all_columns)\n",
    "\n",
    "# Concatenate datasets\n",
    "combined_df = pd.concat([original_aligned, new_aligned], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fdb9360-88b7-489b-aa69-7f1b0cfd2811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "# X = combined_df.drop(columns=['PCOS_Y_N'])\n",
    "X = combined_df.drop(columns=['PCOS_Y_N'])\n",
    "y = combined_df['PCOS_Y_N']\n",
    "\n",
    "# Initialize KNNImputer (e.g., with 5 nearest neighbors)\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "X = pd.DataFrame(knn_imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Sanitize feature names\n",
    "X.columns = [str(col).replace(' ', '_')\n",
    "                        .replace('\"', '')\n",
    "                        .replace(\"'\", '')\n",
    "                        .replace('[', '')\n",
    "                        .replace(']', '')\n",
    "                        .replace('{', '')\n",
    "                        .replace('}', '')\n",
    "                        .replace(':', '')\n",
    "                        .replace(',', '')\n",
    "                        for col in X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d5c242f-5d4a-447d-a275-205eb9cf516c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(X_scaled, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52242187-2c82-4fab-ae7c-c0c52583a69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 376, number of negative: 1165\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000335 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4644\n",
      "[LightGBM] [Info] Number of data points in the train set: 1541, number of used features: 44\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243997 -> initscore=-1.130887\n",
      "[LightGBM] [Info] Start training from score -1.130887\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LGBMClassifier</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model = lgb.LGBMClassifier()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a20d1fe-7615-4a5e-b283-963d6741f97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prathmesh/asep_project/venv/lib/python3.11/site-packages/shap/explainers/_tree.py:583: UserWarning: LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87b86e73-d006-41df-8466-6a5474b69a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_df = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': np.abs(shap_values).mean(axis=0)\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Select top N features\n",
    "top_features = shap_df['feature'].head(20).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57250382-18d5-4361-baff-e8d66b54fae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Menstrual_Irregularity',\n",
       " 'Testosterone_Levelng_dL',\n",
       " 'BMI',\n",
       " 'Antral_Follicle_Count',\n",
       " 'Follicle_No_R',\n",
       " 'Weight_gainY_N',\n",
       " 'hair_growthY_N',\n",
       " 'Skin_darkening_Y_N',\n",
       " 'Follicle_No_L',\n",
       " 'CycleR_I',\n",
       " 'AMHng_mL',\n",
       " 'PimplesY_N',\n",
       " 'Weight_Kg',\n",
       " 'Waistinch',\n",
       " 'Fast_food_Y_N',\n",
       " 'Avg_F_size_L_mm',\n",
       " 'FSHmIU_mL',\n",
       " 'PRLng_mL',\n",
       " 'RBSmg_dl',\n",
       " 'Hipinch']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "965849a1-f97b-457e-b623-14eb9186fb21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Menstrual_Irregularity</th>\n",
       "      <th>Testosterone_Levelng_dL</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Antral_Follicle_Count</th>\n",
       "      <th>Follicle_No_R</th>\n",
       "      <th>Weight_gainY_N</th>\n",
       "      <th>hair_growthY_N</th>\n",
       "      <th>Skin_darkening_Y_N</th>\n",
       "      <th>Follicle_No_L</th>\n",
       "      <th>CycleR_I</th>\n",
       "      <th>AMHng_mL</th>\n",
       "      <th>PimplesY_N</th>\n",
       "      <th>Weight_Kg</th>\n",
       "      <th>Waistinch</th>\n",
       "      <th>Fast_food_Y_N</th>\n",
       "      <th>Avg_F_size_L_mm</th>\n",
       "      <th>FSHmIU_mL</th>\n",
       "      <th>PRLng_mL</th>\n",
       "      <th>RBSmg_dl</th>\n",
       "      <th>Hipinch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.656317</td>\n",
       "      <td>0.921543</td>\n",
       "      <td>-1.339000</td>\n",
       "      <td>-0.416229</td>\n",
       "      <td>-1.125957</td>\n",
       "      <td>-1.086229</td>\n",
       "      <td>-0.946673</td>\n",
       "      <td>-0.985749</td>\n",
       "      <td>-1.007449</td>\n",
       "      <td>-0.958462</td>\n",
       "      <td>-0.907123</td>\n",
       "      <td>-1.401700</td>\n",
       "      <td>-1.587199</td>\n",
       "      <td>-1.506695</td>\n",
       "      <td>1.304546</td>\n",
       "      <td>1.252232</td>\n",
       "      <td>-0.019464</td>\n",
       "      <td>2.150797</td>\n",
       "      <td>-0.557131</td>\n",
       "      <td>-0.860948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.745139</td>\n",
       "      <td>-0.682661</td>\n",
       "      <td>-0.159445</td>\n",
       "      <td>-0.550597</td>\n",
       "      <td>-0.499205</td>\n",
       "      <td>-1.086229</td>\n",
       "      <td>-0.946673</td>\n",
       "      <td>-0.985749</td>\n",
       "      <td>-1.007449</td>\n",
       "      <td>-0.958462</td>\n",
       "      <td>-1.035045</td>\n",
       "      <td>-1.401700</td>\n",
       "      <td>0.187214</td>\n",
       "      <td>-0.849850</td>\n",
       "      <td>-1.445529</td>\n",
       "      <td>0.057427</td>\n",
       "      <td>-0.028435</td>\n",
       "      <td>-0.316955</td>\n",
       "      <td>-0.557131</td>\n",
       "      <td>-0.260730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.123469</td>\n",
       "      <td>0.413190</td>\n",
       "      <td>-0.075192</td>\n",
       "      <td>0.154838</td>\n",
       "      <td>2.634553</td>\n",
       "      <td>-1.086229</td>\n",
       "      <td>-0.946673</td>\n",
       "      <td>-0.985749</td>\n",
       "      <td>2.290786</td>\n",
       "      <td>-0.958462</td>\n",
       "      <td>0.173112</td>\n",
       "      <td>1.415227</td>\n",
       "      <td>0.517742</td>\n",
       "      <td>0.463841</td>\n",
       "      <td>1.304546</td>\n",
       "      <td>1.252232</td>\n",
       "      <td>-0.037185</td>\n",
       "      <td>-1.258973</td>\n",
       "      <td>-1.058309</td>\n",
       "      <td>0.339487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.656317</td>\n",
       "      <td>-0.413772</td>\n",
       "      <td>0.851601</td>\n",
       "      <td>-0.214676</td>\n",
       "      <td>-1.439332</td>\n",
       "      <td>-1.086229</td>\n",
       "      <td>-0.946673</td>\n",
       "      <td>-0.985749</td>\n",
       "      <td>-1.337273</td>\n",
       "      <td>-0.958462</td>\n",
       "      <td>-1.108482</td>\n",
       "      <td>-1.401700</td>\n",
       "      <td>0.187214</td>\n",
       "      <td>0.463841</td>\n",
       "      <td>-1.445529</td>\n",
       "      <td>0.057427</td>\n",
       "      <td>-0.018656</td>\n",
       "      <td>1.337729</td>\n",
       "      <td>-1.559486</td>\n",
       "      <td>0.939704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.277987</td>\n",
       "      <td>-0.028194</td>\n",
       "      <td>-1.170492</td>\n",
       "      <td>-0.248268</td>\n",
       "      <td>-0.812581</td>\n",
       "      <td>-1.086229</td>\n",
       "      <td>-0.946673</td>\n",
       "      <td>-0.985749</td>\n",
       "      <td>-1.007449</td>\n",
       "      <td>-0.958462</td>\n",
       "      <td>-0.862113</td>\n",
       "      <td>-1.401700</td>\n",
       "      <td>-0.943539</td>\n",
       "      <td>-1.506695</td>\n",
       "      <td>-1.445529</td>\n",
       "      <td>0.455696</td>\n",
       "      <td>-0.048656</td>\n",
       "      <td>0.667390</td>\n",
       "      <td>-1.058309</td>\n",
       "      <td>-0.560839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>1.123469</td>\n",
       "      <td>1.825621</td>\n",
       "      <td>-1.528571</td>\n",
       "      <td>0.927457</td>\n",
       "      <td>-0.373855</td>\n",
       "      <td>-1.086229</td>\n",
       "      <td>-0.312126</td>\n",
       "      <td>0.198225</td>\n",
       "      <td>-0.677626</td>\n",
       "      <td>-0.958462</td>\n",
       "      <td>-0.137218</td>\n",
       "      <td>-1.401700</td>\n",
       "      <td>-1.500218</td>\n",
       "      <td>-2.360594</td>\n",
       "      <td>-0.895514</td>\n",
       "      <td>0.814137</td>\n",
       "      <td>-0.034332</td>\n",
       "      <td>0.569743</td>\n",
       "      <td>0.069340</td>\n",
       "      <td>-2.121404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>1.123469</td>\n",
       "      <td>-1.583694</td>\n",
       "      <td>0.683094</td>\n",
       "      <td>-1.759915</td>\n",
       "      <td>-0.185829</td>\n",
       "      <td>0.455096</td>\n",
       "      <td>-0.312126</td>\n",
       "      <td>-0.393762</td>\n",
       "      <td>0.245880</td>\n",
       "      <td>-0.356714</td>\n",
       "      <td>-0.601056</td>\n",
       "      <td>-0.274929</td>\n",
       "      <td>0.195912</td>\n",
       "      <td>0.595210</td>\n",
       "      <td>-1.445529</td>\n",
       "      <td>0.216735</td>\n",
       "      <td>-0.047817</td>\n",
       "      <td>-0.987687</td>\n",
       "      <td>-0.068483</td>\n",
       "      <td>0.459530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>-1.212292</td>\n",
       "      <td>-1.385832</td>\n",
       "      <td>0.556713</td>\n",
       "      <td>1.767261</td>\n",
       "      <td>-0.373855</td>\n",
       "      <td>-0.058679</td>\n",
       "      <td>-0.312126</td>\n",
       "      <td>-0.985749</td>\n",
       "      <td>-0.149908</td>\n",
       "      <td>-0.356714</td>\n",
       "      <td>-0.145273</td>\n",
       "      <td>-0.838314</td>\n",
       "      <td>0.568191</td>\n",
       "      <td>0.463841</td>\n",
       "      <td>-0.345499</td>\n",
       "      <td>0.455696</td>\n",
       "      <td>-0.046126</td>\n",
       "      <td>-0.542173</td>\n",
       "      <td>0.846165</td>\n",
       "      <td>0.519552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>-1.212292</td>\n",
       "      <td>1.820547</td>\n",
       "      <td>0.346078</td>\n",
       "      <td>-1.423993</td>\n",
       "      <td>-0.812581</td>\n",
       "      <td>1.482646</td>\n",
       "      <td>-0.312126</td>\n",
       "      <td>0.790213</td>\n",
       "      <td>-0.347802</td>\n",
       "      <td>0.846781</td>\n",
       "      <td>0.042821</td>\n",
       "      <td>-0.274929</td>\n",
       "      <td>0.648214</td>\n",
       "      <td>1.186371</td>\n",
       "      <td>1.304546</td>\n",
       "      <td>0.137081</td>\n",
       "      <td>-0.038744</td>\n",
       "      <td>-0.175997</td>\n",
       "      <td>-0.632308</td>\n",
       "      <td>0.819661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>1.123469</td>\n",
       "      <td>0.973292</td>\n",
       "      <td>-0.791350</td>\n",
       "      <td>-1.759915</td>\n",
       "      <td>0.628948</td>\n",
       "      <td>-0.058679</td>\n",
       "      <td>0.956967</td>\n",
       "      <td>-0.393762</td>\n",
       "      <td>-0.083943</td>\n",
       "      <td>0.245033</td>\n",
       "      <td>-0.109739</td>\n",
       "      <td>0.288456</td>\n",
       "      <td>-0.682596</td>\n",
       "      <td>-0.193004</td>\n",
       "      <td>0.204516</td>\n",
       "      <td>-0.181534</td>\n",
       "      <td>-0.043817</td>\n",
       "      <td>0.312632</td>\n",
       "      <td>-0.030895</td>\n",
       "      <td>-0.200709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1541 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Menstrual_Irregularity  Testosterone_Levelng_dL       BMI  \\\n",
       "0                   0.656317                 0.921543 -1.339000   \n",
       "1                  -0.745139                -0.682661 -0.159445   \n",
       "2                   1.123469                 0.413190 -0.075192   \n",
       "3                   0.656317                -0.413772  0.851601   \n",
       "4                  -0.277987                -0.028194 -1.170492   \n",
       "...                      ...                      ...       ...   \n",
       "1536                1.123469                 1.825621 -1.528571   \n",
       "1537                1.123469                -1.583694  0.683094   \n",
       "1538               -1.212292                -1.385832  0.556713   \n",
       "1539               -1.212292                 1.820547  0.346078   \n",
       "1540                1.123469                 0.973292 -0.791350   \n",
       "\n",
       "      Antral_Follicle_Count  Follicle_No_R  Weight_gainY_N  hair_growthY_N  \\\n",
       "0                 -0.416229      -1.125957       -1.086229       -0.946673   \n",
       "1                 -0.550597      -0.499205       -1.086229       -0.946673   \n",
       "2                  0.154838       2.634553       -1.086229       -0.946673   \n",
       "3                 -0.214676      -1.439332       -1.086229       -0.946673   \n",
       "4                 -0.248268      -0.812581       -1.086229       -0.946673   \n",
       "...                     ...            ...             ...             ...   \n",
       "1536               0.927457      -0.373855       -1.086229       -0.312126   \n",
       "1537              -1.759915      -0.185829        0.455096       -0.312126   \n",
       "1538               1.767261      -0.373855       -0.058679       -0.312126   \n",
       "1539              -1.423993      -0.812581        1.482646       -0.312126   \n",
       "1540              -1.759915       0.628948       -0.058679        0.956967   \n",
       "\n",
       "      Skin_darkening_Y_N  Follicle_No_L  CycleR_I  AMHng_mL  PimplesY_N  \\\n",
       "0              -0.985749      -1.007449 -0.958462 -0.907123   -1.401700   \n",
       "1              -0.985749      -1.007449 -0.958462 -1.035045   -1.401700   \n",
       "2              -0.985749       2.290786 -0.958462  0.173112    1.415227   \n",
       "3              -0.985749      -1.337273 -0.958462 -1.108482   -1.401700   \n",
       "4              -0.985749      -1.007449 -0.958462 -0.862113   -1.401700   \n",
       "...                  ...            ...       ...       ...         ...   \n",
       "1536            0.198225      -0.677626 -0.958462 -0.137218   -1.401700   \n",
       "1537           -0.393762       0.245880 -0.356714 -0.601056   -0.274929   \n",
       "1538           -0.985749      -0.149908 -0.356714 -0.145273   -0.838314   \n",
       "1539            0.790213      -0.347802  0.846781  0.042821   -0.274929   \n",
       "1540           -0.393762      -0.083943  0.245033 -0.109739    0.288456   \n",
       "\n",
       "      Weight_Kg  Waistinch  Fast_food_Y_N  Avg_F_size_L_mm  FSHmIU_mL  \\\n",
       "0     -1.587199  -1.506695       1.304546         1.252232  -0.019464   \n",
       "1      0.187214  -0.849850      -1.445529         0.057427  -0.028435   \n",
       "2      0.517742   0.463841       1.304546         1.252232  -0.037185   \n",
       "3      0.187214   0.463841      -1.445529         0.057427  -0.018656   \n",
       "4     -0.943539  -1.506695      -1.445529         0.455696  -0.048656   \n",
       "...         ...        ...            ...              ...        ...   \n",
       "1536  -1.500218  -2.360594      -0.895514         0.814137  -0.034332   \n",
       "1537   0.195912   0.595210      -1.445529         0.216735  -0.047817   \n",
       "1538   0.568191   0.463841      -0.345499         0.455696  -0.046126   \n",
       "1539   0.648214   1.186371       1.304546         0.137081  -0.038744   \n",
       "1540  -0.682596  -0.193004       0.204516        -0.181534  -0.043817   \n",
       "\n",
       "      PRLng_mL  RBSmg_dl   Hipinch  \n",
       "0     2.150797 -0.557131 -0.860948  \n",
       "1    -0.316955 -0.557131 -0.260730  \n",
       "2    -1.258973 -1.058309  0.339487  \n",
       "3     1.337729 -1.559486  0.939704  \n",
       "4     0.667390 -1.058309 -0.560839  \n",
       "...        ...       ...       ...  \n",
       "1536  0.569743  0.069340 -2.121404  \n",
       "1537 -0.987687 -0.068483  0.459530  \n",
       "1538 -0.542173  0.846165  0.519552  \n",
       "1539 -0.175997 -0.632308  0.819661  \n",
       "1540  0.312632 -0.030895 -0.200709  \n",
       "\n",
       "[1541 rows x 20 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X[top_features]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e757bca-fe94-4470-ae04-fb6223ee885a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.15, stratify=y, shuffle=True, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c38188a-94ae-4a5c-8094-1836cd8d65c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Suggest hyperparameters to try\n",
    "    param = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 150),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 50),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 10.0, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 10.0, log=True),\n",
    "        \"random_state\": 42,\n",
    "        \"objective\": \"binary\", # or \"multiclass\" if you're doing that\n",
    "        \"verbose\": -1,\n",
    "    }\n",
    "\n",
    "\n",
    "    train_data = lgb.Dataset(x_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(x_test, label=y_test)\n",
    "\n",
    "    gbm = lgb.train(param,\n",
    "                    train_data,\n",
    "                    valid_sets=[valid_data],\n",
    "                    num_boost_round=1000)\n",
    "\n",
    "    y_pred = gbm.predict(x_test)\n",
    "    y_pred_labels = (y_pred > 0.5).astype(int)\n",
    "    acc = accuracy_score(y_test, y_pred_labels)\n",
    "\n",
    "    return 1.0 - acc  # Optuna minimizes, so 1 - accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9afe6fd-4e8a-4d72-afc9-0f3d15f79891",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 20:35:13,784] A new study created in memory with name: no-name-45a04dec-9e46-4857-8078-2f0323497a0c\n",
      "[I 2025-05-31 20:35:14,773] Trial 0 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.041552175074827495, 'n_estimators': 866, 'max_depth': 5, 'num_leaves': 145, 'min_child_samples': 48, 'subsample': 0.9274285161900622, 'colsample_bytree': 0.9077213215484643, 'reg_alpha': 0.0067849853837518475, 'reg_lambda': 5.992783238052487e-07}. Best is trial 0 with value: 0.030172413793103425.\n",
      "[I 2025-05-31 20:35:16,300] Trial 1 finished with value: 0.017241379310344862 and parameters: {'learning_rate': 0.0323933202509244, 'n_estimators': 484, 'max_depth': 9, 'num_leaves': 58, 'min_child_samples': 17, 'subsample': 0.8420260941226427, 'colsample_bytree': 0.7295044386589632, 'reg_alpha': 2.346905347166588e-08, 'reg_lambda': 1.728237413069774e-05}. Best is trial 1 with value: 0.017241379310344862.\n",
      "[I 2025-05-31 20:35:16,737] Trial 2 finished with value: 0.02155172413793105 and parameters: {'learning_rate': 0.016227257654598138, 'n_estimators': 359, 'max_depth': 6, 'num_leaves': 26, 'min_child_samples': 34, 'subsample': 0.7567872854901768, 'colsample_bytree': 0.6484268180080762, 'reg_alpha': 2.256270337013731, 'reg_lambda': 2.595057803926899e-05}. Best is trial 1 with value: 0.017241379310344862.\n",
      "[I 2025-05-31 20:35:18,271] Trial 3 finished with value: 0.02155172413793105 and parameters: {'learning_rate': 0.1115042542338278, 'n_estimators': 862, 'max_depth': 8, 'num_leaves': 109, 'min_child_samples': 24, 'subsample': 0.7234040879846445, 'colsample_bytree': 0.8079113857578754, 'reg_alpha': 0.0028657962122869427, 'reg_lambda': 0.09327302300869288}. Best is trial 1 with value: 0.017241379310344862.\n",
      "[I 2025-05-31 20:35:19,585] Trial 4 finished with value: 0.012931034482758674 and parameters: {'learning_rate': 0.022811694837696874, 'n_estimators': 615, 'max_depth': 9, 'num_leaves': 63, 'min_child_samples': 27, 'subsample': 0.6577301748062336, 'colsample_bytree': 0.9365511446437059, 'reg_alpha': 0.04912142817831978, 'reg_lambda': 1.14588594457898e-05}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:20,308] Trial 5 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.13601043471034235, 'n_estimators': 676, 'max_depth': 8, 'num_leaves': 70, 'min_child_samples': 36, 'subsample': 0.7569137414272716, 'colsample_bytree': 0.7043521954279397, 'reg_alpha': 1.5698567753258975e-07, 'reg_lambda': 8.899357001026463e-08}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:20,567] Trial 6 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.0839487308594798, 'n_estimators': 175, 'max_depth': 5, 'num_leaves': 92, 'min_child_samples': 20, 'subsample': 0.9487729991711332, 'colsample_bytree': 0.6925227993614367, 'reg_alpha': 1.0200607348296176e-08, 'reg_lambda': 1.0830576637847454e-06}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:20,880] Trial 7 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.08460909664731112, 'n_estimators': 254, 'max_depth': 10, 'num_leaves': 132, 'min_child_samples': 6, 'subsample': 0.7231374806766758, 'colsample_bytree': 0.8949214783641242, 'reg_alpha': 0.9631018528680853, 'reg_lambda': 3.35367550095829e-05}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:21,843] Trial 8 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.24846777873559636, 'n_estimators': 908, 'max_depth': 9, 'num_leaves': 65, 'min_child_samples': 31, 'subsample': 0.8674023448412025, 'colsample_bytree': 0.8898840445382671, 'reg_alpha': 3.516819719310049e-08, 'reg_lambda': 0.011656052961818432}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:22,234] Trial 9 finished with value: 0.017241379310344862 and parameters: {'learning_rate': 0.0416162088711142, 'n_estimators': 239, 'max_depth': 12, 'num_leaves': 126, 'min_child_samples': 37, 'subsample': 0.6136313205064601, 'colsample_bytree': 0.8464639345984675, 'reg_alpha': 0.20318273982480678, 'reg_lambda': 2.0731417194191213}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:22,648] Trial 10 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.011325127789119583, 'n_estimators': 602, 'max_depth': 3, 'num_leaves': 32, 'min_child_samples': 11, 'subsample': 0.6184862994265495, 'colsample_bytree': 0.993841469181798, 'reg_alpha': 1.2543697524771712e-05, 'reg_lambda': 0.005833973391569867}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:24,174] Trial 11 finished with value: 0.017241379310344862 and parameters: {'learning_rate': 0.023569732314593785, 'n_estimators': 421, 'max_depth': 11, 'num_leaves': 57, 'min_child_samples': 17, 'subsample': 0.847983167141159, 'colsample_bytree': 0.7535398793817067, 'reg_alpha': 2.2432783811886697e-05, 'reg_lambda': 4.611772785839026e-05}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:25,615] Trial 12 finished with value: 0.02155172413793105 and parameters: {'learning_rate': 0.023579117414815495, 'n_estimators': 486, 'max_depth': 10, 'num_leaves': 43, 'min_child_samples': 14, 'subsample': 0.82258645549941, 'colsample_bytree': 0.9972938680435972, 'reg_alpha': 0.02714572703899138, 'reg_lambda': 0.0004769381050141624}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:26,947] Trial 13 finished with value: 0.017241379310344862 and parameters: {'learning_rate': 0.028397442281405574, 'n_estimators': 682, 'max_depth': 7, 'num_leaves': 82, 'min_child_samples': 26, 'subsample': 0.6672131665862845, 'colsample_bytree': 0.6154888335156286, 'reg_alpha': 0.00011866146600645621, 'reg_lambda': 3.267229599067343e-06}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:28,893] Trial 14 finished with value: 0.017241379310344862 and parameters: {'learning_rate': 0.010178391209251807, 'n_estimators': 554, 'max_depth': 9, 'num_leaves': 49, 'min_child_samples': 21, 'subsample': 0.8873736950117118, 'colsample_bytree': 0.7610134600730376, 'reg_alpha': 1.0547944244237244e-06, 'reg_lambda': 1.4913499549787903e-08}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:30,168] Trial 15 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.05263888247636965, 'n_estimators': 732, 'max_depth': 12, 'num_leaves': 91, 'min_child_samples': 47, 'subsample': 0.9963601520852672, 'colsample_bytree': 0.9400388080312306, 'reg_alpha': 0.0012134457853854124, 'reg_lambda': 0.000713189279689823}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:31,563] Trial 16 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.016430690823768968, 'n_estimators': 382, 'max_depth': 10, 'num_leaves': 76, 'min_child_samples': 8, 'subsample': 0.6727358375898637, 'colsample_bytree': 0.819208525024891, 'reg_alpha': 0.08492896453962863, 'reg_lambda': 5.010205417486487e-06}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:32,875] Trial 17 finished with value: 0.02155172413793105 and parameters: {'learning_rate': 0.030507732421841408, 'n_estimators': 772, 'max_depth': 7, 'num_leaves': 40, 'min_child_samples': 42, 'subsample': 0.7954452930348175, 'colsample_bytree': 0.7534861343724397, 'reg_alpha': 1.3824287536430224e-06, 'reg_lambda': 1.7001900685427503e-07}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:33,955] Trial 18 finished with value: 0.02155172413793105 and parameters: {'learning_rate': 0.016693421170399295, 'n_estimators': 494, 'max_depth': 9, 'num_leaves': 107, 'min_child_samples': 30, 'subsample': 0.800234641244375, 'colsample_bytree': 0.7006375975689568, 'reg_alpha': 0.0003549718139224643, 'reg_lambda': 0.0020266062039338193}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:34,219] Trial 19 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.06009127287416762, 'n_estimators': 623, 'max_depth': 11, 'num_leaves': 55, 'min_child_samples': 15, 'subsample': 0.6586637519520689, 'colsample_bytree': 0.8500234938087218, 'reg_alpha': 8.274980445484182, 'reg_lambda': 6.717962469397305e-05}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:34,850] Trial 20 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.037184360225770687, 'n_estimators': 987, 'max_depth': 3, 'num_leaves': 64, 'min_child_samples': 24, 'subsample': 0.9071435868430546, 'colsample_bytree': 0.9413468026118161, 'reg_alpha': 0.017292947760664142, 'reg_lambda': 0.02963298316001779}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:35,039] Trial 21 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.05379808827429556, 'n_estimators': 114, 'max_depth': 11, 'num_leaves': 115, 'min_child_samples': 39, 'subsample': 0.6110982935358851, 'colsample_bytree': 0.8559531424818546, 'reg_alpha': 0.3683987879779239, 'reg_lambda': 1.4744301811749894}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:35,405] Trial 22 finished with value: 0.017241379310344862 and parameters: {'learning_rate': 0.039581134132291716, 'n_estimators': 250, 'max_depth': 12, 'num_leaves': 134, 'min_child_samples': 43, 'subsample': 0.6210833122413325, 'colsample_bytree': 0.8467568404677747, 'reg_alpha': 0.27832960713488825, 'reg_lambda': 6.533626619504235}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:36,028] Trial 23 finished with value: 0.012931034482758674 and parameters: {'learning_rate': 0.02145366929960356, 'n_estimators': 285, 'max_depth': 12, 'num_leaves': 100, 'min_child_samples': 29, 'subsample': 0.6997036065307889, 'colsample_bytree': 0.9428892820320169, 'reg_alpha': 0.038916159642181196, 'reg_lambda': 0.11983570960344517}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:36,648] Trial 24 finished with value: 0.017241379310344862 and parameters: {'learning_rate': 0.022329822610361975, 'n_estimators': 319, 'max_depth': 8, 'num_leaves': 99, 'min_child_samples': 28, 'subsample': 0.699446773676046, 'colsample_bytree': 0.9537810529058842, 'reg_alpha': 0.05409860617826103, 'reg_lambda': 0.14644370319362596}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:38,079] Trial 25 finished with value: 0.017241379310344862 and parameters: {'learning_rate': 0.015483882045527683, 'n_estimators': 470, 'max_depth': 10, 'num_leaves': 81, 'min_child_samples': 19, 'subsample': 0.7602998609117593, 'colsample_bytree': 0.7852191745633559, 'reg_alpha': 0.00039892999113406557, 'reg_lambda': 0.000179271176657629}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:38,926] Trial 26 finished with value: 0.017241379310344862 and parameters: {'learning_rate': 0.029672351505293418, 'n_estimators': 551, 'max_depth': 6, 'num_leaves': 73, 'min_child_samples': 32, 'subsample': 0.7005446260187951, 'colsample_bytree': 0.9706200729433213, 'reg_alpha': 4.975820824096372e-05, 'reg_lambda': 7.087456194613255e-06}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:39,627] Trial 27 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.020953944098513613, 'n_estimators': 313, 'max_depth': 9, 'num_leaves': 90, 'min_child_samples': 23, 'subsample': 0.7860071539235343, 'colsample_bytree': 0.9143184430711258, 'reg_alpha': 1.8432936319703968e-06, 'reg_lambda': 0.32345053378191985}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:40,471] Trial 28 finished with value: 0.02155172413793105 and parameters: {'learning_rate': 0.01255158313355302, 'n_estimators': 442, 'max_depth': 11, 'num_leaves': 20, 'min_child_samples': 27, 'subsample': 0.6428332285902356, 'colsample_bytree': 0.7263392312131924, 'reg_alpha': 0.004942349360495511, 'reg_lambda': 0.00022406739040840178}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:41,765] Trial 29 finished with value: 0.02155172413793105 and parameters: {'learning_rate': 0.03397338429518885, 'n_estimators': 606, 'max_depth': 7, 'num_leaves': 55, 'min_child_samples': 12, 'subsample': 0.8383943189431291, 'colsample_bytree': 0.915861220469441, 'reg_alpha': 0.014206011871109788, 'reg_lambda': 6.135938877965548e-07}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:42,793] Trial 30 finished with value: 0.017241379310344862 and parameters: {'learning_rate': 0.019607001579909758, 'n_estimators': 804, 'max_depth': 5, 'num_leaves': 102, 'min_child_samples': 17, 'subsample': 0.7013357062426293, 'colsample_bytree': 0.6680885220294333, 'reg_alpha': 0.0028435452110605573, 'reg_lambda': 0.0032113287433519727}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:43,056] Trial 31 finished with value: 0.02155172413793105 and parameters: {'learning_rate': 0.04476976383688653, 'n_estimators': 218, 'max_depth': 12, 'num_leaves': 149, 'min_child_samples': 37, 'subsample': 0.6018980868248648, 'colsample_bytree': 0.8727633511728744, 'reg_alpha': 4.630896476729304, 'reg_lambda': 7.52878866077772}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:43,624] Trial 32 finished with value: 0.02155172413793105 and parameters: {'learning_rate': 0.026245897904332554, 'n_estimators': 322, 'max_depth': 12, 'num_leaves': 120, 'min_child_samples': 35, 'subsample': 0.6445704498766771, 'colsample_bytree': 0.8252479381610665, 'reg_alpha': 0.2209746380529337, 'reg_lambda': 0.8766503647919075}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:43,844] Trial 33 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.042583658210974464, 'n_estimators': 131, 'max_depth': 11, 'num_leaves': 122, 'min_child_samples': 40, 'subsample': 0.7294703036649448, 'colsample_bytree': 0.9243552304559008, 'reg_alpha': 0.12542755353339802, 'reg_lambda': 1.6167381239538616}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:44,111] Trial 34 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.06306112888749014, 'n_estimators': 367, 'max_depth': 10, 'num_leaves': 135, 'min_child_samples': 50, 'subsample': 0.6378107985402425, 'colsample_bytree': 0.7917781743524559, 'reg_alpha': 2.409819613219535, 'reg_lambda': 0.04640456147081499}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:44,476] Trial 35 finished with value: 0.02155172413793105 and parameters: {'learning_rate': 0.033811630663016914, 'n_estimators': 199, 'max_depth': 8, 'num_leaves': 140, 'min_child_samples': 29, 'subsample': 0.7374145050013238, 'colsample_bytree': 0.9571574482511565, 'reg_alpha': 0.6519817074375718, 'reg_lambda': 9.940161693906036e-06}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:44,904] Trial 36 finished with value: 0.017241379310344862 and parameters: {'learning_rate': 0.07556634567015272, 'n_estimators': 297, 'max_depth': 6, 'num_leaves': 126, 'min_child_samples': 32, 'subsample': 0.6935667982898897, 'colsample_bytree': 0.8813656427963203, 'reg_alpha': 0.0015093661392520843, 'reg_lambda': 0.26270915646177767}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:45,228] Trial 37 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.013542181004097709, 'n_estimators': 406, 'max_depth': 4, 'num_leaves': 111, 'min_child_samples': 45, 'subsample': 0.6738783145827169, 'colsample_bytree': 0.9752636270862151, 'reg_alpha': 1.4239876342226072, 'reg_lambda': 1.8472862801418618e-06}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:46,207] Trial 38 finished with value: 0.02155172413793105 and parameters: {'learning_rate': 0.11357812605826721, 'n_estimators': 660, 'max_depth': 12, 'num_leaves': 66, 'min_child_samples': 33, 'subsample': 0.7634735810756224, 'colsample_bytree': 0.7261233315783125, 'reg_alpha': 1.845890321772563e-07, 'reg_lambda': 1.1391783283496976e-05}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:46,582] Trial 39 finished with value: 0.017241379310344862 and parameters: {'learning_rate': 0.2114104491536155, 'n_estimators': 524, 'max_depth': 9, 'num_leaves': 33, 'min_child_samples': 37, 'subsample': 0.6297619332623464, 'colsample_bytree': 0.6499616464471569, 'reg_alpha': 0.007803066245558127, 'reg_lambda': 9.608657719118719e-08}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:46,919] Trial 40 finished with value: 0.030172413793103425 and parameters: {'learning_rate': 0.019422682493636243, 'n_estimators': 165, 'max_depth': 8, 'num_leaves': 46, 'min_child_samples': 24, 'subsample': 0.9444971724700353, 'colsample_bytree': 0.7696402665809922, 'reg_alpha': 0.035104708981354496, 'reg_lambda': 0.021580662190265616}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:48,418] Trial 41 finished with value: 0.017241379310344862 and parameters: {'learning_rate': 0.025525737315313584, 'n_estimators': 418, 'max_depth': 11, 'num_leaves': 57, 'min_child_samples': 17, 'subsample': 0.8570112357109098, 'colsample_bytree': 0.7436577004341025, 'reg_alpha': 7.98304914636955e-06, 'reg_lambda': 4.2155557393545794e-05}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:49,572] Trial 42 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.04694172141355066, 'n_estimators': 272, 'max_depth': 11, 'num_leaves': 61, 'min_child_samples': 10, 'subsample': 0.8308767277428105, 'colsample_bytree': 0.7252671776403914, 'reg_alpha': 2.8806707977024666e-07, 'reg_lambda': 1.9096313758621892e-05}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:50,668] Trial 43 finished with value: 0.02155172413793105 and parameters: {'learning_rate': 0.025757050840843725, 'n_estimators': 354, 'max_depth': 10, 'num_leaves': 70, 'min_child_samples': 21, 'subsample': 0.8770148173486759, 'colsample_bytree': 0.6736631038169983, 'reg_alpha': 1.7702803619869686e-08, 'reg_lambda': 9.932854480674996e-05}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:52,017] Trial 44 finished with value: 0.017241379310344862 and parameters: {'learning_rate': 0.018504006391848696, 'n_estimators': 518, 'max_depth': 12, 'num_leaves': 50, 'min_child_samples': 26, 'subsample': 0.8111338956153274, 'colsample_bytree': 0.8120449795498224, 'reg_alpha': 8.074242584019616e-05, 'reg_lambda': 0.0007362526638806509}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:53,344] Trial 45 finished with value: 0.017241379310344862 and parameters: {'learning_rate': 0.03665966496436547, 'n_estimators': 434, 'max_depth': 11, 'num_leaves': 38, 'min_child_samples': 18, 'subsample': 0.8490560284406242, 'colsample_bytree': 0.8981703732236006, 'reg_alpha': 1.3210288810346329e-05, 'reg_lambda': 1.4961571110045855e-06}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:54,251] Trial 46 finished with value: 0.03448275862068961 and parameters: {'learning_rate': 0.023450539813173632, 'n_estimators': 231, 'max_depth': 12, 'num_leaves': 85, 'min_child_samples': 22, 'subsample': 0.6605320270982307, 'colsample_bytree': 0.6064235013236817, 'reg_alpha': 4.715408585508924e-08, 'reg_lambda': 2.680715788678108e-07}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:55,422] Trial 47 finished with value: 0.017241379310344862 and parameters: {'learning_rate': 0.031175443465738528, 'n_estimators': 592, 'max_depth': 10, 'num_leaves': 79, 'min_child_samples': 14, 'subsample': 0.7858825080287889, 'colsample_bytree': 0.7752944629571191, 'reg_alpha': 0.11355961293378009, 'reg_lambda': 3.993072141247569e-05}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:56,974] Trial 48 finished with value: 0.025862068965517238 and parameters: {'learning_rate': 0.014322130874860364, 'n_estimators': 457, 'max_depth': 9, 'num_leaves': 93, 'min_child_samples': 5, 'subsample': 0.8949471971439659, 'colsample_bytree': 0.8344170690092214, 'reg_alpha': 0.0008320382735172624, 'reg_lambda': 3.227364880277925}. Best is trial 4 with value: 0.012931034482758674.\n",
      "[I 2025-05-31 20:35:59,746] Trial 49 finished with value: 0.017241379310344862 and parameters: {'learning_rate': 0.016963875219275493, 'n_estimators': 707, 'max_depth': 11, 'num_leaves': 50, 'min_child_samples': 15, 'subsample': 0.6815885432408268, 'colsample_bytree': 0.7459741337477562, 'reg_alpha': 4.999089889743964e-06, 'reg_lambda': 3.3295988384724865e-06}. Best is trial 4 with value: 0.012931034482758674.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:\n",
      "{'learning_rate': 0.022811694837696874, 'n_estimators': 615, 'max_depth': 9, 'num_leaves': 63, 'min_child_samples': 27, 'subsample': 0.6577301748062336, 'colsample_bytree': 0.9365511446437059, 'reg_alpha': 0.04912142817831978, 'reg_lambda': 1.14588594457898e-05}\n",
      "Best accuracy:\n",
      "0.9870689655172413\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')  # Because we return 1 - accuracy\n",
    "study.optimize(objective, n_trials=50)  # Try 50 combinations (or more!)\n",
    "\n",
    "print(\"Best hyperparameters:\")\n",
    "print(study.best_params)\n",
    "\n",
    "print(\"Best accuracy:\")\n",
    "print(1 - study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ae13373-dbdf-4f29-8388-84876b8edf70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final evaluation on test set:\n",
      "Accuracy: 96.98\n",
      "Precision: 93.10\n",
      "Recall: 94.74\n",
      "F1 Score: 93.91\n"
     ]
    }
   ],
   "source": [
    "train_data = lgb.Dataset(x_train, label=y_train)\n",
    "valid_data = lgb.Dataset(x_test, label=y_test)\n",
    "\n",
    "best_model = lgb.train(study.best_params,\n",
    "                train_data,\n",
    "                valid_sets=[valid_data],\n",
    "                num_boost_round=1000)\n",
    "\n",
    "# Predict\n",
    "preds = best_model.predict(x_test)\n",
    "preds = (preds > 0.5).astype(int)\n",
    "\n",
    "# Compute final scores\n",
    "acc = accuracy_score(y_test, preds)\n",
    "precision = precision_score(y_test, preds, average='binary')\n",
    "recall = recall_score(y_test, preds, average='binary')\n",
    "f1 = f1_score(y_test, preds, average='binary')\n",
    "\n",
    "print(\"\\nFinal evaluation on test set:\")\n",
    "print(f\"Accuracy: {acc * 100:.2f}\")\n",
    "print(f\"Precision: {precision * 100:.2f}\")\n",
    "print(f\"Recall: {recall * 100:.2f}\")\n",
    "print(f\"F1 Score: {f1 * 100:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0bb434-b192-4d51-b97d-69f771a53b41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
