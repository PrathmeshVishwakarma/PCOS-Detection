{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c3afa254-1ada-47a7-9fa0-9ac6934dd323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6eb78209-a249-4fa4-9306-6143a0f2daa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load both datasets\n",
    "original = pd.read_csv(\"PCOS_data.csv\")\n",
    "new = pd.read_csv(\"pcos_dataset.csv\")\n",
    "\n",
    "# Set max columns to show is unlimited\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ad33fc1e-fca1-47ac-b0ba-eba4f05e080c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df = df.copy()  # avoid SettingWithCopyWarning\n",
    "\n",
    "    # 1. Clean column names\n",
    "    df.columns = df.columns.str.strip() \\\n",
    "                           .str.replace(' ', '_') \\\n",
    "                           .str.replace('(', '') \\\n",
    "                           .str.replace(')', '') \\\n",
    "                           .str.replace('.', '') \\\n",
    "                           .str.replace('-', '_') \\\n",
    "                           .str.replace('/', '_')\n",
    "    df.rename(columns={'II____beta_HCGmIU_mL': 'II_beta_HCG'}, inplace=True)\n",
    "\n",
    "    # 2. Drop irrelevant columns\n",
    "    df.drop(columns=['Sl_No', 'Patient_File_No'], inplace=True, errors='ignore')\n",
    "    df = df.loc[:, ~df.columns.str.startswith('Unnamed')]\n",
    "\n",
    "    # 3. Merge Age columns\n",
    "    if 'Age' not in df.columns and 'Age_yrs' in df.columns:\n",
    "        df.rename(columns={'Age_yrs': 'Age'}, inplace=True)\n",
    "    elif 'Age' in df.columns and 'Age_yrs' in df.columns:\n",
    "        df['Age'] = df['Age'].fillna(df['Age_yrs'])\n",
    "        df.drop(columns=['Age_yrs'], inplace=True)\n",
    "\n",
    "    # 4. Merge PCOS diagnosis columns\n",
    "    if 'PCOS_Diagnosis' in df.columns:\n",
    "        df.rename(columns={'PCOS_Diagnosis': 'PCOS_Y_N'}, inplace=True)\n",
    "\n",
    "    # 5. Handle missing values\n",
    "    if 'Marraige_Status_Yrs' in df.columns:\n",
    "        df.loc[:, 'Marraige_Status_Yrs'] = df['Marraige_Status_Yrs'].fillna(df['Marraige_Status_Yrs'].median())\n",
    "\n",
    "    if 'Fast_food_Y_N' not in df.columns and 'Fast_food_YN' in df.columns:\n",
    "        df.rename(columns={'Fast_food_YN': 'Fast_food_Y_N'}, inplace=True)\n",
    "    if 'Fast_food_Y_N' in df.columns:\n",
    "        df.loc[:, 'Fast_food_Y_N'] = df['Fast_food_Y_N'].fillna(df['Fast_food_Y_N'].mode()[0])\n",
    "\n",
    "    # 6. Convert to numeric and fill missing values\n",
    "    if 'II_beta_HCG' not in df.columns and 'II_beta_HCGmIU_mL' in df.columns:\n",
    "        df.rename(columns={'II_beta_HCGmIU_mL': 'II_beta_HCG'}, inplace=True)\n",
    "    if 'II_beta_HCG' in df.columns:\n",
    "        df.loc[:, 'II_beta_HCG'] = pd.to_numeric(df['II_beta_HCG'], errors='coerce')\n",
    "        df['II_beta_HCG'] = df['II_beta_HCG'].astype(float)\n",
    "        df.loc[:, 'II_beta_HCG'] = df['II_beta_HCG'].fillna(df['II_beta_HCG'].median())\n",
    "\n",
    "    if 'AMHng_mL' in df.columns:\n",
    "        df.loc[:, 'AMHng_mL'] = pd.to_numeric(df['AMHng_mL'], errors='coerce')\n",
    "        df['AMHng_mL'] = df['AMHng_mL'].astype(float)\n",
    "        df.loc[:, 'AMHng_mL'] = df['AMHng_mL'].fillna(df['AMHng_mL'].median())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "96b0d4ec-1291-443f-bdc3-d2ab8b624742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing\n",
    "original_clean = preprocess(original)\n",
    "new_clean = preprocess(new)\n",
    "\n",
    "# Ensure consistent columns across both\n",
    "all_columns = list(set(original_clean.columns).union(set(new_clean.columns)))\n",
    "\n",
    "# Align both dataframes to same columns, fill missing with NaN\n",
    "original_aligned = original_clean.reindex(columns=all_columns)\n",
    "new_aligned = new_clean.reindex(columns=all_columns)\n",
    "\n",
    "# Concatenate datasets\n",
    "combined_df = pd.concat([original_aligned, new_aligned], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "970f88be-1205-4abc-a06a-4dbd146b1734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "# X = combined_df.drop(columns=['PCOS_Y_N'])\n",
    "X = combined_df.drop(columns=['PCOS_Y_N'])\n",
    "y = combined_df['PCOS_Y_N']\n",
    "\n",
    "# Initialize KNNImputer (e.g., with 5 nearest neighbors)\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "X = pd.DataFrame(knn_imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Sanitize feature names\n",
    "X.columns = [str(col).replace(' ', '_')\n",
    "                        .replace('\"', '')\n",
    "                        .replace(\"'\", '')\n",
    "                        .replace('[', '')\n",
    "                        .replace(']', '')\n",
    "                        .replace('{', '')\n",
    "                        .replace('}', '')\n",
    "                        .replace(':', '')\n",
    "                        .replace(',', '')\n",
    "                        for col in X.columns]\n",
    "\n",
    "X.to_pickle('unscaled_X.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d02ac8f3-8794-4ee0-982f-f5b94425a38d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PimplesY_N</th>\n",
       "      <th>PRLng_mL</th>\n",
       "      <th>Vit_D3_ng_mL</th>\n",
       "      <th>Cycle_lengthdays</th>\n",
       "      <th>CycleR_I</th>\n",
       "      <th>BMI</th>\n",
       "      <th>RBSmg_dl</th>\n",
       "      <th>Weight_gainY_N</th>\n",
       "      <th>Avg_F_size_L_mm</th>\n",
       "      <th>Weight_Kg</th>\n",
       "      <th>hair_growthY_N</th>\n",
       "      <th>I___beta_HCGmIU_mL</th>\n",
       "      <th>Avg_F_size_R_mm</th>\n",
       "      <th>FSH_LH</th>\n",
       "      <th>Skin_darkening_Y_N</th>\n",
       "      <th>LHmIU_mL</th>\n",
       "      <th>TSH_mIU_L</th>\n",
       "      <th>Antral_Follicle_Count</th>\n",
       "      <th>WaistHip_Ratio</th>\n",
       "      <th>Follicle_No_R</th>\n",
       "      <th>BP__Systolic_mmHg</th>\n",
       "      <th>Marraige_Status_Yrs</th>\n",
       "      <th>FSHmIU_mL</th>\n",
       "      <th>Testosterone_Levelng_dL</th>\n",
       "      <th>AMHng_mL</th>\n",
       "      <th>Menstrual_Irregularity</th>\n",
       "      <th>Follicle_No_L</th>\n",
       "      <th>Endometrium_mm</th>\n",
       "      <th>Hipinch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.520</td>\n",
       "      <td>49.700</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.3</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>68.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>494.080</td>\n",
       "      <td>20.00</td>\n",
       "      <td>6.300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>2.540</td>\n",
       "      <td>18.4</td>\n",
       "      <td>0.900</td>\n",
       "      <td>15.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.540</td>\n",
       "      <td>67.86</td>\n",
       "      <td>6.630</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>22.430</td>\n",
       "      <td>31.400</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>74.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1214.230</td>\n",
       "      <td>21.00</td>\n",
       "      <td>1.320</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5100</td>\n",
       "      <td>6.510</td>\n",
       "      <td>15.2</td>\n",
       "      <td>0.890</td>\n",
       "      <td>8.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>66.10</td>\n",
       "      <td>7.940</td>\n",
       "      <td>0.4</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>19.130</td>\n",
       "      <td>28.000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>85.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.580</td>\n",
       "      <td>17.00</td>\n",
       "      <td>2.330</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8100</td>\n",
       "      <td>2.870</td>\n",
       "      <td>15.8</td>\n",
       "      <td>0.950</td>\n",
       "      <td>8.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.890</td>\n",
       "      <td>64.34</td>\n",
       "      <td>2.070</td>\n",
       "      <td>0.4</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11.00</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>11.460</td>\n",
       "      <td>21.500</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>63.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>610.630</td>\n",
       "      <td>17.00</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8900</td>\n",
       "      <td>0.650</td>\n",
       "      <td>14.6</td>\n",
       "      <td>0.840</td>\n",
       "      <td>6.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.340</td>\n",
       "      <td>52.42</td>\n",
       "      <td>1.890</td>\n",
       "      <td>0.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.30</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>17.980</td>\n",
       "      <td>25.140</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>29.7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>76.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.990</td>\n",
       "      <td>12.00</td>\n",
       "      <td>2.220</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.7800</td>\n",
       "      <td>4.280</td>\n",
       "      <td>16.4</td>\n",
       "      <td>0.840</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.180</td>\n",
       "      <td>66.24</td>\n",
       "      <td>3.840</td>\n",
       "      <td>0.4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.80</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>0.4</td>\n",
       "      <td>10.944</td>\n",
       "      <td>28.920</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>28.4</td>\n",
       "      <td>101.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>15.0</td>\n",
       "      <td>67.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123.998</td>\n",
       "      <td>13.60</td>\n",
       "      <td>5.182</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.1300</td>\n",
       "      <td>2.110</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.894</td>\n",
       "      <td>4.2</td>\n",
       "      <td>118.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>5.022</td>\n",
       "      <td>68.30</td>\n",
       "      <td>3.022</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>6.64</td>\n",
       "      <td>41.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519</th>\n",
       "      <td>0.2</td>\n",
       "      <td>27.706</td>\n",
       "      <td>22.912</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>33.3</td>\n",
       "      <td>171.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.8</td>\n",
       "      <td>82.90</td>\n",
       "      <td>0.4</td>\n",
       "      <td>99.238</td>\n",
       "      <td>13.76</td>\n",
       "      <td>3.426</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.4120</td>\n",
       "      <td>2.518</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.888</td>\n",
       "      <td>7.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>7.766</td>\n",
       "      <td>96.10</td>\n",
       "      <td>4.064</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>8.62</td>\n",
       "      <td>42.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>0.4</td>\n",
       "      <td>16.532</td>\n",
       "      <td>38.200</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>32.0</td>\n",
       "      <td>101.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>16.8</td>\n",
       "      <td>81.40</td>\n",
       "      <td>0.6</td>\n",
       "      <td>286.896</td>\n",
       "      <td>17.40</td>\n",
       "      <td>14.930</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0044</td>\n",
       "      <td>1.438</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.872</td>\n",
       "      <td>7.8</td>\n",
       "      <td>118.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.384</td>\n",
       "      <td>71.90</td>\n",
       "      <td>11.354</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.8</td>\n",
       "      <td>8.14</td>\n",
       "      <td>41.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>0.6</td>\n",
       "      <td>20.580</td>\n",
       "      <td>32.250</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.7</td>\n",
       "      <td>97.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>15.6</td>\n",
       "      <td>63.00</td>\n",
       "      <td>0.4</td>\n",
       "      <td>182.794</td>\n",
       "      <td>14.40</td>\n",
       "      <td>3.152</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.9440</td>\n",
       "      <td>2.308</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.874</td>\n",
       "      <td>4.8</td>\n",
       "      <td>118.0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>6.124</td>\n",
       "      <td>74.10</td>\n",
       "      <td>3.356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>9.06</td>\n",
       "      <td>41.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>0.6</td>\n",
       "      <td>16.272</td>\n",
       "      <td>21.360</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>28.0</td>\n",
       "      <td>96.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>13.3</td>\n",
       "      <td>67.20</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5329.030</td>\n",
       "      <td>14.00</td>\n",
       "      <td>2.120</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.3020</td>\n",
       "      <td>1.514</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.888</td>\n",
       "      <td>7.4</td>\n",
       "      <td>114.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.464</td>\n",
       "      <td>76.50</td>\n",
       "      <td>9.344</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>9.32</td>\n",
       "      <td>40.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>376 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PimplesY_N  PRLng_mL  Vit_D3_ng_mL  Cycle_lengthdays  CycleR_I   BMI  \\\n",
       "2            1.0    10.520        49.700               5.0       2.0  25.3   \n",
       "12           1.0    22.430        31.400               2.0       4.0  32.0   \n",
       "19           1.0    19.130        28.000               7.0       4.0  31.2   \n",
       "24           1.0    11.460        21.500               5.0       2.0  25.2   \n",
       "26           1.0    17.980        25.140               3.0       4.0  29.7   \n",
       "...          ...       ...           ...               ...       ...   ...   \n",
       "1516         0.4    10.944        28.920               4.6       2.4  28.4   \n",
       "1519         0.2    27.706        22.912               4.4       2.4  33.3   \n",
       "1524         0.4    16.532        38.200               6.8       3.6  32.0   \n",
       "1529         0.6    20.580        32.250               5.0       2.0  25.7   \n",
       "1530         0.6    16.272        21.360               5.2       3.4  28.0   \n",
       "\n",
       "      RBSmg_dl  Weight_gainY_N  Avg_F_size_L_mm  Weight_Kg  hair_growthY_N  \\\n",
       "2         84.0             0.0             18.0      68.80             0.0   \n",
       "12       125.0             1.0             20.0      74.00             1.0   \n",
       "19       100.0             0.0             18.0      85.00             1.0   \n",
       "24       100.0             0.0             18.0      63.00             1.0   \n",
       "26       100.0             1.0             11.0      76.00             1.0   \n",
       "...        ...             ...              ...        ...             ...   \n",
       "1516     101.4             0.6             15.0      67.94             0.0   \n",
       "1519     171.2             0.6              7.8      82.90             0.4   \n",
       "1524     101.6             0.4             16.8      81.40             0.6   \n",
       "1529      97.4             0.6             15.6      63.00             0.4   \n",
       "1530      96.2             0.6             13.3      67.20             0.2   \n",
       "\n",
       "      I___beta_HCGmIU_mL  Avg_F_size_R_mm  FSH_LH  Skin_darkening_Y_N  \\\n",
       "2                494.080            20.00   6.300                 0.0   \n",
       "12              1214.230            21.00   1.320                 1.0   \n",
       "19                23.580            17.00   2.330                 1.0   \n",
       "24               610.630            17.00   6.000                 0.0   \n",
       "26                 1.990            12.00   2.220                 1.0   \n",
       "...                  ...              ...     ...                 ...   \n",
       "1516             123.998            13.60   5.182                 0.2   \n",
       "1519              99.238            13.76   3.426                 0.4   \n",
       "1524             286.896            17.40  14.930                 0.8   \n",
       "1529             182.794            14.40   3.152                 0.4   \n",
       "1530            5329.030            14.00   2.120                 0.8   \n",
       "\n",
       "      LHmIU_mL  TSH_mIU_L  Antral_Follicle_Count  WaistHip_Ratio  \\\n",
       "2       0.8800      2.540                   18.4           0.900   \n",
       "12      1.5100      6.510                   15.2           0.890   \n",
       "19      0.8100      2.870                   15.8           0.950   \n",
       "24      0.8900      0.650                   14.6           0.840   \n",
       "26      2.7800      4.280                   16.4           0.840   \n",
       "...        ...        ...                    ...             ...   \n",
       "1516    3.1300      2.110                   16.0           0.894   \n",
       "1519    2.4120      2.518                   20.0           0.888   \n",
       "1524    1.0044      1.438                   18.0           0.872   \n",
       "1529    2.9440      2.308                   28.0           0.874   \n",
       "1530    2.3020      1.514                   26.0           0.888   \n",
       "\n",
       "      Follicle_No_R  BP__Systolic_mmHg  Marraige_Status_Yrs  FSHmIU_mL  \\\n",
       "2              15.0              120.0                 10.0      5.540   \n",
       "12              8.0              120.0                  7.0      2.000   \n",
       "19              8.0              120.0                  7.0      1.890   \n",
       "24              6.0              120.0                 12.0      5.340   \n",
       "26             20.0              120.0                  5.0      6.180   \n",
       "...             ...                ...                  ...        ...   \n",
       "1516            4.2              118.0                 13.2      5.022   \n",
       "1519            7.0              114.0                 12.4      7.766   \n",
       "1524            7.8              118.0                 10.0      3.384   \n",
       "1529            4.8              118.0                 10.8      6.124   \n",
       "1530            7.4              114.0                  2.8      3.464   \n",
       "\n",
       "      Testosterone_Levelng_dL  AMHng_mL  Menstrual_Irregularity  \\\n",
       "2                       67.86     6.630                     1.0   \n",
       "12                      66.10     7.940                     0.4   \n",
       "19                      64.34     2.070                     0.4   \n",
       "24                      52.42     1.890                     0.8   \n",
       "26                      66.24     3.840                     0.4   \n",
       "...                       ...       ...                     ...   \n",
       "1516                    68.30     3.022                     1.0   \n",
       "1519                    96.10     4.064                     1.0   \n",
       "1524                    71.90    11.354                     1.0   \n",
       "1529                    74.10     3.356                     1.0   \n",
       "1530                    76.50     9.344                     1.0   \n",
       "\n",
       "      Follicle_No_L  Endometrium_mm  Hipinch  \n",
       "2              13.0           10.00     40.0  \n",
       "12             15.0            8.00     45.0  \n",
       "19             16.0           11.00     44.0  \n",
       "24              4.0            7.30     38.0  \n",
       "26             21.0            6.80     45.0  \n",
       "...             ...             ...      ...  \n",
       "1516            4.8            6.64     41.2  \n",
       "1519            5.8            8.62     42.6  \n",
       "1524            9.8            8.14     41.6  \n",
       "1529            3.4            9.06     41.4  \n",
       "1530            5.4            9.32     40.4  \n",
       "\n",
       "[376 rows x 29 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X[y==1][selected_features[\"selected_features\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a04628-07ab-4f84-9734-9d248127477b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "joblib.dump(scaler, 'scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99da1aee-6fd4-4186-b4c8-2ede05fa71c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "model = LGBMClassifier()\n",
    "rfecv = RFECV(estimator=model, step=1, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "rfecv.fit(X, y)\n",
    "selected_mask = rfecv.support_\n",
    "selected_features = X.columns[selected_mask]\n",
    "X = X[selected_features]\n",
    "print(selected_features, len(selected_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bf70d3c5-114c-4270-af5d-02ead936a6c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PimplesY_N</th>\n",
       "      <th>PRLng_mL</th>\n",
       "      <th>Vit_D3_ng_mL</th>\n",
       "      <th>Cycle_lengthdays</th>\n",
       "      <th>CycleR_I</th>\n",
       "      <th>BMI</th>\n",
       "      <th>RBSmg_dl</th>\n",
       "      <th>Weight_gainY_N</th>\n",
       "      <th>Avg_F_size_L_mm</th>\n",
       "      <th>Weight_Kg</th>\n",
       "      <th>hair_growthY_N</th>\n",
       "      <th>I___beta_HCGmIU_mL</th>\n",
       "      <th>Avg_F_size_R_mm</th>\n",
       "      <th>FSH_LH</th>\n",
       "      <th>Skin_darkening_Y_N</th>\n",
       "      <th>LHmIU_mL</th>\n",
       "      <th>TSH_mIU_L</th>\n",
       "      <th>Antral_Follicle_Count</th>\n",
       "      <th>WaistHip_Ratio</th>\n",
       "      <th>Follicle_No_R</th>\n",
       "      <th>BP__Systolic_mmHg</th>\n",
       "      <th>Marraige_Status_Yrs</th>\n",
       "      <th>FSHmIU_mL</th>\n",
       "      <th>Testosterone_Levelng_dL</th>\n",
       "      <th>AMHng_mL</th>\n",
       "      <th>Menstrual_Irregularity</th>\n",
       "      <th>Follicle_No_L</th>\n",
       "      <th>Endometrium_mm</th>\n",
       "      <th>Hipinch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.399388</td>\n",
       "      <td>2.155471</td>\n",
       "      <td>-0.110646</td>\n",
       "      <td>0.114163</td>\n",
       "      <td>-0.960521</td>\n",
       "      <td>-1.339000</td>\n",
       "      <td>-0.557356</td>\n",
       "      <td>-1.084586</td>\n",
       "      <td>1.248061</td>\n",
       "      <td>-1.585880</td>\n",
       "      <td>-0.946011</td>\n",
       "      <td>-0.287763</td>\n",
       "      <td>1.180819</td>\n",
       "      <td>-0.112551</td>\n",
       "      <td>-0.986565</td>\n",
       "      <td>-0.021274</td>\n",
       "      <td>-0.913143</td>\n",
       "      <td>-0.416698</td>\n",
       "      <td>-1.864279</td>\n",
       "      <td>-1.122485</td>\n",
       "      <td>-0.942889</td>\n",
       "      <td>-0.240167</td>\n",
       "      <td>-0.019515</td>\n",
       "      <td>0.920724</td>\n",
       "      <td>-0.908231</td>\n",
       "      <td>0.655466</td>\n",
       "      <td>-1.005084</td>\n",
       "      <td>0.027633</td>\n",
       "      <td>-0.859636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.399388</td>\n",
       "      <td>-0.316869</td>\n",
       "      <td>0.088920</td>\n",
       "      <td>0.114163</td>\n",
       "      <td>-0.960521</td>\n",
       "      <td>-0.159445</td>\n",
       "      <td>-0.557356</td>\n",
       "      <td>-1.084586</td>\n",
       "      <td>0.055459</td>\n",
       "      <td>0.188663</td>\n",
       "      <td>-0.946011</td>\n",
       "      <td>-0.263601</td>\n",
       "      <td>-0.537339</td>\n",
       "      <td>-0.009492</td>\n",
       "      <td>-0.986565</td>\n",
       "      <td>-0.068956</td>\n",
       "      <td>0.033082</td>\n",
       "      <td>-0.551112</td>\n",
       "      <td>-1.556469</td>\n",
       "      <td>-0.495969</td>\n",
       "      <td>0.965828</td>\n",
       "      <td>0.632036</td>\n",
       "      <td>-0.028486</td>\n",
       "      <td>-0.683586</td>\n",
       "      <td>-1.036085</td>\n",
       "      <td>-0.744820</td>\n",
       "      <td>-1.005084</td>\n",
       "      <td>-3.162981</td>\n",
       "      <td>-0.259464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.415830</td>\n",
       "      <td>-1.260638</td>\n",
       "      <td>0.036545</td>\n",
       "      <td>0.114163</td>\n",
       "      <td>-0.960521</td>\n",
       "      <td>-0.075192</td>\n",
       "      <td>-1.060306</td>\n",
       "      <td>-1.084586</td>\n",
       "      <td>1.248061</td>\n",
       "      <td>0.519215</td>\n",
       "      <td>-0.946011</td>\n",
       "      <td>-0.085585</td>\n",
       "      <td>2.039898</td>\n",
       "      <td>-0.006151</td>\n",
       "      <td>-0.986565</td>\n",
       "      <td>-0.072822</td>\n",
       "      <td>-0.203474</td>\n",
       "      <td>0.154564</td>\n",
       "      <td>0.290392</td>\n",
       "      <td>2.636615</td>\n",
       "      <td>0.965828</td>\n",
       "      <td>0.413985</td>\n",
       "      <td>-0.037236</td>\n",
       "      <td>0.412338</td>\n",
       "      <td>0.171418</td>\n",
       "      <td>1.122228</td>\n",
       "      <td>2.296491</td>\n",
       "      <td>1.024700</td>\n",
       "      <td>0.340707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.399388</td>\n",
       "      <td>1.340891</td>\n",
       "      <td>-0.037051</td>\n",
       "      <td>0.114163</td>\n",
       "      <td>-0.960521</td>\n",
       "      <td>0.851601</td>\n",
       "      <td>-1.563256</td>\n",
       "      <td>-1.084586</td>\n",
       "      <td>0.055459</td>\n",
       "      <td>0.188663</td>\n",
       "      <td>-0.946011</td>\n",
       "      <td>-0.287763</td>\n",
       "      <td>-0.537339</td>\n",
       "      <td>-0.080168</td>\n",
       "      <td>-0.986565</td>\n",
       "      <td>-0.045575</td>\n",
       "      <td>5.088521</td>\n",
       "      <td>-0.215076</td>\n",
       "      <td>-0.940849</td>\n",
       "      <td>-1.435744</td>\n",
       "      <td>0.965828</td>\n",
       "      <td>-0.894320</td>\n",
       "      <td>-0.018706</td>\n",
       "      <td>-0.414679</td>\n",
       "      <td>-1.109482</td>\n",
       "      <td>0.655466</td>\n",
       "      <td>-1.335242</td>\n",
       "      <td>-0.637078</td>\n",
       "      <td>0.940879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.399388</td>\n",
       "      <td>0.669306</td>\n",
       "      <td>0.009906</td>\n",
       "      <td>0.114163</td>\n",
       "      <td>-0.960521</td>\n",
       "      <td>-1.170492</td>\n",
       "      <td>-1.060306</td>\n",
       "      <td>-1.084586</td>\n",
       "      <td>0.452993</td>\n",
       "      <td>-0.942173</td>\n",
       "      <td>-0.946011</td>\n",
       "      <td>0.040700</td>\n",
       "      <td>-0.537339</td>\n",
       "      <td>-0.054468</td>\n",
       "      <td>-0.986565</td>\n",
       "      <td>-0.072454</td>\n",
       "      <td>0.189515</td>\n",
       "      <td>-0.248680</td>\n",
       "      <td>-2.479900</td>\n",
       "      <td>-0.809227</td>\n",
       "      <td>0.965828</td>\n",
       "      <td>-1.548473</td>\n",
       "      <td>-0.048706</td>\n",
       "      <td>-0.029076</td>\n",
       "      <td>-0.863246</td>\n",
       "      <td>-0.278058</td>\n",
       "      <td>-1.005084</td>\n",
       "      <td>-0.969434</td>\n",
       "      <td>-0.559550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>-1.399388</td>\n",
       "      <td>0.571478</td>\n",
       "      <td>-0.065315</td>\n",
       "      <td>0.114163</td>\n",
       "      <td>-0.960521</td>\n",
       "      <td>-1.528571</td>\n",
       "      <td>0.071332</td>\n",
       "      <td>-1.084586</td>\n",
       "      <td>0.810773</td>\n",
       "      <td>-1.498893</td>\n",
       "      <td>-0.312459</td>\n",
       "      <td>-0.209596</td>\n",
       "      <td>0.321740</td>\n",
       "      <td>-0.079346</td>\n",
       "      <td>0.197006</td>\n",
       "      <td>-0.046533</td>\n",
       "      <td>0.018584</td>\n",
       "      <td>0.927447</td>\n",
       "      <td>-0.756162</td>\n",
       "      <td>-0.370665</td>\n",
       "      <td>-0.561145</td>\n",
       "      <td>-0.065727</td>\n",
       "      <td>-0.034383</td>\n",
       "      <td>1.824861</td>\n",
       "      <td>-0.138744</td>\n",
       "      <td>1.122228</td>\n",
       "      <td>-0.674927</td>\n",
       "      <td>0.147281</td>\n",
       "      <td>-2.119996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>-0.273301</td>\n",
       "      <td>-0.988848</td>\n",
       "      <td>-0.063148</td>\n",
       "      <td>-0.080876</td>\n",
       "      <td>-0.358706</td>\n",
       "      <td>0.683094</td>\n",
       "      <td>-0.066979</td>\n",
       "      <td>0.457721</td>\n",
       "      <td>0.214472</td>\n",
       "      <td>0.197361</td>\n",
       "      <td>-0.312459</td>\n",
       "      <td>1.816304</td>\n",
       "      <td>-0.021892</td>\n",
       "      <td>-0.001268</td>\n",
       "      <td>-0.394779</td>\n",
       "      <td>-0.054964</td>\n",
       "      <td>-0.223314</td>\n",
       "      <td>-1.760842</td>\n",
       "      <td>0.413516</td>\n",
       "      <td>-0.182710</td>\n",
       "      <td>-0.179402</td>\n",
       "      <td>1.809511</td>\n",
       "      <td>-0.047868</td>\n",
       "      <td>-1.584678</td>\n",
       "      <td>-0.602331</td>\n",
       "      <td>1.122228</td>\n",
       "      <td>0.249514</td>\n",
       "      <td>-0.902963</td>\n",
       "      <td>0.460742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>-0.836344</td>\n",
       "      <td>-0.542505</td>\n",
       "      <td>-0.046370</td>\n",
       "      <td>0.504239</td>\n",
       "      <td>-0.358706</td>\n",
       "      <td>0.556713</td>\n",
       "      <td>0.850904</td>\n",
       "      <td>-0.056381</td>\n",
       "      <td>0.452993</td>\n",
       "      <td>0.569668</td>\n",
       "      <td>-0.312459</td>\n",
       "      <td>-0.257178</td>\n",
       "      <td>0.149924</td>\n",
       "      <td>-0.072664</td>\n",
       "      <td>-0.986565</td>\n",
       "      <td>-0.064059</td>\n",
       "      <td>0.123889</td>\n",
       "      <td>1.767537</td>\n",
       "      <td>-0.140542</td>\n",
       "      <td>-0.370665</td>\n",
       "      <td>0.202341</td>\n",
       "      <td>0.719257</td>\n",
       "      <td>-0.046177</td>\n",
       "      <td>-1.386803</td>\n",
       "      <td>-0.146794</td>\n",
       "      <td>-1.211582</td>\n",
       "      <td>-0.146675</td>\n",
       "      <td>0.107399</td>\n",
       "      <td>0.520759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>-0.273301</td>\n",
       "      <td>-0.175648</td>\n",
       "      <td>-0.070553</td>\n",
       "      <td>0.114163</td>\n",
       "      <td>0.844922</td>\n",
       "      <td>0.346078</td>\n",
       "      <td>-0.632798</td>\n",
       "      <td>1.485926</td>\n",
       "      <td>0.134966</td>\n",
       "      <td>0.649696</td>\n",
       "      <td>-0.312459</td>\n",
       "      <td>-0.287589</td>\n",
       "      <td>-0.279616</td>\n",
       "      <td>-0.127406</td>\n",
       "      <td>0.788791</td>\n",
       "      <td>-0.022269</td>\n",
       "      <td>-0.430111</td>\n",
       "      <td>-1.424806</td>\n",
       "      <td>0.782889</td>\n",
       "      <td>-0.809227</td>\n",
       "      <td>1.347571</td>\n",
       "      <td>1.286189</td>\n",
       "      <td>-0.038794</td>\n",
       "      <td>1.819787</td>\n",
       "      <td>0.041197</td>\n",
       "      <td>-1.211582</td>\n",
       "      <td>-0.344769</td>\n",
       "      <td>-0.052132</td>\n",
       "      <td>0.820844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>0.289743</td>\n",
       "      <td>0.313889</td>\n",
       "      <td>-0.118232</td>\n",
       "      <td>-0.470952</td>\n",
       "      <td>0.243108</td>\n",
       "      <td>-0.791350</td>\n",
       "      <td>-0.029258</td>\n",
       "      <td>-0.056381</td>\n",
       "      <td>-0.183062</td>\n",
       "      <td>-0.681211</td>\n",
       "      <td>0.954645</td>\n",
       "      <td>-0.108302</td>\n",
       "      <td>0.321740</td>\n",
       "      <td>-0.112191</td>\n",
       "      <td>-0.394779</td>\n",
       "      <td>-0.046901</td>\n",
       "      <td>-0.005835</td>\n",
       "      <td>-1.760842</td>\n",
       "      <td>-0.078980</td>\n",
       "      <td>0.631761</td>\n",
       "      <td>-0.179402</td>\n",
       "      <td>-1.177786</td>\n",
       "      <td>-0.043868</td>\n",
       "      <td>0.972476</td>\n",
       "      <td>-0.111279</td>\n",
       "      <td>1.122228</td>\n",
       "      <td>-0.080643</td>\n",
       "      <td>0.692344</td>\n",
       "      <td>-0.199447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1541 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PimplesY_N  PRLng_mL  Vit_D3_ng_mL  Cycle_lengthdays  CycleR_I  \\\n",
       "0      -1.399388  2.155471     -0.110646          0.114163 -0.960521   \n",
       "1      -1.399388 -0.316869      0.088920          0.114163 -0.960521   \n",
       "2       1.415830 -1.260638      0.036545          0.114163 -0.960521   \n",
       "3      -1.399388  1.340891     -0.037051          0.114163 -0.960521   \n",
       "4      -1.399388  0.669306      0.009906          0.114163 -0.960521   \n",
       "...          ...       ...           ...               ...       ...   \n",
       "1536   -1.399388  0.571478     -0.065315          0.114163 -0.960521   \n",
       "1537   -0.273301 -0.988848     -0.063148         -0.080876 -0.358706   \n",
       "1538   -0.836344 -0.542505     -0.046370          0.504239 -0.358706   \n",
       "1539   -0.273301 -0.175648     -0.070553          0.114163  0.844922   \n",
       "1540    0.289743  0.313889     -0.118232         -0.470952  0.243108   \n",
       "\n",
       "           BMI  RBSmg_dl  Weight_gainY_N  Avg_F_size_L_mm  Weight_Kg  \\\n",
       "0    -1.339000 -0.557356       -1.084586         1.248061  -1.585880   \n",
       "1    -0.159445 -0.557356       -1.084586         0.055459   0.188663   \n",
       "2    -0.075192 -1.060306       -1.084586         1.248061   0.519215   \n",
       "3     0.851601 -1.563256       -1.084586         0.055459   0.188663   \n",
       "4    -1.170492 -1.060306       -1.084586         0.452993  -0.942173   \n",
       "...        ...       ...             ...              ...        ...   \n",
       "1536 -1.528571  0.071332       -1.084586         0.810773  -1.498893   \n",
       "1537  0.683094 -0.066979        0.457721         0.214472   0.197361   \n",
       "1538  0.556713  0.850904       -0.056381         0.452993   0.569668   \n",
       "1539  0.346078 -0.632798        1.485926         0.134966   0.649696   \n",
       "1540 -0.791350 -0.029258       -0.056381        -0.183062  -0.681211   \n",
       "\n",
       "      hair_growthY_N  I___beta_HCGmIU_mL  Avg_F_size_R_mm    FSH_LH  \\\n",
       "0          -0.946011           -0.287763         1.180819 -0.112551   \n",
       "1          -0.946011           -0.263601        -0.537339 -0.009492   \n",
       "2          -0.946011           -0.085585         2.039898 -0.006151   \n",
       "3          -0.946011           -0.287763        -0.537339 -0.080168   \n",
       "4          -0.946011            0.040700        -0.537339 -0.054468   \n",
       "...              ...                 ...              ...       ...   \n",
       "1536       -0.312459           -0.209596         0.321740 -0.079346   \n",
       "1537       -0.312459            1.816304        -0.021892 -0.001268   \n",
       "1538       -0.312459           -0.257178         0.149924 -0.072664   \n",
       "1539       -0.312459           -0.287589        -0.279616 -0.127406   \n",
       "1540        0.954645           -0.108302         0.321740 -0.112191   \n",
       "\n",
       "      Skin_darkening_Y_N  LHmIU_mL  TSH_mIU_L  Antral_Follicle_Count  \\\n",
       "0              -0.986565 -0.021274  -0.913143              -0.416698   \n",
       "1              -0.986565 -0.068956   0.033082              -0.551112   \n",
       "2              -0.986565 -0.072822  -0.203474               0.154564   \n",
       "3              -0.986565 -0.045575   5.088521              -0.215076   \n",
       "4              -0.986565 -0.072454   0.189515              -0.248680   \n",
       "...                  ...       ...        ...                    ...   \n",
       "1536            0.197006 -0.046533   0.018584               0.927447   \n",
       "1537           -0.394779 -0.054964  -0.223314              -1.760842   \n",
       "1538           -0.986565 -0.064059   0.123889               1.767537   \n",
       "1539            0.788791 -0.022269  -0.430111              -1.424806   \n",
       "1540           -0.394779 -0.046901  -0.005835              -1.760842   \n",
       "\n",
       "      WaistHip_Ratio  Follicle_No_R  BP__Systolic_mmHg  Marraige_Status_Yrs  \\\n",
       "0          -1.864279      -1.122485          -0.942889            -0.240167   \n",
       "1          -1.556469      -0.495969           0.965828             0.632036   \n",
       "2           0.290392       2.636615           0.965828             0.413985   \n",
       "3          -0.940849      -1.435744           0.965828            -0.894320   \n",
       "4          -2.479900      -0.809227           0.965828            -1.548473   \n",
       "...              ...            ...                ...                  ...   \n",
       "1536       -0.756162      -0.370665          -0.561145            -0.065727   \n",
       "1537        0.413516      -0.182710          -0.179402             1.809511   \n",
       "1538       -0.140542      -0.370665           0.202341             0.719257   \n",
       "1539        0.782889      -0.809227           1.347571             1.286189   \n",
       "1540       -0.078980       0.631761          -0.179402            -1.177786   \n",
       "\n",
       "      FSHmIU_mL  Testosterone_Levelng_dL  AMHng_mL  Menstrual_Irregularity  \\\n",
       "0     -0.019515                 0.920724 -0.908231                0.655466   \n",
       "1     -0.028486                -0.683586 -1.036085               -0.744820   \n",
       "2     -0.037236                 0.412338  0.171418                1.122228   \n",
       "3     -0.018706                -0.414679 -1.109482                0.655466   \n",
       "4     -0.048706                -0.029076 -0.863246               -0.278058   \n",
       "...         ...                      ...       ...                     ...   \n",
       "1536  -0.034383                 1.824861 -0.138744                1.122228   \n",
       "1537  -0.047868                -1.584678 -0.602331                1.122228   \n",
       "1538  -0.046177                -1.386803 -0.146794               -1.211582   \n",
       "1539  -0.038794                 1.819787  0.041197               -1.211582   \n",
       "1540  -0.043868                 0.972476 -0.111279                1.122228   \n",
       "\n",
       "      Follicle_No_L  Endometrium_mm   Hipinch  \n",
       "0         -1.005084        0.027633 -0.859636  \n",
       "1         -1.005084       -3.162981 -0.259464  \n",
       "2          2.296491        1.024700  0.340707  \n",
       "3         -1.335242       -0.637078  0.940879  \n",
       "4         -1.005084       -0.969434 -0.559550  \n",
       "...             ...             ...       ...  \n",
       "1536      -0.674927        0.147281 -2.119996  \n",
       "1537       0.249514       -0.902963  0.460742  \n",
       "1538      -0.146675        0.107399  0.520759  \n",
       "1539      -0.344769       -0.052132  0.820844  \n",
       "1540      -0.080643        0.692344 -0.199447  \n",
       "\n",
       "[1541 rows x 29 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0805fba2-0b06-4958-9044-1febab9b3f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.15, stratify=y, shuffle=True, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "75f440c4-5b71-40b0-b151-729ca44dc0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = lgb.Dataset(x_train, label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d9d60c69-b579-4245-8dbd-c82faec1e150",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'learning_rate': 0.3,\n",
    "              'application': 'binary',\n",
    "              'num_leaves': 30,\n",
    "              'verbosity': -1,\n",
    "              'metric': 'binary_error',\n",
    "              'data_random_seed': 2,\n",
    "              'bagging_fraction': 0.8,\n",
    "              'feature_fraction': 0.6,\n",
    "              'nthread': 4,\n",
    "              'lambda_l1': 1,\n",
    "              'lambda_l2': 1}\n",
    "# params = {\n",
    "#     'learning_rate': 0.5,\n",
    "#     'application': 'binary',\n",
    "#     'num_boost_round': 100,\n",
    "#     'nfold': 10,\n",
    "#     'num_leaves': 31,\n",
    "#     'verbosity': -1,\n",
    "#     'metric': 'binary_error',\n",
    "#     'data_random_seed': 2,\n",
    "#     'bagging_fraction': 0.8,\n",
    "#     'feature_fraction': 0.6,\n",
    "#     'nthread': 4,\n",
    "#     'lambda_l1': 1,\n",
    "#     'lambda_l2': 1,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5ee06680-298f-4c9a-adfe-edd1f4d544e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbcv = lgb.cv(params, train_set=d_train, nfold=10, stratified=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c4e76d9f-58d0-41d3-afaf-c3749902dd98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated accuracy: 0.9565\n"
     ]
    }
   ],
   "source": [
    "min_error = min(lgbcv['valid binary_error-mean'])\n",
    "\n",
    "# Accuracy is (1 - error)\n",
    "accuracy = 1 - min_error\n",
    "print(f\"Cross-validated accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ffae1146-3730-4a86-8f49-4b3fd9da02e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective(trial):\n",
    "#     # Suggest hyperparameters to try\n",
    "#     param = {\n",
    "#         \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "#         \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "#         \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "#         \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 150),\n",
    "#         \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 50),\n",
    "#         \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "#         \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "#         \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 10.0, log=True),\n",
    "#         \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 10.0, log=True),\n",
    "#         \"random_state\": 42,\n",
    "#         \"objective\": \"binary\",  # or \"multiclass\" if you're doing that\n",
    "#     }\n",
    "\n",
    "#     skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=8)\n",
    "#     acc_scores = []\n",
    "\n",
    "#     for train_idx, valid_idx in skf.split(X, y):\n",
    "#         X_train_fold = X.iloc[train_idx]\n",
    "#         X_valid_fold = X.iloc[valid_idx]\n",
    "#         y_train_fold = y.iloc[train_idx]\n",
    "#         y_valid_fold = y.iloc[valid_idx]\n",
    "\n",
    "\n",
    "#         train_data = lgb.Dataset(X_train_fold, label=y_train_fold)\n",
    "#         valid_data = lgb.Dataset(X_valid_fold, label=y_valid_fold)\n",
    "\n",
    "#         gbm = lgb.train(param,\n",
    "#                         train_data,\n",
    "#                         valid_sets=[valid_data],\n",
    "#                         num_boost_round=1000)\n",
    "\n",
    "#         y_pred = gbm.predict(X_valid_fold)\n",
    "#         y_pred_labels = (y_pred > 0.5).astype(int)\n",
    "#         acc = accuracy_score(y_valid_fold, y_pred_labels)\n",
    "#         acc_scores.append(acc)\n",
    "\n",
    "#     return 1.0 - np.mean(acc_scores)  # Optuna minimizes, so 1 - accuracy\n",
    "\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters to try\n",
    "    param = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 150),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 50),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 10.0, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 10.0, log=True),\n",
    "        \"random_state\": 42,\n",
    "        \"objective\": \"binary\",  # or \"multiclass\" if you're doing that\n",
    "    }\n",
    "\n",
    "\n",
    "    train_data = lgb.Dataset(x_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(x_test, label=y_test)\n",
    "\n",
    "    gbm = lgb.train(param,\n",
    "                    train_data,\n",
    "                    valid_sets=[valid_data],\n",
    "                    num_boost_round=1000)\n",
    "\n",
    "    y_pred = gbm.predict(x_test)\n",
    "    y_pred_labels = (y_pred > 0.5).astype(int)\n",
    "    acc = accuracy_score(y_test, y_pred_labels)\n",
    "\n",
    "    return 1.0 - acc  # Optuna minimizes, so 1 - accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39589823-effc-4de9-a40f-77b761f45277",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='minimize')  # Because we return 1 - accuracy\n",
    "study.optimize(objective, n_trials=50)  # Try 50 combinations (or more!)\n",
    "\n",
    "print(\"Best hyperparameters:\")\n",
    "print(study.best_params)\n",
    "\n",
    "print(\"Best accuracy:\")\n",
    "print(1 - study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "aaa481ad-ba2b-4570-8435-690c788a3488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.978448275862069\n"
     ]
    }
   ],
   "source": [
    "# Making the best model\n",
    "\n",
    "#Taking the best params for training\n",
    "best_params = study.best_params\n",
    "\n",
    "#Training and testing\n",
    "train_data = lgb.Dataset(x_train, label=y_train)\n",
    "best_model = lgb.train(best_params,\n",
    "                train_data,\n",
    "                num_boost_round=1000)\n",
    "\n",
    "y_pred = best_model.predict(x_test)\n",
    "y_pred_labels = (y_pred > 0.5).astype(int)\n",
    "acc = accuracy_score(y_test, y_pred_labels)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0cbcde81-8b0b-4d2d-bb82-dff4440a0feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x11a17bb90>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the best model\n",
    "\n",
    "best_model.save_model('best_model.txt', num_iteration=best_model.best_iteration) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7c2e3f5d-4986-4f85-844b-91fc6c59ab11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.978448275862069\n"
     ]
    }
   ],
   "source": [
    "# To read the model\n",
    "new_model = lgb.Booster(model_file='best_model.txt')\n",
    "\n",
    "# Testing\n",
    "y_pred = new_model.predict(x_test)\n",
    "y_pred_labels = (y_pred > 0.5).astype(int)\n",
    "acc = accuracy_score(y_test, y_pred_labels)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d10fdb40-51d8-4c6a-b11a-c986d5c0231f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving selected features\n",
    "selected_features = selected_features.tolist()\n",
    "selected_features = { \"selected_features\" : selected_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e9ab43eb-db0d-49a7-b499-cc9bab456901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"selected_features.json\", \"w\") as f:\n",
    "    json.dump(selected_features, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c0ad294c-8ad5-473f-ae26-04235be07bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'selected_features': ['PimplesY_N',\n",
       "  'PRLng_mL',\n",
       "  'Vit_D3_ng_mL',\n",
       "  'Cycle_lengthdays',\n",
       "  'CycleR_I',\n",
       "  'BMI',\n",
       "  'RBSmg_dl',\n",
       "  'Weight_gainY_N',\n",
       "  'Avg_F_size_L_mm',\n",
       "  'Weight_Kg',\n",
       "  'hair_growthY_N',\n",
       "  'I___beta_HCGmIU_mL',\n",
       "  'Avg_F_size_R_mm',\n",
       "  'FSH_LH',\n",
       "  'Skin_darkening_Y_N',\n",
       "  'LHmIU_mL',\n",
       "  'TSH_mIU_L',\n",
       "  'Antral_Follicle_Count',\n",
       "  'WaistHip_Ratio',\n",
       "  'Follicle_No_R',\n",
       "  'BP__Systolic_mmHg',\n",
       "  'Marraige_Status_Yrs',\n",
       "  'FSHmIU_mL',\n",
       "  'Testosterone_Levelng_dL',\n",
       "  'AMHng_mL',\n",
       "  'Menstrual_Irregularity',\n",
       "  'Follicle_No_L',\n",
       "  'Endometrium_mm',\n",
       "  'Hipinch']}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2818\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000321 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2563\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000414 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2556\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000346 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2430\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2368\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000447 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2113\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000439 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2106\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000670 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2080\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000429 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1834\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000343 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1827\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000409 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1769\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000369 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1762\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000404 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1702\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000387 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1517\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000381 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1262\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000316 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1193\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000439 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000397 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000228 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000404 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "\n",
      "[LightGBM] [Info] Total Bins 3260\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000436 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3229\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3110\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 24\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000380 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3103\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3025\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000468 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3018\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000430 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2763\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000350 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2662\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000347 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2652\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000353 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2645\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2589\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000201 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2582\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000378 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2336\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2081\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000409 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000340 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1771\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000353 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1516\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000374 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1509\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000353 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1502\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000410 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1443\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000542 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1374\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000261 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1119\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000276 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 935\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000369 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000366 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000270 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000402 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3587\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 28\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000447 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3561\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 27\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000410 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3306\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000396 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3289\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000434 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3034\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 24\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000543 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3027\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2895\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2640\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000306 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2574\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000446 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2319\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2253\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2246\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000361 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1996\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000376 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1741\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1661\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000411 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1650\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000325 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1395\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1199\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000307 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1134\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000477 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1127\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000303 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1120\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000380 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1113\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000454 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1054\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000427 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 995\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000395 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 936\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000323 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 681\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000346 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000397 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000597 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2647\n",
      "[LightGBM] [Info] Number of data points in the train set: 1232, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243506 -> initscore=-1.133550\n",
      "[LightGBM] [Info] Start training from score -1.133550\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 300, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000348 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2579\n",
      "[LightGBM] [Info] Number of data points in the train set: 1232, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243506 -> initscore=-1.133550\n",
      "[LightGBM] [Info] Start training from score -1.133550\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 300, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000492 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2548\n",
      "[LightGBM] [Info] Number of data points in the train set: 1232, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243506 -> initscore=-1.133550\n",
      "[LightGBM] [Info] Start training from score -1.133550\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 300, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000370 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2541\n",
      "[LightGBM] [Info] Number of data points in the train set: 1232, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243506 -> initscore=-1.133550\n",
      "[LightGBM] [Info] Start training from score -1.133550\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 300, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000377 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 1232, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243506 -> initscore=-1.133550\n",
      "[LightGBM] [Info] Start training from score -1.133550\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 300, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2031\n",
      "[LightGBM] [Info] Number of data points in the train set: 1232, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243506 -> initscore=-1.133550\n",
      "[LightGBM] [Info] Start training from score -1.133550\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 300, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000436 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1782\n",
      "[LightGBM] [Info] Number of data points in the train set: 1232, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243506 -> initscore=-1.133550\n",
      "[LightGBM] [Info] Start training from score -1.133550\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 300, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1703\n",
      "[LightGBM] [Info] Number of data points in the train set: 1232, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243506 -> initscore=-1.133550\n",
      "[LightGBM] [Info] Start training from score -1.133550\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 300, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000261 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1448\n",
      "[LightGBM] [Info] Number of data points in the train set: 1232, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243506 -> initscore=-1.133550\n",
      "[LightGBM] [Info] Start training from score -1.133550\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 300, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000459 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1392\n",
      "[LightGBM] [Info] Number of data points in the train set: 1232, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243506 -> initscore=-1.133550\n",
      "[LightGBM] [Info] Start training from score -1.133550\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 300, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000324 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1385\n",
      "[LightGBM] [Info] Number of data points in the train set: 1232, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243506 -> initscore=-1.133550\n",
      "[LightGBM] [Info] Start training from score -1.133550\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 300, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 1232, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243506 -> initscore=-1.133550\n",
      "[LightGBM] [Info] Start training from score -1.133550\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 300, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1123\n",
      "[LightGBM] [Info] Number of data points in the train set: 1232, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243506 -> initscore=-1.133550\n",
      "[LightGBM] [Info] Start training from score -1.133550\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 300, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000307 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1116\n",
      "[LightGBM] [Info] Number of data points in the train set: 1232, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243506 -> initscore=-1.133550\n",
      "[LightGBM] [Info] Start training from score -1.133550\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 300, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000399 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1051\n",
      "[LightGBM] [Info] Number of data points in the train set: 1232, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243506 -> initscore=-1.133550\n",
      "[LightGBM] [Info] Start training from score -1.133550\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 300, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000279 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 1232, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243506 -> initscore=-1.133550\n",
      "[LightGBM] [Info] Start training from score -1.133550\n",
      "[LightGBM] [Info] Number of positive: 300, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000310 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 934\n",
      "[LightGBM] [Info] Number of data points in the train set: 1232, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243506 -> initscore=-1.133550\n",
      "[LightGBM] [Info] Start training from score -1.133550\n",
      "[LightGBM] [Info] Number of positive: 300, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 679\n",
      "[LightGBM] [Info] Number of data points in the train set: 1232, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243506 -> initscore=-1.133550\n",
      "[LightGBM] [Info] Start training from score -1.133550\n",
      "[LightGBM] [Info] Number of positive: 300, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000346 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 509\n",
      "[LightGBM] [Info] Number of data points in the train set: 1232, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243506 -> initscore=-1.133550\n",
      "[LightGBM] [Info] Start training from score -1.133550\n",
      "[LightGBM] [Info] Number of positive: 300, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000129 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 254\n",
      "[LightGBM] [Info] Number of data points in the train set: 1232, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243506 -> initscore=-1.133550\n",
      "[LightGBM] [Info] Start training from score -1.133550\n",
      "\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3611\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 27\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000562 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3356\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000504 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3261\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000415 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3179\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 24\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000367 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3117\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000388 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3106\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000415 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2983\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000553 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2976\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000357 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2729\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000394 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2474\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2219\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2157\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000356 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2150\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000313 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2143\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000315 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2087\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000452 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1832\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000547 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1825\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1765\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000347 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1758\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000510 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1572\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000306 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1513\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1444\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000346 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1189\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000212 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 934\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000313 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n",
      "[LightGBM] [Info] Number of positive: 301, number of negative: 932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 1233, number of used features: 1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244120 -> initscore=-1.130223\n",
      "[LightGBM] [Info] Start training from score -1.130223\n"
     ]
    }
   ],
   "source": [
    "with open(\"selected_features.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cde2d1-879b-49a2-9c5b-ea6bcc371fab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced6bb6d-d289-46fe-88f0-b88829de76cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aca7fb5-e777-4349-9f08-7cbb141e3e68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
